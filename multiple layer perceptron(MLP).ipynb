{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P9x-ktrE5jY8"
   },
   "source": [
    "# 多层感知机（MLP）\n",
    "\n",
    "*  使用 tf.keras.datasets 获得数据集并预处理\n",
    "*  使用 tf.keras.Model 和 tf.keras.layers 构建模型\n",
    "*  构建模型训练流程，使用 tf.keras.losses 计算损失函数，并使用 tf.keras.optimizer 优化模型\n",
    "*  构建模型评估流程，使用 tf.keras.metrics 计算评估指标\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-AsPJ5I05ldD",
    "outputId": "54cbcbf7-5a10-476c-df82-0994eef797cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "yKDWqqYy255E",
    "outputId": "e11e7708-0647-47ae-f3a7-d587bc68313e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling tensorflow-1.15.0rc3:\n",
      "  Would remove:\n",
      "    /usr/local/bin/estimator_ckpt_converter\n",
      "    /usr/local/bin/freeze_graph\n",
      "    /usr/local/bin/saved_model_cli\n",
      "    /usr/local/bin/tensorboard\n",
      "    /usr/local/bin/tf_upgrade_v2\n",
      "    /usr/local/bin/tflite_convert\n",
      "    /usr/local/bin/toco\n",
      "    /usr/local/bin/toco_from_protos\n",
      "    /usr/local/lib/python3.6/dist-packages/tensorflow-1.15.0rc3.dist-info/*\n",
      "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
      "    /usr/local/lib/python3.6/dist-packages/tensorflow_core/*\n",
      "Proceed (y/n)? y\n",
      "  Successfully uninstalled tensorflow-1.15.0rc3\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "colab_type": "code",
    "id": "JjTCbhad3AIZ",
    "outputId": "51187eaf-412f-4caf-a64b-6647c8964d98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
      "\u001b[K     |████████████████████████████████| 86.3MB 386kB/s \n",
      "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.11.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.33.6)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.0.8)\n",
      "Collecting tensorflow-estimator<2.1.0,>=2.0.0 (from tensorflow==2.0.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/00/5e6cdf86190a70d7382d320b2b04e4ff0f8191a37d90a422a2f8ff0705bb/tensorflow_estimator-2.0.0-py2.py3-none-any.whl (449kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 34.9MB/s \n",
      "\u001b[?25hCollecting tensorboard<2.1.0,>=2.0.0 (from tensorflow==2.0.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/a6/e8ffa4e2ddb216449d34cfcb825ebb38206bee5c4553d69e7bc8bc2c5d64/tensorboard-2.0.0-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 29.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.16.5)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.1.7)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.1.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.7.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.15.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.2)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (41.2.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.16.0)\n",
      "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n",
      "  Found existing installation: tensorflow-estimator 1.15.1\n",
      "    Uninstalling tensorflow-estimator-1.15.1:\n",
      "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
      "  Found existing installation: tensorboard 1.15.0\n",
      "    Uninstalling tensorboard-1.15.0:\n",
      "      Successfully uninstalled tensorboard-1.15.0\n",
      "Successfully installed tensorboard-2.0.0 tensorflow-2.0.0 tensorflow-estimator-2.0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "tensorboard",
         "tensorflow",
         "tensorflow_core",
         "tensorflow_estimator"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install tensorflow==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ySsKb9t73Oyu",
    "outputId": "34af7421-e210-4137-c56a-eeb693521bc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gtGmJ-Oc3UkZ",
    "outputId": "b422a36e-b8ff-45ee-c4c1-71c8a6c0bdee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly() \n",
    "#tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TKTcQHje6GWd"
   },
   "source": [
    "# 数据获取及预处理： tf.keras.datasets\n",
    "先进行预备工作，实现一个简单的 MNISTLoader 类来读取 MNIST 数据集数据。这里使用了 tf.keras.datasets 快速载入 MNIST 数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EoXZNhp-33aV"
   },
   "outputs": [],
   "source": [
    "class MNISTLoader():\n",
    "  def __init__(self):\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "    (self.train_data, self.train_label), (self.test_data, self.test_label) = mnist.load_data()\n",
    "    self.train_data = np.expand_dims(self.train_data.astype(np.float32) / 255.0, axis=-1)\n",
    "    self.test_data = np.expand_dims(self.test_data.astype(np.float32) / 255.0, axis=-1)\n",
    "    self.train_label = self.train_label.astype(np.int32)    # [60000]\n",
    "    self.test_label = self.test_label.astype(np.int32)      # [10000]\n",
    "    self.num_train_data, self.num_test_data = self.train_data.shape[0], self.test_data.shape[0]\n",
    "  \n",
    "  def get_batch(self, batch_size):\n",
    "    index = np.random.randint(0, np.shape(self.train_data)[0], batch_size)\n",
    "    return self.train_data[index, :], self.train_label[index]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XsIKIP8E6OHS"
   },
   "source": [
    "# 模型的构建： tf.keras.Model 和 tf.keras.layers\n",
    "多层感知机的模型类实现与上面的线性模型类似，使用 tf.keras.Model 和 tf.keras.layers 构建，所不同的地方在于层数增加了（顾名思义，“多层” 感知机），以及引入了非线性激活函数（这里使用了 ReLU 函数 ， 即下方的 activation=tf.nn.relu ）。该模型输入一个向量（比如这里是拉直的 1×784 手写体数字图片），输出 10 维的向量，分别代表这张图片属于 0 到 9 的概率。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rb7FwTLz336k"
   },
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.flatten = tf.keras.layers.Flatten()\n",
    "    self.dense1 = tf.keras.layers.Dense(units= 100, activation=tf.nn.relu)\n",
    "    self.dense2 = tf.keras.layers.Dense(units = 10)\n",
    "    \n",
    "  def call(self, inputs):\n",
    "    x = self.flatten(inputs)\n",
    "    x = self.dense1(x)\n",
    "    x = self.dense2(x)\n",
    "    output = tf.nn.softmax(x)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yce2D1vp6UyU"
   },
   "source": [
    "# 模型的训练： tf.keras.losses 和 tf.keras.optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q5iK_vIf39gs"
   },
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "batch_size = 50\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CIFHCo8g39-t"
   },
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "data_loader = MNISTLoader()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UF7QbeVG6YtH"
   },
   "source": [
    "然后迭代进行以下步骤：\n",
    "\n",
    "从 DataLoader 中随机取一批训练数据；\n",
    "\n",
    "将这批数据送入模型，计算出模型的预测值；\n",
    "\n",
    "将模型预测值与真实值进行比较，计算损失函数（loss）。这里使用 tf.keras.losses 中的交叉熵函数作为损失函数；\n",
    "\n",
    "计算损失函数关于模型变量的导数；\n",
    "\n",
    "将求出的导数值传入优化器，使用优化器的 apply_gradients 方法更新模型参数以最小化损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "WcTDYj0E4Ar2",
    "outputId": "a2259b81-ca98-433b-b471-0d390787dd80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0: loss 2.285256\n",
      "batch 1: loss 2.205372\n",
      "batch 2: loss 2.334929\n",
      "batch 3: loss 2.056121\n",
      "batch 4: loss 2.081305\n",
      "batch 5: loss 1.941437\n",
      "batch 6: loss 2.061041\n",
      "batch 7: loss 1.972376\n",
      "batch 8: loss 1.754983\n",
      "batch 9: loss 1.749182\n",
      "batch 10: loss 1.632017\n",
      "batch 11: loss 1.592685\n",
      "batch 12: loss 1.543856\n",
      "batch 13: loss 1.629244\n",
      "batch 14: loss 1.514880\n",
      "batch 15: loss 1.428778\n",
      "batch 16: loss 1.384761\n",
      "batch 17: loss 1.380737\n",
      "batch 18: loss 1.174533\n",
      "batch 19: loss 1.367718\n",
      "batch 20: loss 1.302076\n",
      "batch 21: loss 1.189340\n",
      "batch 22: loss 1.042583\n",
      "batch 23: loss 1.025285\n",
      "batch 24: loss 1.220943\n",
      "batch 25: loss 1.032526\n",
      "batch 26: loss 0.888587\n",
      "batch 27: loss 1.059231\n",
      "batch 28: loss 1.008494\n",
      "batch 29: loss 0.836554\n",
      "batch 30: loss 0.864243\n",
      "batch 31: loss 0.854915\n",
      "batch 32: loss 0.907002\n",
      "batch 33: loss 1.022292\n",
      "batch 34: loss 0.848349\n",
      "batch 35: loss 0.761802\n",
      "batch 36: loss 0.874089\n",
      "batch 37: loss 0.739989\n",
      "batch 38: loss 0.718120\n",
      "batch 39: loss 0.734513\n",
      "batch 40: loss 0.776238\n",
      "batch 41: loss 0.595228\n",
      "batch 42: loss 0.819337\n",
      "batch 43: loss 0.679247\n",
      "batch 44: loss 0.594760\n",
      "batch 45: loss 0.811826\n",
      "batch 46: loss 0.661954\n",
      "batch 47: loss 0.793975\n",
      "batch 48: loss 0.486048\n",
      "batch 49: loss 0.591936\n",
      "batch 50: loss 0.585743\n",
      "batch 51: loss 0.614658\n",
      "batch 52: loss 0.406398\n",
      "batch 53: loss 0.634467\n",
      "batch 54: loss 0.614022\n",
      "batch 55: loss 0.672396\n",
      "batch 56: loss 0.476113\n",
      "batch 57: loss 0.537915\n",
      "batch 58: loss 0.513415\n",
      "batch 59: loss 0.550884\n",
      "batch 60: loss 0.583696\n",
      "batch 61: loss 0.651275\n",
      "batch 62: loss 0.506319\n",
      "batch 63: loss 0.502315\n",
      "batch 64: loss 0.688968\n",
      "batch 65: loss 0.448250\n",
      "batch 66: loss 0.605824\n",
      "batch 67: loss 0.489055\n",
      "batch 68: loss 0.405522\n",
      "batch 69: loss 0.525403\n",
      "batch 70: loss 0.635453\n",
      "batch 71: loss 0.301678\n",
      "batch 72: loss 0.635552\n",
      "batch 73: loss 0.568243\n",
      "batch 74: loss 0.697631\n",
      "batch 75: loss 0.460927\n",
      "batch 76: loss 0.476688\n",
      "batch 77: loss 0.357887\n",
      "batch 78: loss 0.431935\n",
      "batch 79: loss 0.565880\n",
      "batch 80: loss 0.566409\n",
      "batch 81: loss 0.468039\n",
      "batch 82: loss 0.622586\n",
      "batch 83: loss 0.487366\n",
      "batch 84: loss 0.498076\n",
      "batch 85: loss 0.385445\n",
      "batch 86: loss 0.478501\n",
      "batch 87: loss 0.558496\n",
      "batch 88: loss 0.526953\n",
      "batch 89: loss 0.547417\n",
      "batch 90: loss 0.547640\n",
      "batch 91: loss 0.557868\n",
      "batch 92: loss 0.358667\n",
      "batch 93: loss 0.409599\n",
      "batch 94: loss 0.561230\n",
      "batch 95: loss 0.668404\n",
      "batch 96: loss 0.559714\n",
      "batch 97: loss 0.524012\n",
      "batch 98: loss 0.474580\n",
      "batch 99: loss 0.399339\n",
      "batch 100: loss 0.475849\n",
      "batch 101: loss 0.324837\n",
      "batch 102: loss 0.389984\n",
      "batch 103: loss 0.473782\n",
      "batch 104: loss 0.419292\n",
      "batch 105: loss 0.416162\n",
      "batch 106: loss 0.509604\n",
      "batch 107: loss 0.346391\n",
      "batch 108: loss 0.352209\n",
      "batch 109: loss 0.488571\n",
      "batch 110: loss 0.419189\n",
      "batch 111: loss 0.437918\n",
      "batch 112: loss 0.350439\n",
      "batch 113: loss 0.315364\n",
      "batch 114: loss 0.351902\n",
      "batch 115: loss 0.549310\n",
      "batch 116: loss 0.420044\n",
      "batch 117: loss 0.357893\n",
      "batch 118: loss 0.327098\n",
      "batch 119: loss 0.293401\n",
      "batch 120: loss 0.291696\n",
      "batch 121: loss 0.294370\n",
      "batch 122: loss 0.379132\n",
      "batch 123: loss 0.437771\n",
      "batch 124: loss 0.364326\n",
      "batch 125: loss 0.363065\n",
      "batch 126: loss 0.515139\n",
      "batch 127: loss 0.221047\n",
      "batch 128: loss 0.207894\n",
      "batch 129: loss 0.304511\n",
      "batch 130: loss 0.569853\n",
      "batch 131: loss 0.434927\n",
      "batch 132: loss 0.402055\n",
      "batch 133: loss 0.551857\n",
      "batch 134: loss 0.451924\n",
      "batch 135: loss 0.390041\n",
      "batch 136: loss 0.205925\n",
      "batch 137: loss 0.300728\n",
      "batch 138: loss 0.279311\n",
      "batch 139: loss 0.254808\n",
      "batch 140: loss 0.406166\n",
      "batch 141: loss 0.510225\n",
      "batch 142: loss 0.336390\n",
      "batch 143: loss 0.286932\n",
      "batch 144: loss 0.334305\n",
      "batch 145: loss 0.505116\n",
      "batch 146: loss 0.296393\n",
      "batch 147: loss 0.498919\n",
      "batch 148: loss 0.507318\n",
      "batch 149: loss 0.261467\n",
      "batch 150: loss 0.298310\n",
      "batch 151: loss 0.411035\n",
      "batch 152: loss 0.361716\n",
      "batch 153: loss 0.277789\n",
      "batch 154: loss 0.288142\n",
      "batch 155: loss 0.430213\n",
      "batch 156: loss 0.242033\n",
      "batch 157: loss 0.438750\n",
      "batch 158: loss 0.418472\n",
      "batch 159: loss 0.703795\n",
      "batch 160: loss 0.331291\n",
      "batch 161: loss 0.392003\n",
      "batch 162: loss 0.503135\n",
      "batch 163: loss 0.416751\n",
      "batch 164: loss 0.649559\n",
      "batch 165: loss 0.284626\n",
      "batch 166: loss 0.253399\n",
      "batch 167: loss 0.320030\n",
      "batch 168: loss 0.521847\n",
      "batch 169: loss 0.307325\n",
      "batch 170: loss 0.274674\n",
      "batch 171: loss 0.358530\n",
      "batch 172: loss 0.518101\n",
      "batch 173: loss 0.390567\n",
      "batch 174: loss 0.174029\n",
      "batch 175: loss 0.539849\n",
      "batch 176: loss 0.428587\n",
      "batch 177: loss 0.329828\n",
      "batch 178: loss 0.812834\n",
      "batch 179: loss 0.396530\n",
      "batch 180: loss 0.224222\n",
      "batch 181: loss 0.258882\n",
      "batch 182: loss 0.207767\n",
      "batch 183: loss 0.155181\n",
      "batch 184: loss 0.377799\n",
      "batch 185: loss 0.284999\n",
      "batch 186: loss 0.323863\n",
      "batch 187: loss 0.338120\n",
      "batch 188: loss 0.188672\n",
      "batch 189: loss 0.327143\n",
      "batch 190: loss 0.504763\n",
      "batch 191: loss 0.337281\n",
      "batch 192: loss 0.262181\n",
      "batch 193: loss 0.223661\n",
      "batch 194: loss 0.283222\n",
      "batch 195: loss 0.190049\n",
      "batch 196: loss 0.274772\n",
      "batch 197: loss 0.282986\n",
      "batch 198: loss 0.372376\n",
      "batch 199: loss 0.440532\n",
      "batch 200: loss 0.427018\n",
      "batch 201: loss 0.316213\n",
      "batch 202: loss 0.460297\n",
      "batch 203: loss 0.486977\n",
      "batch 204: loss 0.261368\n",
      "batch 205: loss 0.321267\n",
      "batch 206: loss 0.350332\n",
      "batch 207: loss 0.225021\n",
      "batch 208: loss 0.342973\n",
      "batch 209: loss 0.244674\n",
      "batch 210: loss 0.441389\n",
      "batch 211: loss 0.378784\n",
      "batch 212: loss 0.413090\n",
      "batch 213: loss 0.252654\n",
      "batch 214: loss 0.414331\n",
      "batch 215: loss 0.536494\n",
      "batch 216: loss 0.192939\n",
      "batch 217: loss 0.213020\n",
      "batch 218: loss 0.297483\n",
      "batch 219: loss 0.343482\n",
      "batch 220: loss 0.412594\n",
      "batch 221: loss 0.324474\n",
      "batch 222: loss 0.318865\n",
      "batch 223: loss 0.234760\n",
      "batch 224: loss 0.272884\n",
      "batch 225: loss 0.242461\n",
      "batch 226: loss 0.545350\n",
      "batch 227: loss 0.312405\n",
      "batch 228: loss 0.391701\n",
      "batch 229: loss 0.372519\n",
      "batch 230: loss 0.472101\n",
      "batch 231: loss 0.377553\n",
      "batch 232: loss 0.216674\n",
      "batch 233: loss 0.271941\n",
      "batch 234: loss 0.558961\n",
      "batch 235: loss 0.170775\n",
      "batch 236: loss 0.262034\n",
      "batch 237: loss 0.225955\n",
      "batch 238: loss 0.212476\n",
      "batch 239: loss 0.260501\n",
      "batch 240: loss 0.214531\n",
      "batch 241: loss 0.323311\n",
      "batch 242: loss 0.478120\n",
      "batch 243: loss 0.236381\n",
      "batch 244: loss 0.410681\n",
      "batch 245: loss 0.263916\n",
      "batch 246: loss 0.323504\n",
      "batch 247: loss 0.399251\n",
      "batch 248: loss 0.294628\n",
      "batch 249: loss 0.326098\n",
      "batch 250: loss 0.372162\n",
      "batch 251: loss 0.495363\n",
      "batch 252: loss 0.221127\n",
      "batch 253: loss 0.576529\n",
      "batch 254: loss 0.397664\n",
      "batch 255: loss 0.369326\n",
      "batch 256: loss 0.210746\n",
      "batch 257: loss 0.264947\n",
      "batch 258: loss 0.207313\n",
      "batch 259: loss 0.211112\n",
      "batch 260: loss 0.255969\n",
      "batch 261: loss 0.215782\n",
      "batch 262: loss 0.190437\n",
      "batch 263: loss 0.222935\n",
      "batch 264: loss 0.397785\n",
      "batch 265: loss 0.227694\n",
      "batch 266: loss 0.467060\n",
      "batch 267: loss 0.419647\n",
      "batch 268: loss 0.357369\n",
      "batch 269: loss 0.204077\n",
      "batch 270: loss 0.456494\n",
      "batch 271: loss 0.174073\n",
      "batch 272: loss 0.438463\n",
      "batch 273: loss 0.257310\n",
      "batch 274: loss 0.358364\n",
      "batch 275: loss 0.197801\n",
      "batch 276: loss 0.552193\n",
      "batch 277: loss 0.302756\n",
      "batch 278: loss 0.383897\n",
      "batch 279: loss 0.243372\n",
      "batch 280: loss 0.619185\n",
      "batch 281: loss 0.313286\n",
      "batch 282: loss 0.353051\n",
      "batch 283: loss 0.262350\n",
      "batch 284: loss 0.167927\n",
      "batch 285: loss 0.241061\n",
      "batch 286: loss 0.197949\n",
      "batch 287: loss 0.249585\n",
      "batch 288: loss 0.337045\n",
      "batch 289: loss 0.382001\n",
      "batch 290: loss 0.555709\n",
      "batch 291: loss 0.468115\n",
      "batch 292: loss 0.413247\n",
      "batch 293: loss 0.389037\n",
      "batch 294: loss 0.517556\n",
      "batch 295: loss 0.302482\n",
      "batch 296: loss 0.189868\n",
      "batch 297: loss 0.396580\n",
      "batch 298: loss 0.217572\n",
      "batch 299: loss 0.280075\n",
      "batch 300: loss 0.411861\n",
      "batch 301: loss 0.194347\n",
      "batch 302: loss 0.157477\n",
      "batch 303: loss 0.200695\n",
      "batch 304: loss 0.212443\n",
      "batch 305: loss 0.240730\n",
      "batch 306: loss 0.295195\n",
      "batch 307: loss 0.406676\n",
      "batch 308: loss 0.212255\n",
      "batch 309: loss 0.360117\n",
      "batch 310: loss 0.228627\n",
      "batch 311: loss 0.207296\n",
      "batch 312: loss 0.142424\n",
      "batch 313: loss 0.268343\n",
      "batch 314: loss 0.237308\n",
      "batch 315: loss 0.289460\n",
      "batch 316: loss 0.303796\n",
      "batch 317: loss 0.220824\n",
      "batch 318: loss 0.213275\n",
      "batch 319: loss 0.246066\n",
      "batch 320: loss 0.335618\n",
      "batch 321: loss 0.291521\n",
      "batch 322: loss 0.334310\n",
      "batch 323: loss 0.446926\n",
      "batch 324: loss 0.171458\n",
      "batch 325: loss 0.422111\n",
      "batch 326: loss 0.156345\n",
      "batch 327: loss 0.284695\n",
      "batch 328: loss 0.267974\n",
      "batch 329: loss 0.577840\n",
      "batch 330: loss 0.387926\n",
      "batch 331: loss 0.268040\n",
      "batch 332: loss 0.353480\n",
      "batch 333: loss 0.298518\n",
      "batch 334: loss 0.478521\n",
      "batch 335: loss 0.365600\n",
      "batch 336: loss 0.185804\n",
      "batch 337: loss 0.223569\n",
      "batch 338: loss 0.256348\n",
      "batch 339: loss 0.321289\n",
      "batch 340: loss 0.271853\n",
      "batch 341: loss 0.176548\n",
      "batch 342: loss 0.229647\n",
      "batch 343: loss 0.111074\n",
      "batch 344: loss 0.463467\n",
      "batch 345: loss 0.239988\n",
      "batch 346: loss 0.314291\n",
      "batch 347: loss 0.207193\n",
      "batch 348: loss 0.171432\n",
      "batch 349: loss 0.364189\n",
      "batch 350: loss 0.335221\n",
      "batch 351: loss 0.413151\n",
      "batch 352: loss 0.362950\n",
      "batch 353: loss 0.319661\n",
      "batch 354: loss 0.162014\n",
      "batch 355: loss 0.389689\n",
      "batch 356: loss 0.421089\n",
      "batch 357: loss 0.181052\n",
      "batch 358: loss 0.177759\n",
      "batch 359: loss 0.402913\n",
      "batch 360: loss 0.235380\n",
      "batch 361: loss 0.267268\n",
      "batch 362: loss 0.202916\n",
      "batch 363: loss 0.201494\n",
      "batch 364: loss 0.150469\n",
      "batch 365: loss 0.364969\n",
      "batch 366: loss 0.412862\n",
      "batch 367: loss 0.321997\n",
      "batch 368: loss 0.132545\n",
      "batch 369: loss 0.159412\n",
      "batch 370: loss 0.342442\n",
      "batch 371: loss 0.259415\n",
      "batch 372: loss 0.070327\n",
      "batch 373: loss 0.316670\n",
      "batch 374: loss 0.199430\n",
      "batch 375: loss 0.291386\n",
      "batch 376: loss 0.313575\n",
      "batch 377: loss 0.081056\n",
      "batch 378: loss 0.325014\n",
      "batch 379: loss 0.404023\n",
      "batch 380: loss 0.389470\n",
      "batch 381: loss 0.253171\n",
      "batch 382: loss 0.223153\n",
      "batch 383: loss 0.229689\n",
      "batch 384: loss 0.350770\n",
      "batch 385: loss 0.254723\n",
      "batch 386: loss 0.179526\n",
      "batch 387: loss 0.473149\n",
      "batch 388: loss 0.440840\n",
      "batch 389: loss 0.237252\n",
      "batch 390: loss 0.197012\n",
      "batch 391: loss 0.332625\n",
      "batch 392: loss 0.455114\n",
      "batch 393: loss 0.250911\n",
      "batch 394: loss 0.479606\n",
      "batch 395: loss 0.355097\n",
      "batch 396: loss 0.588226\n",
      "batch 397: loss 0.258520\n",
      "batch 398: loss 0.306099\n",
      "batch 399: loss 0.147707\n",
      "batch 400: loss 0.169863\n",
      "batch 401: loss 0.170929\n",
      "batch 402: loss 0.267700\n",
      "batch 403: loss 0.330947\n",
      "batch 404: loss 0.266987\n",
      "batch 405: loss 0.192440\n",
      "batch 406: loss 0.343603\n",
      "batch 407: loss 0.200144\n",
      "batch 408: loss 0.171768\n",
      "batch 409: loss 0.284261\n",
      "batch 410: loss 0.201596\n",
      "batch 411: loss 0.118803\n",
      "batch 412: loss 0.349311\n",
      "batch 413: loss 0.322410\n",
      "batch 414: loss 0.286590\n",
      "batch 415: loss 0.218352\n",
      "batch 416: loss 0.159007\n",
      "batch 417: loss 0.303618\n",
      "batch 418: loss 0.138437\n",
      "batch 419: loss 0.332913\n",
      "batch 420: loss 0.210851\n",
      "batch 421: loss 0.306345\n",
      "batch 422: loss 0.285776\n",
      "batch 423: loss 0.507604\n",
      "batch 424: loss 0.403712\n",
      "batch 425: loss 0.226156\n",
      "batch 426: loss 0.246216\n",
      "batch 427: loss 0.197353\n",
      "batch 428: loss 0.213131\n",
      "batch 429: loss 0.298204\n",
      "batch 430: loss 0.271106\n",
      "batch 431: loss 0.409738\n",
      "batch 432: loss 0.156217\n",
      "batch 433: loss 0.185648\n",
      "batch 434: loss 0.357938\n",
      "batch 435: loss 0.126928\n",
      "batch 436: loss 0.335029\n",
      "batch 437: loss 0.342921\n",
      "batch 438: loss 0.197034\n",
      "batch 439: loss 0.268930\n",
      "batch 440: loss 0.276491\n",
      "batch 441: loss 0.274351\n",
      "batch 442: loss 0.237839\n",
      "batch 443: loss 0.161867\n",
      "batch 444: loss 0.431481\n",
      "batch 445: loss 0.318385\n",
      "batch 446: loss 0.096307\n",
      "batch 447: loss 0.375171\n",
      "batch 448: loss 0.397831\n",
      "batch 449: loss 0.445601\n",
      "batch 450: loss 0.227258\n",
      "batch 451: loss 0.400308\n",
      "batch 452: loss 0.251131\n",
      "batch 453: loss 0.328621\n",
      "batch 454: loss 0.340671\n",
      "batch 455: loss 0.299543\n",
      "batch 456: loss 0.247674\n",
      "batch 457: loss 0.219753\n",
      "batch 458: loss 0.432150\n",
      "batch 459: loss 0.101117\n",
      "batch 460: loss 0.222552\n",
      "batch 461: loss 0.246256\n",
      "batch 462: loss 0.137580\n",
      "batch 463: loss 0.150216\n",
      "batch 464: loss 0.266098\n",
      "batch 465: loss 0.152606\n",
      "batch 466: loss 0.172253\n",
      "batch 467: loss 0.276848\n",
      "batch 468: loss 0.222936\n",
      "batch 469: loss 0.447961\n",
      "batch 470: loss 0.186578\n",
      "batch 471: loss 0.330791\n",
      "batch 472: loss 0.496173\n",
      "batch 473: loss 0.355145\n",
      "batch 474: loss 0.210110\n",
      "batch 475: loss 0.254539\n",
      "batch 476: loss 0.133599\n",
      "batch 477: loss 0.174432\n",
      "batch 478: loss 0.198371\n",
      "batch 479: loss 0.148955\n",
      "batch 480: loss 0.190068\n",
      "batch 481: loss 0.226166\n",
      "batch 482: loss 0.304002\n",
      "batch 483: loss 0.209559\n",
      "batch 484: loss 0.388254\n",
      "batch 485: loss 0.199749\n",
      "batch 486: loss 0.310077\n",
      "batch 487: loss 0.692423\n",
      "batch 488: loss 0.363514\n",
      "batch 489: loss 0.300715\n",
      "batch 490: loss 0.230611\n",
      "batch 491: loss 0.163196\n",
      "batch 492: loss 0.095125\n",
      "batch 493: loss 0.175935\n",
      "batch 494: loss 0.282566\n",
      "batch 495: loss 0.086311\n",
      "batch 496: loss 0.154789\n",
      "batch 497: loss 0.149378\n",
      "batch 498: loss 0.375296\n",
      "batch 499: loss 0.332906\n",
      "batch 500: loss 0.098054\n",
      "batch 501: loss 0.324982\n",
      "batch 502: loss 0.156018\n",
      "batch 503: loss 0.149343\n",
      "batch 504: loss 0.221093\n",
      "batch 505: loss 0.135403\n",
      "batch 506: loss 0.370418\n",
      "batch 507: loss 0.229524\n",
      "batch 508: loss 0.159202\n",
      "batch 509: loss 0.383838\n",
      "batch 510: loss 0.226361\n",
      "batch 511: loss 0.127674\n",
      "batch 512: loss 0.257506\n",
      "batch 513: loss 0.323373\n",
      "batch 514: loss 0.329182\n",
      "batch 515: loss 0.244790\n",
      "batch 516: loss 0.139769\n",
      "batch 517: loss 0.099394\n",
      "batch 518: loss 0.329889\n",
      "batch 519: loss 0.328298\n",
      "batch 520: loss 0.435600\n",
      "batch 521: loss 0.163262\n",
      "batch 522: loss 0.233294\n",
      "batch 523: loss 0.117601\n",
      "batch 524: loss 0.150298\n",
      "batch 525: loss 0.399950\n",
      "batch 526: loss 0.220615\n",
      "batch 527: loss 0.294963\n",
      "batch 528: loss 0.278380\n",
      "batch 529: loss 0.134269\n",
      "batch 530: loss 0.119274\n",
      "batch 531: loss 0.403507\n",
      "batch 532: loss 0.176568\n",
      "batch 533: loss 0.440408\n",
      "batch 534: loss 0.270867\n",
      "batch 535: loss 0.248501\n",
      "batch 536: loss 0.642812\n",
      "batch 537: loss 0.211954\n",
      "batch 538: loss 0.369788\n",
      "batch 539: loss 0.124490\n",
      "batch 540: loss 0.302076\n",
      "batch 541: loss 0.232399\n",
      "batch 542: loss 0.228947\n",
      "batch 543: loss 0.444461\n",
      "batch 544: loss 0.529427\n",
      "batch 545: loss 0.186108\n",
      "batch 546: loss 0.239489\n",
      "batch 547: loss 0.244953\n",
      "batch 548: loss 0.181797\n",
      "batch 549: loss 0.188976\n",
      "batch 550: loss 0.189450\n",
      "batch 551: loss 0.163070\n",
      "batch 552: loss 0.245811\n",
      "batch 553: loss 0.151188\n",
      "batch 554: loss 0.335199\n",
      "batch 555: loss 0.263940\n",
      "batch 556: loss 0.271129\n",
      "batch 557: loss 0.202406\n",
      "batch 558: loss 0.419538\n",
      "batch 559: loss 0.278002\n",
      "batch 560: loss 0.188402\n",
      "batch 561: loss 0.143863\n",
      "batch 562: loss 0.451175\n",
      "batch 563: loss 0.153855\n",
      "batch 564: loss 0.254996\n",
      "batch 565: loss 0.421723\n",
      "batch 566: loss 0.200114\n",
      "batch 567: loss 0.204463\n",
      "batch 568: loss 0.330874\n",
      "batch 569: loss 0.226188\n",
      "batch 570: loss 0.181282\n",
      "batch 571: loss 0.239751\n",
      "batch 572: loss 0.305427\n",
      "batch 573: loss 0.108541\n",
      "batch 574: loss 0.269573\n",
      "batch 575: loss 0.322800\n",
      "batch 576: loss 0.180970\n",
      "batch 577: loss 0.107506\n",
      "batch 578: loss 0.293277\n",
      "batch 579: loss 0.129323\n",
      "batch 580: loss 0.346278\n",
      "batch 581: loss 0.216237\n",
      "batch 582: loss 0.308874\n",
      "batch 583: loss 0.138837\n",
      "batch 584: loss 0.156226\n",
      "batch 585: loss 0.242788\n",
      "batch 586: loss 0.357992\n",
      "batch 587: loss 0.254993\n",
      "batch 588: loss 0.142026\n",
      "batch 589: loss 0.333713\n",
      "batch 590: loss 0.448854\n",
      "batch 591: loss 0.238323\n",
      "batch 592: loss 0.249784\n",
      "batch 593: loss 0.124006\n",
      "batch 594: loss 0.083847\n",
      "batch 595: loss 0.068844\n",
      "batch 596: loss 0.152750\n",
      "batch 597: loss 0.181854\n",
      "batch 598: loss 0.293189\n",
      "batch 599: loss 0.130568\n",
      "batch 600: loss 0.228575\n",
      "batch 601: loss 0.114651\n",
      "batch 602: loss 0.274828\n",
      "batch 603: loss 0.214390\n",
      "batch 604: loss 0.287496\n",
      "batch 605: loss 0.240209\n",
      "batch 606: loss 0.157249\n",
      "batch 607: loss 0.133174\n",
      "batch 608: loss 0.295633\n",
      "batch 609: loss 0.101599\n",
      "batch 610: loss 0.327761\n",
      "batch 611: loss 0.153859\n",
      "batch 612: loss 0.222140\n",
      "batch 613: loss 0.190587\n",
      "batch 614: loss 0.119984\n",
      "batch 615: loss 0.160714\n",
      "batch 616: loss 0.120944\n",
      "batch 617: loss 0.287635\n",
      "batch 618: loss 0.061606\n",
      "batch 619: loss 0.159002\n",
      "batch 620: loss 0.102159\n",
      "batch 621: loss 0.212164\n",
      "batch 622: loss 0.123733\n",
      "batch 623: loss 0.220980\n",
      "batch 624: loss 0.170258\n",
      "batch 625: loss 0.386752\n",
      "batch 626: loss 0.202990\n",
      "batch 627: loss 0.221710\n",
      "batch 628: loss 0.218060\n",
      "batch 629: loss 0.285306\n",
      "batch 630: loss 0.184506\n",
      "batch 631: loss 0.107576\n",
      "batch 632: loss 0.135285\n",
      "batch 633: loss 0.259310\n",
      "batch 634: loss 0.221828\n",
      "batch 635: loss 0.402952\n",
      "batch 636: loss 0.186237\n",
      "batch 637: loss 0.145068\n",
      "batch 638: loss 0.329077\n",
      "batch 639: loss 0.240307\n",
      "batch 640: loss 0.377551\n",
      "batch 641: loss 0.494494\n",
      "batch 642: loss 0.135959\n",
      "batch 643: loss 0.297693\n",
      "batch 644: loss 0.332268\n",
      "batch 645: loss 0.124169\n",
      "batch 646: loss 0.095379\n",
      "batch 647: loss 0.201203\n",
      "batch 648: loss 0.266056\n",
      "batch 649: loss 0.288723\n",
      "batch 650: loss 0.226291\n",
      "batch 651: loss 0.434054\n",
      "batch 652: loss 0.325442\n",
      "batch 653: loss 0.213596\n",
      "batch 654: loss 0.244598\n",
      "batch 655: loss 0.252400\n",
      "batch 656: loss 0.190792\n",
      "batch 657: loss 0.255896\n",
      "batch 658: loss 0.163001\n",
      "batch 659: loss 0.183375\n",
      "batch 660: loss 0.160560\n",
      "batch 661: loss 0.234111\n",
      "batch 662: loss 0.119940\n",
      "batch 663: loss 0.209808\n",
      "batch 664: loss 0.136872\n",
      "batch 665: loss 0.176688\n",
      "batch 666: loss 0.113685\n",
      "batch 667: loss 0.347155\n",
      "batch 668: loss 0.158519\n",
      "batch 669: loss 0.397002\n",
      "batch 670: loss 0.179305\n",
      "batch 671: loss 0.190632\n",
      "batch 672: loss 0.235130\n",
      "batch 673: loss 0.181187\n",
      "batch 674: loss 0.253867\n",
      "batch 675: loss 0.129148\n",
      "batch 676: loss 0.303930\n",
      "batch 677: loss 0.133495\n",
      "batch 678: loss 0.090633\n",
      "batch 679: loss 0.152214\n",
      "batch 680: loss 0.237603\n",
      "batch 681: loss 0.227588\n",
      "batch 682: loss 0.254605\n",
      "batch 683: loss 0.186847\n",
      "batch 684: loss 0.147803\n",
      "batch 685: loss 0.120886\n",
      "batch 686: loss 0.164892\n",
      "batch 687: loss 0.331868\n",
      "batch 688: loss 0.414535\n",
      "batch 689: loss 0.312438\n",
      "batch 690: loss 0.170866\n",
      "batch 691: loss 0.504608\n",
      "batch 692: loss 0.377827\n",
      "batch 693: loss 0.158408\n",
      "batch 694: loss 0.209521\n",
      "batch 695: loss 0.057885\n",
      "batch 696: loss 0.098620\n",
      "batch 697: loss 0.185616\n",
      "batch 698: loss 0.137314\n",
      "batch 699: loss 0.119743\n",
      "batch 700: loss 0.234409\n",
      "batch 701: loss 0.239075\n",
      "batch 702: loss 0.151472\n",
      "batch 703: loss 0.165083\n",
      "batch 704: loss 0.269955\n",
      "batch 705: loss 0.226257\n",
      "batch 706: loss 0.239466\n",
      "batch 707: loss 0.199373\n",
      "batch 708: loss 0.325505\n",
      "batch 709: loss 0.228041\n",
      "batch 710: loss 0.144823\n",
      "batch 711: loss 0.114232\n",
      "batch 712: loss 0.227160\n",
      "batch 713: loss 0.330252\n",
      "batch 714: loss 0.158552\n",
      "batch 715: loss 0.210313\n",
      "batch 716: loss 0.164293\n",
      "batch 717: loss 0.161685\n",
      "batch 718: loss 0.188547\n",
      "batch 719: loss 0.180156\n",
      "batch 720: loss 0.200851\n",
      "batch 721: loss 0.092565\n",
      "batch 722: loss 0.173485\n",
      "batch 723: loss 0.172144\n",
      "batch 724: loss 0.306569\n",
      "batch 725: loss 0.363967\n",
      "batch 726: loss 0.097801\n",
      "batch 727: loss 0.347186\n",
      "batch 728: loss 0.188027\n",
      "batch 729: loss 0.209128\n",
      "batch 730: loss 0.181954\n",
      "batch 731: loss 0.150047\n",
      "batch 732: loss 0.234956\n",
      "batch 733: loss 0.156357\n",
      "batch 734: loss 0.207043\n",
      "batch 735: loss 0.219058\n",
      "batch 736: loss 0.113917\n",
      "batch 737: loss 0.337811\n",
      "batch 738: loss 0.131980\n",
      "batch 739: loss 0.172769\n",
      "batch 740: loss 0.169920\n",
      "batch 741: loss 0.178208\n",
      "batch 742: loss 0.338216\n",
      "batch 743: loss 0.180800\n",
      "batch 744: loss 0.205118\n",
      "batch 745: loss 0.174190\n",
      "batch 746: loss 0.201298\n",
      "batch 747: loss 0.353466\n",
      "batch 748: loss 0.362657\n",
      "batch 749: loss 0.069622\n",
      "batch 750: loss 0.171295\n",
      "batch 751: loss 0.220336\n",
      "batch 752: loss 0.149348\n",
      "batch 753: loss 0.129534\n",
      "batch 754: loss 0.295249\n",
      "batch 755: loss 0.191030\n",
      "batch 756: loss 0.217733\n",
      "batch 757: loss 0.260932\n",
      "batch 758: loss 0.216347\n",
      "batch 759: loss 0.218694\n",
      "batch 760: loss 0.182442\n",
      "batch 761: loss 0.184780\n",
      "batch 762: loss 0.283169\n",
      "batch 763: loss 0.185836\n",
      "batch 764: loss 0.225887\n",
      "batch 765: loss 0.462201\n",
      "batch 766: loss 0.201778\n",
      "batch 767: loss 0.118126\n",
      "batch 768: loss 0.086200\n",
      "batch 769: loss 0.071274\n",
      "batch 770: loss 0.150370\n",
      "batch 771: loss 0.153042\n",
      "batch 772: loss 0.177931\n",
      "batch 773: loss 0.120760\n",
      "batch 774: loss 0.179441\n",
      "batch 775: loss 0.188710\n",
      "batch 776: loss 0.116437\n",
      "batch 777: loss 0.190658\n",
      "batch 778: loss 0.338074\n",
      "batch 779: loss 0.287869\n",
      "batch 780: loss 0.204810\n",
      "batch 781: loss 0.286212\n",
      "batch 782: loss 0.356835\n",
      "batch 783: loss 0.114364\n",
      "batch 784: loss 0.257239\n",
      "batch 785: loss 0.211892\n",
      "batch 786: loss 0.322811\n",
      "batch 787: loss 0.327907\n",
      "batch 788: loss 0.183872\n",
      "batch 789: loss 0.292791\n",
      "batch 790: loss 0.147020\n",
      "batch 791: loss 0.146361\n",
      "batch 792: loss 0.155734\n",
      "batch 793: loss 0.148340\n",
      "batch 794: loss 0.105872\n",
      "batch 795: loss 0.205811\n",
      "batch 796: loss 0.262269\n",
      "batch 797: loss 0.115890\n",
      "batch 798: loss 0.224688\n",
      "batch 799: loss 0.290177\n",
      "batch 800: loss 0.154820\n",
      "batch 801: loss 0.180000\n",
      "batch 802: loss 0.305846\n",
      "batch 803: loss 0.327215\n",
      "batch 804: loss 0.196993\n",
      "batch 805: loss 0.143069\n",
      "batch 806: loss 0.240165\n",
      "batch 807: loss 0.132887\n",
      "batch 808: loss 0.366762\n",
      "batch 809: loss 0.105375\n",
      "batch 810: loss 0.501361\n",
      "batch 811: loss 0.201997\n",
      "batch 812: loss 0.096392\n",
      "batch 813: loss 0.152439\n",
      "batch 814: loss 0.138672\n",
      "batch 815: loss 0.151600\n",
      "batch 816: loss 0.227888\n",
      "batch 817: loss 0.145324\n",
      "batch 818: loss 0.146025\n",
      "batch 819: loss 0.135243\n",
      "batch 820: loss 0.233483\n",
      "batch 821: loss 0.457414\n",
      "batch 822: loss 0.149514\n",
      "batch 823: loss 0.166615\n",
      "batch 824: loss 0.372353\n",
      "batch 825: loss 0.588749\n",
      "batch 826: loss 0.096479\n",
      "batch 827: loss 0.165670\n",
      "batch 828: loss 0.337628\n",
      "batch 829: loss 0.146481\n",
      "batch 830: loss 0.062156\n",
      "batch 831: loss 0.134446\n",
      "batch 832: loss 0.294032\n",
      "batch 833: loss 0.060535\n",
      "batch 834: loss 0.258834\n",
      "batch 835: loss 0.219695\n",
      "batch 836: loss 0.162427\n",
      "batch 837: loss 0.246701\n",
      "batch 838: loss 0.096755\n",
      "batch 839: loss 0.214149\n",
      "batch 840: loss 0.250912\n",
      "batch 841: loss 0.187933\n",
      "batch 842: loss 0.185414\n",
      "batch 843: loss 0.227188\n",
      "batch 844: loss 0.119188\n",
      "batch 845: loss 0.334929\n",
      "batch 846: loss 0.133930\n",
      "batch 847: loss 0.124146\n",
      "batch 848: loss 0.105841\n",
      "batch 849: loss 0.131862\n",
      "batch 850: loss 0.117265\n",
      "batch 851: loss 0.235734\n",
      "batch 852: loss 0.109177\n",
      "batch 853: loss 0.323216\n",
      "batch 854: loss 0.076868\n",
      "batch 855: loss 0.270427\n",
      "batch 856: loss 0.167292\n",
      "batch 857: loss 0.367964\n",
      "batch 858: loss 0.158193\n",
      "batch 859: loss 0.243538\n",
      "batch 860: loss 0.203438\n",
      "batch 861: loss 0.188599\n",
      "batch 862: loss 0.250619\n",
      "batch 863: loss 0.097269\n",
      "batch 864: loss 0.221504\n",
      "batch 865: loss 0.233273\n",
      "batch 866: loss 0.128052\n",
      "batch 867: loss 0.253130\n",
      "batch 868: loss 0.150896\n",
      "batch 869: loss 0.236543\n",
      "batch 870: loss 0.128203\n",
      "batch 871: loss 0.081954\n",
      "batch 872: loss 0.101310\n",
      "batch 873: loss 0.174750\n",
      "batch 874: loss 0.160408\n",
      "batch 875: loss 0.105250\n",
      "batch 876: loss 0.076193\n",
      "batch 877: loss 0.175928\n",
      "batch 878: loss 0.216347\n",
      "batch 879: loss 0.317106\n",
      "batch 880: loss 0.100854\n",
      "batch 881: loss 0.127127\n",
      "batch 882: loss 0.308445\n",
      "batch 883: loss 0.124931\n",
      "batch 884: loss 0.248890\n",
      "batch 885: loss 0.169293\n",
      "batch 886: loss 0.107638\n",
      "batch 887: loss 0.158109\n",
      "batch 888: loss 0.102283\n",
      "batch 889: loss 0.280424\n",
      "batch 890: loss 0.139364\n",
      "batch 891: loss 0.094142\n",
      "batch 892: loss 0.157169\n",
      "batch 893: loss 0.048151\n",
      "batch 894: loss 0.059561\n",
      "batch 895: loss 0.287735\n",
      "batch 896: loss 0.374580\n",
      "batch 897: loss 0.107784\n",
      "batch 898: loss 0.313108\n",
      "batch 899: loss 0.135252\n",
      "batch 900: loss 0.114187\n",
      "batch 901: loss 0.305683\n",
      "batch 902: loss 0.245307\n",
      "batch 903: loss 0.191814\n",
      "batch 904: loss 0.107314\n",
      "batch 905: loss 0.208177\n",
      "batch 906: loss 0.089450\n",
      "batch 907: loss 0.176495\n",
      "batch 908: loss 0.234527\n",
      "batch 909: loss 0.073686\n",
      "batch 910: loss 0.136289\n",
      "batch 911: loss 0.080171\n",
      "batch 912: loss 0.305031\n",
      "batch 913: loss 0.272383\n",
      "batch 914: loss 0.140583\n",
      "batch 915: loss 0.338411\n",
      "batch 916: loss 0.135546\n",
      "batch 917: loss 0.071687\n",
      "batch 918: loss 0.143426\n",
      "batch 919: loss 0.192598\n",
      "batch 920: loss 0.100333\n",
      "batch 921: loss 0.150586\n",
      "batch 922: loss 0.179805\n",
      "batch 923: loss 0.237417\n",
      "batch 924: loss 0.303762\n",
      "batch 925: loss 0.145758\n",
      "batch 926: loss 0.274656\n",
      "batch 927: loss 0.054583\n",
      "batch 928: loss 0.054210\n",
      "batch 929: loss 0.129085\n",
      "batch 930: loss 0.079100\n",
      "batch 931: loss 0.305413\n",
      "batch 932: loss 0.121410\n",
      "batch 933: loss 0.174353\n",
      "batch 934: loss 0.160843\n",
      "batch 935: loss 0.272624\n",
      "batch 936: loss 0.133957\n",
      "batch 937: loss 0.228590\n",
      "batch 938: loss 0.265474\n",
      "batch 939: loss 0.211100\n",
      "batch 940: loss 0.110170\n",
      "batch 941: loss 0.123010\n",
      "batch 942: loss 0.390093\n",
      "batch 943: loss 0.174213\n",
      "batch 944: loss 0.124961\n",
      "batch 945: loss 0.148612\n",
      "batch 946: loss 0.135782\n",
      "batch 947: loss 0.298315\n",
      "batch 948: loss 0.257022\n",
      "batch 949: loss 0.186655\n",
      "batch 950: loss 0.111080\n",
      "batch 951: loss 0.209432\n",
      "batch 952: loss 0.147841\n",
      "batch 953: loss 0.208873\n",
      "batch 954: loss 0.350158\n",
      "batch 955: loss 0.430361\n",
      "batch 956: loss 0.379979\n",
      "batch 957: loss 0.218984\n",
      "batch 958: loss 0.271433\n",
      "batch 959: loss 0.173331\n",
      "batch 960: loss 0.124364\n",
      "batch 961: loss 0.119645\n",
      "batch 962: loss 0.139107\n",
      "batch 963: loss 0.145757\n",
      "batch 964: loss 0.105806\n",
      "batch 965: loss 0.237184\n",
      "batch 966: loss 0.147279\n",
      "batch 967: loss 0.277448\n",
      "batch 968: loss 0.182009\n",
      "batch 969: loss 0.199019\n",
      "batch 970: loss 0.158343\n",
      "batch 971: loss 0.123158\n",
      "batch 972: loss 0.164376\n",
      "batch 973: loss 0.090123\n",
      "batch 974: loss 0.130950\n",
      "batch 975: loss 0.315210\n",
      "batch 976: loss 0.335807\n",
      "batch 977: loss 0.161216\n",
      "batch 978: loss 0.225412\n",
      "batch 979: loss 0.131215\n",
      "batch 980: loss 0.247282\n",
      "batch 981: loss 0.134753\n",
      "batch 982: loss 0.135581\n",
      "batch 983: loss 0.203192\n",
      "batch 984: loss 0.228613\n",
      "batch 985: loss 0.231663\n",
      "batch 986: loss 0.135012\n",
      "batch 987: loss 0.322604\n",
      "batch 988: loss 0.183648\n",
      "batch 989: loss 0.273781\n",
      "batch 990: loss 0.055497\n",
      "batch 991: loss 0.419740\n",
      "batch 992: loss 0.216128\n",
      "batch 993: loss 0.150260\n",
      "batch 994: loss 0.085838\n",
      "batch 995: loss 0.308117\n",
      "batch 996: loss 0.201595\n",
      "batch 997: loss 0.343333\n",
      "batch 998: loss 0.398500\n",
      "batch 999: loss 0.254225\n",
      "batch 1000: loss 0.086956\n",
      "batch 1001: loss 0.059464\n",
      "batch 1002: loss 0.249137\n",
      "batch 1003: loss 0.188538\n",
      "batch 1004: loss 0.140708\n",
      "batch 1005: loss 0.265630\n",
      "batch 1006: loss 0.256077\n",
      "batch 1007: loss 0.110759\n",
      "batch 1008: loss 0.208575\n",
      "batch 1009: loss 0.207554\n",
      "batch 1010: loss 0.182978\n",
      "batch 1011: loss 0.047142\n",
      "batch 1012: loss 0.234092\n",
      "batch 1013: loss 0.255006\n",
      "batch 1014: loss 0.380593\n",
      "batch 1015: loss 0.382022\n",
      "batch 1016: loss 0.250487\n",
      "batch 1017: loss 0.389435\n",
      "batch 1018: loss 0.138237\n",
      "batch 1019: loss 0.122437\n",
      "batch 1020: loss 0.215960\n",
      "batch 1021: loss 0.144368\n",
      "batch 1022: loss 0.063167\n",
      "batch 1023: loss 0.258749\n",
      "batch 1024: loss 0.215660\n",
      "batch 1025: loss 0.169605\n",
      "batch 1026: loss 0.222371\n",
      "batch 1027: loss 0.160503\n",
      "batch 1028: loss 0.091064\n",
      "batch 1029: loss 0.166862\n",
      "batch 1030: loss 0.256545\n",
      "batch 1031: loss 0.263640\n",
      "batch 1032: loss 0.363329\n",
      "batch 1033: loss 0.132013\n",
      "batch 1034: loss 0.361455\n",
      "batch 1035: loss 0.122579\n",
      "batch 1036: loss 0.255639\n",
      "batch 1037: loss 0.147059\n",
      "batch 1038: loss 0.128041\n",
      "batch 1039: loss 0.097752\n",
      "batch 1040: loss 0.176450\n",
      "batch 1041: loss 0.116697\n",
      "batch 1042: loss 0.073593\n",
      "batch 1043: loss 0.219901\n",
      "batch 1044: loss 0.141889\n",
      "batch 1045: loss 0.219300\n",
      "batch 1046: loss 0.157903\n",
      "batch 1047: loss 0.147873\n",
      "batch 1048: loss 0.132922\n",
      "batch 1049: loss 0.103669\n",
      "batch 1050: loss 0.293736\n",
      "batch 1051: loss 0.195533\n",
      "batch 1052: loss 0.241293\n",
      "batch 1053: loss 0.318838\n",
      "batch 1054: loss 0.238642\n",
      "batch 1055: loss 0.266800\n",
      "batch 1056: loss 0.096591\n",
      "batch 1057: loss 0.108956\n",
      "batch 1058: loss 0.049442\n",
      "batch 1059: loss 0.089660\n",
      "batch 1060: loss 0.059911\n",
      "batch 1061: loss 0.281191\n",
      "batch 1062: loss 0.123201\n",
      "batch 1063: loss 0.113689\n",
      "batch 1064: loss 0.161101\n",
      "batch 1065: loss 0.378393\n",
      "batch 1066: loss 0.163909\n",
      "batch 1067: loss 0.073953\n",
      "batch 1068: loss 0.136903\n",
      "batch 1069: loss 0.148149\n",
      "batch 1070: loss 0.183497\n",
      "batch 1071: loss 0.236094\n",
      "batch 1072: loss 0.101146\n",
      "batch 1073: loss 0.103948\n",
      "batch 1074: loss 0.275163\n",
      "batch 1075: loss 0.185820\n",
      "batch 1076: loss 0.121375\n",
      "batch 1077: loss 0.115727\n",
      "batch 1078: loss 0.130624\n",
      "batch 1079: loss 0.229426\n",
      "batch 1080: loss 0.143067\n",
      "batch 1081: loss 0.097142\n",
      "batch 1082: loss 0.180269\n",
      "batch 1083: loss 0.208798\n",
      "batch 1084: loss 0.340739\n",
      "batch 1085: loss 0.131768\n",
      "batch 1086: loss 0.125420\n",
      "batch 1087: loss 0.152654\n",
      "batch 1088: loss 0.141136\n",
      "batch 1089: loss 0.100431\n",
      "batch 1090: loss 0.135799\n",
      "batch 1091: loss 0.379679\n",
      "batch 1092: loss 0.078721\n",
      "batch 1093: loss 0.391473\n",
      "batch 1094: loss 0.553992\n",
      "batch 1095: loss 0.139589\n",
      "batch 1096: loss 0.083935\n",
      "batch 1097: loss 0.181077\n",
      "batch 1098: loss 0.142036\n",
      "batch 1099: loss 0.026884\n",
      "batch 1100: loss 0.202918\n",
      "batch 1101: loss 0.113825\n",
      "batch 1102: loss 0.100030\n",
      "batch 1103: loss 0.161295\n",
      "batch 1104: loss 0.096025\n",
      "batch 1105: loss 0.133122\n",
      "batch 1106: loss 0.105768\n",
      "batch 1107: loss 0.199275\n",
      "batch 1108: loss 0.092459\n",
      "batch 1109: loss 0.128206\n",
      "batch 1110: loss 0.271589\n",
      "batch 1111: loss 0.180427\n",
      "batch 1112: loss 0.069741\n",
      "batch 1113: loss 0.122419\n",
      "batch 1114: loss 0.099530\n",
      "batch 1115: loss 0.063315\n",
      "batch 1116: loss 0.298018\n",
      "batch 1117: loss 0.130231\n",
      "batch 1118: loss 0.133063\n",
      "batch 1119: loss 0.135472\n",
      "batch 1120: loss 0.121924\n",
      "batch 1121: loss 0.171091\n",
      "batch 1122: loss 0.279224\n",
      "batch 1123: loss 0.307852\n",
      "batch 1124: loss 0.127327\n",
      "batch 1125: loss 0.093573\n",
      "batch 1126: loss 0.071929\n",
      "batch 1127: loss 0.072314\n",
      "batch 1128: loss 0.297164\n",
      "batch 1129: loss 0.141945\n",
      "batch 1130: loss 0.332947\n",
      "batch 1131: loss 0.064779\n",
      "batch 1132: loss 0.188216\n",
      "batch 1133: loss 0.088020\n",
      "batch 1134: loss 0.089753\n",
      "batch 1135: loss 0.226469\n",
      "batch 1136: loss 0.177748\n",
      "batch 1137: loss 0.070747\n",
      "batch 1138: loss 0.065446\n",
      "batch 1139: loss 0.173488\n",
      "batch 1140: loss 0.385899\n",
      "batch 1141: loss 0.221569\n",
      "batch 1142: loss 0.156759\n",
      "batch 1143: loss 0.112594\n",
      "batch 1144: loss 0.422016\n",
      "batch 1145: loss 0.319304\n",
      "batch 1146: loss 0.182611\n",
      "batch 1147: loss 0.133673\n",
      "batch 1148: loss 0.203741\n",
      "batch 1149: loss 0.126668\n",
      "batch 1150: loss 0.119662\n",
      "batch 1151: loss 0.186640\n",
      "batch 1152: loss 0.139905\n",
      "batch 1153: loss 0.219523\n",
      "batch 1154: loss 0.184631\n",
      "batch 1155: loss 0.204487\n",
      "batch 1156: loss 0.076739\n",
      "batch 1157: loss 0.151207\n",
      "batch 1158: loss 0.135014\n",
      "batch 1159: loss 0.119042\n",
      "batch 1160: loss 0.118406\n",
      "batch 1161: loss 0.351821\n",
      "batch 1162: loss 0.061940\n",
      "batch 1163: loss 0.253970\n",
      "batch 1164: loss 0.167846\n",
      "batch 1165: loss 0.139168\n",
      "batch 1166: loss 0.247836\n",
      "batch 1167: loss 0.057595\n",
      "batch 1168: loss 0.129493\n",
      "batch 1169: loss 0.215815\n",
      "batch 1170: loss 0.223963\n",
      "batch 1171: loss 0.339548\n",
      "batch 1172: loss 0.297872\n",
      "batch 1173: loss 0.327555\n",
      "batch 1174: loss 0.433832\n",
      "batch 1175: loss 0.069864\n",
      "batch 1176: loss 0.094290\n",
      "batch 1177: loss 0.125915\n",
      "batch 1178: loss 0.238062\n",
      "batch 1179: loss 0.148865\n",
      "batch 1180: loss 0.152390\n",
      "batch 1181: loss 0.321877\n",
      "batch 1182: loss 0.159312\n",
      "batch 1183: loss 0.121863\n",
      "batch 1184: loss 0.126018\n",
      "batch 1185: loss 0.298994\n",
      "batch 1186: loss 0.197636\n",
      "batch 1187: loss 0.304063\n",
      "batch 1188: loss 0.212336\n",
      "batch 1189: loss 0.087733\n",
      "batch 1190: loss 0.193774\n",
      "batch 1191: loss 0.048554\n",
      "batch 1192: loss 0.204662\n",
      "batch 1193: loss 0.137300\n",
      "batch 1194: loss 0.127973\n",
      "batch 1195: loss 0.056515\n",
      "batch 1196: loss 0.170080\n",
      "batch 1197: loss 0.178005\n",
      "batch 1198: loss 0.201939\n",
      "batch 1199: loss 0.158659\n",
      "batch 1200: loss 0.057527\n",
      "batch 1201: loss 0.066631\n",
      "batch 1202: loss 0.239361\n",
      "batch 1203: loss 0.295863\n",
      "batch 1204: loss 0.202713\n",
      "batch 1205: loss 0.175453\n",
      "batch 1206: loss 0.151113\n",
      "batch 1207: loss 0.111702\n",
      "batch 1208: loss 0.115063\n",
      "batch 1209: loss 0.405141\n",
      "batch 1210: loss 0.194995\n",
      "batch 1211: loss 0.108887\n",
      "batch 1212: loss 0.110585\n",
      "batch 1213: loss 0.178238\n",
      "batch 1214: loss 0.456279\n",
      "batch 1215: loss 0.215396\n",
      "batch 1216: loss 0.375919\n",
      "batch 1217: loss 0.292410\n",
      "batch 1218: loss 0.233430\n",
      "batch 1219: loss 0.082915\n",
      "batch 1220: loss 0.044667\n",
      "batch 1221: loss 0.205689\n",
      "batch 1222: loss 0.153146\n",
      "batch 1223: loss 0.102365\n",
      "batch 1224: loss 0.178039\n",
      "batch 1225: loss 0.204808\n",
      "batch 1226: loss 0.068649\n",
      "batch 1227: loss 0.122761\n",
      "batch 1228: loss 0.168883\n",
      "batch 1229: loss 0.215185\n",
      "batch 1230: loss 0.059585\n",
      "batch 1231: loss 0.099353\n",
      "batch 1232: loss 0.044335\n",
      "batch 1233: loss 0.235951\n",
      "batch 1234: loss 0.119594\n",
      "batch 1235: loss 0.209500\n",
      "batch 1236: loss 0.259497\n",
      "batch 1237: loss 0.183863\n",
      "batch 1238: loss 0.147382\n",
      "batch 1239: loss 0.106911\n",
      "batch 1240: loss 0.143807\n",
      "batch 1241: loss 0.099386\n",
      "batch 1242: loss 0.070967\n",
      "batch 1243: loss 0.061872\n",
      "batch 1244: loss 0.241676\n",
      "batch 1245: loss 0.119739\n",
      "batch 1246: loss 0.078217\n",
      "batch 1247: loss 0.121922\n",
      "batch 1248: loss 0.160528\n",
      "batch 1249: loss 0.079236\n",
      "batch 1250: loss 0.188721\n",
      "batch 1251: loss 0.198645\n",
      "batch 1252: loss 0.216188\n",
      "batch 1253: loss 0.114762\n",
      "batch 1254: loss 0.314956\n",
      "batch 1255: loss 0.084592\n",
      "batch 1256: loss 0.187403\n",
      "batch 1257: loss 0.129780\n",
      "batch 1258: loss 0.185557\n",
      "batch 1259: loss 0.148457\n",
      "batch 1260: loss 0.072056\n",
      "batch 1261: loss 0.109900\n",
      "batch 1262: loss 0.136295\n",
      "batch 1263: loss 0.101410\n",
      "batch 1264: loss 0.060827\n",
      "batch 1265: loss 0.246105\n",
      "batch 1266: loss 0.103243\n",
      "batch 1267: loss 0.180316\n",
      "batch 1268: loss 0.276934\n",
      "batch 1269: loss 0.241241\n",
      "batch 1270: loss 0.101124\n",
      "batch 1271: loss 0.202732\n",
      "batch 1272: loss 0.207178\n",
      "batch 1273: loss 0.192073\n",
      "batch 1274: loss 0.119625\n",
      "batch 1275: loss 0.090027\n",
      "batch 1276: loss 0.181500\n",
      "batch 1277: loss 0.077355\n",
      "batch 1278: loss 0.099186\n",
      "batch 1279: loss 0.076298\n",
      "batch 1280: loss 0.323314\n",
      "batch 1281: loss 0.222952\n",
      "batch 1282: loss 0.090059\n",
      "batch 1283: loss 0.149054\n",
      "batch 1284: loss 0.222186\n",
      "batch 1285: loss 0.230546\n",
      "batch 1286: loss 0.179495\n",
      "batch 1287: loss 0.126828\n",
      "batch 1288: loss 0.042617\n",
      "batch 1289: loss 0.199431\n",
      "batch 1290: loss 0.034311\n",
      "batch 1291: loss 0.162598\n",
      "batch 1292: loss 0.104663\n",
      "batch 1293: loss 0.103817\n",
      "batch 1294: loss 0.149288\n",
      "batch 1295: loss 0.164269\n",
      "batch 1296: loss 0.191383\n",
      "batch 1297: loss 0.179974\n",
      "batch 1298: loss 0.217316\n",
      "batch 1299: loss 0.226904\n",
      "batch 1300: loss 0.233357\n",
      "batch 1301: loss 0.120341\n",
      "batch 1302: loss 0.246057\n",
      "batch 1303: loss 0.212662\n",
      "batch 1304: loss 0.039704\n",
      "batch 1305: loss 0.087358\n",
      "batch 1306: loss 0.102482\n",
      "batch 1307: loss 0.050334\n",
      "batch 1308: loss 0.109127\n",
      "batch 1309: loss 0.076433\n",
      "batch 1310: loss 0.224881\n",
      "batch 1311: loss 0.155667\n",
      "batch 1312: loss 0.290537\n",
      "batch 1313: loss 0.170355\n",
      "batch 1314: loss 0.078326\n",
      "batch 1315: loss 0.116402\n",
      "batch 1316: loss 0.094977\n",
      "batch 1317: loss 0.080414\n",
      "batch 1318: loss 0.182958\n",
      "batch 1319: loss 0.084502\n",
      "batch 1320: loss 0.144475\n",
      "batch 1321: loss 0.314457\n",
      "batch 1322: loss 0.074945\n",
      "batch 1323: loss 0.129656\n",
      "batch 1324: loss 0.202856\n",
      "batch 1325: loss 0.085085\n",
      "batch 1326: loss 0.159788\n",
      "batch 1327: loss 0.088743\n",
      "batch 1328: loss 0.148562\n",
      "batch 1329: loss 0.061326\n",
      "batch 1330: loss 0.067049\n",
      "batch 1331: loss 0.079137\n",
      "batch 1332: loss 0.149813\n",
      "batch 1333: loss 0.156012\n",
      "batch 1334: loss 0.106383\n",
      "batch 1335: loss 0.195407\n",
      "batch 1336: loss 0.117331\n",
      "batch 1337: loss 0.144202\n",
      "batch 1338: loss 0.035008\n",
      "batch 1339: loss 0.151514\n",
      "batch 1340: loss 0.275237\n",
      "batch 1341: loss 0.108586\n",
      "batch 1342: loss 0.285805\n",
      "batch 1343: loss 0.089338\n",
      "batch 1344: loss 0.090068\n",
      "batch 1345: loss 0.173817\n",
      "batch 1346: loss 0.158978\n",
      "batch 1347: loss 0.072520\n",
      "batch 1348: loss 0.238436\n",
      "batch 1349: loss 0.071986\n",
      "batch 1350: loss 0.133349\n",
      "batch 1351: loss 0.158019\n",
      "batch 1352: loss 0.383180\n",
      "batch 1353: loss 0.181066\n",
      "batch 1354: loss 0.088203\n",
      "batch 1355: loss 0.114737\n",
      "batch 1356: loss 0.060488\n",
      "batch 1357: loss 0.072827\n",
      "batch 1358: loss 0.155710\n",
      "batch 1359: loss 0.329212\n",
      "batch 1360: loss 0.365677\n",
      "batch 1361: loss 0.172669\n",
      "batch 1362: loss 0.208262\n",
      "batch 1363: loss 0.101943\n",
      "batch 1364: loss 0.157510\n",
      "batch 1365: loss 0.083603\n",
      "batch 1366: loss 0.087421\n",
      "batch 1367: loss 0.282993\n",
      "batch 1368: loss 0.131696\n",
      "batch 1369: loss 0.049725\n",
      "batch 1370: loss 0.205607\n",
      "batch 1371: loss 0.139240\n",
      "batch 1372: loss 0.067435\n",
      "batch 1373: loss 0.190844\n",
      "batch 1374: loss 0.151582\n",
      "batch 1375: loss 0.123935\n",
      "batch 1376: loss 0.187806\n",
      "batch 1377: loss 0.154925\n",
      "batch 1378: loss 0.144847\n",
      "batch 1379: loss 0.123899\n",
      "batch 1380: loss 0.058784\n",
      "batch 1381: loss 0.095483\n",
      "batch 1382: loss 0.213942\n",
      "batch 1383: loss 0.044768\n",
      "batch 1384: loss 0.026207\n",
      "batch 1385: loss 0.131318\n",
      "batch 1386: loss 0.113887\n",
      "batch 1387: loss 0.161639\n",
      "batch 1388: loss 0.358534\n",
      "batch 1389: loss 0.106709\n",
      "batch 1390: loss 0.124312\n",
      "batch 1391: loss 0.167660\n",
      "batch 1392: loss 0.161695\n",
      "batch 1393: loss 0.090013\n",
      "batch 1394: loss 0.171644\n",
      "batch 1395: loss 0.206010\n",
      "batch 1396: loss 0.151351\n",
      "batch 1397: loss 0.108932\n",
      "batch 1398: loss 0.093417\n",
      "batch 1399: loss 0.043502\n",
      "batch 1400: loss 0.135936\n",
      "batch 1401: loss 0.027241\n",
      "batch 1402: loss 0.147960\n",
      "batch 1403: loss 0.227250\n",
      "batch 1404: loss 0.060430\n",
      "batch 1405: loss 0.113846\n",
      "batch 1406: loss 0.271906\n",
      "batch 1407: loss 0.223470\n",
      "batch 1408: loss 0.126127\n",
      "batch 1409: loss 0.118032\n",
      "batch 1410: loss 0.153849\n",
      "batch 1411: loss 0.067678\n",
      "batch 1412: loss 0.353581\n",
      "batch 1413: loss 0.134555\n",
      "batch 1414: loss 0.085473\n",
      "batch 1415: loss 0.101222\n",
      "batch 1416: loss 0.265397\n",
      "batch 1417: loss 0.121898\n",
      "batch 1418: loss 0.167279\n",
      "batch 1419: loss 0.161637\n",
      "batch 1420: loss 0.064142\n",
      "batch 1421: loss 0.194803\n",
      "batch 1422: loss 0.244527\n",
      "batch 1423: loss 0.208915\n",
      "batch 1424: loss 0.158811\n",
      "batch 1425: loss 0.161438\n",
      "batch 1426: loss 0.148854\n",
      "batch 1427: loss 0.068200\n",
      "batch 1428: loss 0.140407\n",
      "batch 1429: loss 0.041441\n",
      "batch 1430: loss 0.087957\n",
      "batch 1431: loss 0.263506\n",
      "batch 1432: loss 0.136997\n",
      "batch 1433: loss 0.036348\n",
      "batch 1434: loss 0.171637\n",
      "batch 1435: loss 0.170839\n",
      "batch 1436: loss 0.040981\n",
      "batch 1437: loss 0.141913\n",
      "batch 1438: loss 0.058457\n",
      "batch 1439: loss 0.111420\n",
      "batch 1440: loss 0.072916\n",
      "batch 1441: loss 0.134955\n",
      "batch 1442: loss 0.349068\n",
      "batch 1443: loss 0.403454\n",
      "batch 1444: loss 0.046174\n",
      "batch 1445: loss 0.140343\n",
      "batch 1446: loss 0.361651\n",
      "batch 1447: loss 0.073325\n",
      "batch 1448: loss 0.201574\n",
      "batch 1449: loss 0.282763\n",
      "batch 1450: loss 0.166776\n",
      "batch 1451: loss 0.049856\n",
      "batch 1452: loss 0.442807\n",
      "batch 1453: loss 0.056928\n",
      "batch 1454: loss 0.193937\n",
      "batch 1455: loss 0.186638\n",
      "batch 1456: loss 0.212456\n",
      "batch 1457: loss 0.132587\n",
      "batch 1458: loss 0.061240\n",
      "batch 1459: loss 0.125790\n",
      "batch 1460: loss 0.086778\n",
      "batch 1461: loss 0.223342\n",
      "batch 1462: loss 0.073102\n",
      "batch 1463: loss 0.172625\n",
      "batch 1464: loss 0.049398\n",
      "batch 1465: loss 0.056480\n",
      "batch 1466: loss 0.175554\n",
      "batch 1467: loss 0.096673\n",
      "batch 1468: loss 0.138041\n",
      "batch 1469: loss 0.271026\n",
      "batch 1470: loss 0.184490\n",
      "batch 1471: loss 0.334884\n",
      "batch 1472: loss 0.227595\n",
      "batch 1473: loss 0.195948\n",
      "batch 1474: loss 0.104903\n",
      "batch 1475: loss 0.132554\n",
      "batch 1476: loss 0.074199\n",
      "batch 1477: loss 0.083951\n",
      "batch 1478: loss 0.085383\n",
      "batch 1479: loss 0.110166\n",
      "batch 1480: loss 0.085300\n",
      "batch 1481: loss 0.223421\n",
      "batch 1482: loss 0.054771\n",
      "batch 1483: loss 0.200337\n",
      "batch 1484: loss 0.050381\n",
      "batch 1485: loss 0.074962\n",
      "batch 1486: loss 0.246032\n",
      "batch 1487: loss 0.073304\n",
      "batch 1488: loss 0.113620\n",
      "batch 1489: loss 0.111328\n",
      "batch 1490: loss 0.114153\n",
      "batch 1491: loss 0.176752\n",
      "batch 1492: loss 0.056558\n",
      "batch 1493: loss 0.127653\n",
      "batch 1494: loss 0.204782\n",
      "batch 1495: loss 0.098405\n",
      "batch 1496: loss 0.139801\n",
      "batch 1497: loss 0.171365\n",
      "batch 1498: loss 0.065936\n",
      "batch 1499: loss 0.193868\n",
      "batch 1500: loss 0.067943\n",
      "batch 1501: loss 0.373573\n",
      "batch 1502: loss 0.083531\n",
      "batch 1503: loss 0.169613\n",
      "batch 1504: loss 0.031984\n",
      "batch 1505: loss 0.128734\n",
      "batch 1506: loss 0.067587\n",
      "batch 1507: loss 0.160154\n",
      "batch 1508: loss 0.166314\n",
      "batch 1509: loss 0.126860\n",
      "batch 1510: loss 0.244981\n",
      "batch 1511: loss 0.067589\n",
      "batch 1512: loss 0.177220\n",
      "batch 1513: loss 0.242172\n",
      "batch 1514: loss 0.105581\n",
      "batch 1515: loss 0.098557\n",
      "batch 1516: loss 0.032413\n",
      "batch 1517: loss 0.295351\n",
      "batch 1518: loss 0.332770\n",
      "batch 1519: loss 0.106635\n",
      "batch 1520: loss 0.123111\n",
      "batch 1521: loss 0.223616\n",
      "batch 1522: loss 0.166255\n",
      "batch 1523: loss 0.135530\n",
      "batch 1524: loss 0.169617\n",
      "batch 1525: loss 0.319859\n",
      "batch 1526: loss 0.260895\n",
      "batch 1527: loss 0.117953\n",
      "batch 1528: loss 0.169725\n",
      "batch 1529: loss 0.051938\n",
      "batch 1530: loss 0.142080\n",
      "batch 1531: loss 0.070138\n",
      "batch 1532: loss 0.129309\n",
      "batch 1533: loss 0.065802\n",
      "batch 1534: loss 0.310964\n",
      "batch 1535: loss 0.124325\n",
      "batch 1536: loss 0.281955\n",
      "batch 1537: loss 0.205220\n",
      "batch 1538: loss 0.105222\n",
      "batch 1539: loss 0.061550\n",
      "batch 1540: loss 0.094480\n",
      "batch 1541: loss 0.072762\n",
      "batch 1542: loss 0.227720\n",
      "batch 1543: loss 0.101869\n",
      "batch 1544: loss 0.149875\n",
      "batch 1545: loss 0.045095\n",
      "batch 1546: loss 0.124846\n",
      "batch 1547: loss 0.071393\n",
      "batch 1548: loss 0.263223\n",
      "batch 1549: loss 0.066497\n",
      "batch 1550: loss 0.018484\n",
      "batch 1551: loss 0.162232\n",
      "batch 1552: loss 0.073881\n",
      "batch 1553: loss 0.086745\n",
      "batch 1554: loss 0.250906\n",
      "batch 1555: loss 0.316796\n",
      "batch 1556: loss 0.170762\n",
      "batch 1557: loss 0.070687\n",
      "batch 1558: loss 0.226285\n",
      "batch 1559: loss 0.042845\n",
      "batch 1560: loss 0.272982\n",
      "batch 1561: loss 0.175275\n",
      "batch 1562: loss 0.203419\n",
      "batch 1563: loss 0.046091\n",
      "batch 1564: loss 0.085855\n",
      "batch 1565: loss 0.279768\n",
      "batch 1566: loss 0.267686\n",
      "batch 1567: loss 0.098631\n",
      "batch 1568: loss 0.323532\n",
      "batch 1569: loss 0.316258\n",
      "batch 1570: loss 0.128388\n",
      "batch 1571: loss 0.156156\n",
      "batch 1572: loss 0.067399\n",
      "batch 1573: loss 0.084954\n",
      "batch 1574: loss 0.050930\n",
      "batch 1575: loss 0.052628\n",
      "batch 1576: loss 0.252350\n",
      "batch 1577: loss 0.240127\n",
      "batch 1578: loss 0.116356\n",
      "batch 1579: loss 0.059999\n",
      "batch 1580: loss 0.059138\n",
      "batch 1581: loss 0.075477\n",
      "batch 1582: loss 0.156270\n",
      "batch 1583: loss 0.130352\n",
      "batch 1584: loss 0.166613\n",
      "batch 1585: loss 0.177924\n",
      "batch 1586: loss 0.167287\n",
      "batch 1587: loss 0.078113\n",
      "batch 1588: loss 0.132710\n",
      "batch 1589: loss 0.065202\n",
      "batch 1590: loss 0.150624\n",
      "batch 1591: loss 0.138538\n",
      "batch 1592: loss 0.026458\n",
      "batch 1593: loss 0.135037\n",
      "batch 1594: loss 0.145239\n",
      "batch 1595: loss 0.199954\n",
      "batch 1596: loss 0.106114\n",
      "batch 1597: loss 0.166718\n",
      "batch 1598: loss 0.033807\n",
      "batch 1599: loss 0.135695\n",
      "batch 1600: loss 0.105491\n",
      "batch 1601: loss 0.023846\n",
      "batch 1602: loss 0.122538\n",
      "batch 1603: loss 0.282346\n",
      "batch 1604: loss 0.222211\n",
      "batch 1605: loss 0.149137\n",
      "batch 1606: loss 0.215130\n",
      "batch 1607: loss 0.111519\n",
      "batch 1608: loss 0.142803\n",
      "batch 1609: loss 0.091796\n",
      "batch 1610: loss 0.056376\n",
      "batch 1611: loss 0.076025\n",
      "batch 1612: loss 0.158699\n",
      "batch 1613: loss 0.223542\n",
      "batch 1614: loss 0.299938\n",
      "batch 1615: loss 0.051778\n",
      "batch 1616: loss 0.326036\n",
      "batch 1617: loss 0.112040\n",
      "batch 1618: loss 0.182789\n",
      "batch 1619: loss 0.078892\n",
      "batch 1620: loss 0.060284\n",
      "batch 1621: loss 0.043222\n",
      "batch 1622: loss 0.205435\n",
      "batch 1623: loss 0.199029\n",
      "batch 1624: loss 0.188738\n",
      "batch 1625: loss 0.092539\n",
      "batch 1626: loss 0.130759\n",
      "batch 1627: loss 0.137500\n",
      "batch 1628: loss 0.060705\n",
      "batch 1629: loss 0.089530\n",
      "batch 1630: loss 0.100268\n",
      "batch 1631: loss 0.034952\n",
      "batch 1632: loss 0.134042\n",
      "batch 1633: loss 0.043620\n",
      "batch 1634: loss 0.110084\n",
      "batch 1635: loss 0.083792\n",
      "batch 1636: loss 0.264239\n",
      "batch 1637: loss 0.044856\n",
      "batch 1638: loss 0.223906\n",
      "batch 1639: loss 0.299948\n",
      "batch 1640: loss 0.190232\n",
      "batch 1641: loss 0.135617\n",
      "batch 1642: loss 0.094353\n",
      "batch 1643: loss 0.105740\n",
      "batch 1644: loss 0.088110\n",
      "batch 1645: loss 0.138510\n",
      "batch 1646: loss 0.116407\n",
      "batch 1647: loss 0.101016\n",
      "batch 1648: loss 0.197392\n",
      "batch 1649: loss 0.179140\n",
      "batch 1650: loss 0.133098\n",
      "batch 1651: loss 0.170886\n",
      "batch 1652: loss 0.312445\n",
      "batch 1653: loss 0.090581\n",
      "batch 1654: loss 0.173874\n",
      "batch 1655: loss 0.170793\n",
      "batch 1656: loss 0.071192\n",
      "batch 1657: loss 0.070332\n",
      "batch 1658: loss 0.140612\n",
      "batch 1659: loss 0.188475\n",
      "batch 1660: loss 0.116071\n",
      "batch 1661: loss 0.076099\n",
      "batch 1662: loss 0.120539\n",
      "batch 1663: loss 0.090774\n",
      "batch 1664: loss 0.135504\n",
      "batch 1665: loss 0.183301\n",
      "batch 1666: loss 0.180372\n",
      "batch 1667: loss 0.146037\n",
      "batch 1668: loss 0.188491\n",
      "batch 1669: loss 0.160445\n",
      "batch 1670: loss 0.143845\n",
      "batch 1671: loss 0.087139\n",
      "batch 1672: loss 0.040511\n",
      "batch 1673: loss 0.074215\n",
      "batch 1674: loss 0.263080\n",
      "batch 1675: loss 0.045759\n",
      "batch 1676: loss 0.369232\n",
      "batch 1677: loss 0.090095\n",
      "batch 1678: loss 0.137385\n",
      "batch 1679: loss 0.200896\n",
      "batch 1680: loss 0.084518\n",
      "batch 1681: loss 0.089530\n",
      "batch 1682: loss 0.038353\n",
      "batch 1683: loss 0.066038\n",
      "batch 1684: loss 0.366885\n",
      "batch 1685: loss 0.081251\n",
      "batch 1686: loss 0.229301\n",
      "batch 1687: loss 0.089203\n",
      "batch 1688: loss 0.147315\n",
      "batch 1689: loss 0.111134\n",
      "batch 1690: loss 0.105883\n",
      "batch 1691: loss 0.171984\n",
      "batch 1692: loss 0.041543\n",
      "batch 1693: loss 0.129988\n",
      "batch 1694: loss 0.076774\n",
      "batch 1695: loss 0.103276\n",
      "batch 1696: loss 0.034778\n",
      "batch 1697: loss 0.216547\n",
      "batch 1698: loss 0.096075\n",
      "batch 1699: loss 0.056325\n",
      "batch 1700: loss 0.179158\n",
      "batch 1701: loss 0.034523\n",
      "batch 1702: loss 0.102419\n",
      "batch 1703: loss 0.208498\n",
      "batch 1704: loss 0.218125\n",
      "batch 1705: loss 0.313097\n",
      "batch 1706: loss 0.070261\n",
      "batch 1707: loss 0.096690\n",
      "batch 1708: loss 0.172761\n",
      "batch 1709: loss 0.161449\n",
      "batch 1710: loss 0.112637\n",
      "batch 1711: loss 0.035839\n",
      "batch 1712: loss 0.056868\n",
      "batch 1713: loss 0.399204\n",
      "batch 1714: loss 0.109838\n",
      "batch 1715: loss 0.107315\n",
      "batch 1716: loss 0.159676\n",
      "batch 1717: loss 0.257750\n",
      "batch 1718: loss 0.136556\n",
      "batch 1719: loss 0.134750\n",
      "batch 1720: loss 0.224041\n",
      "batch 1721: loss 0.250269\n",
      "batch 1722: loss 0.218350\n",
      "batch 1723: loss 0.140447\n",
      "batch 1724: loss 0.192994\n",
      "batch 1725: loss 0.087426\n",
      "batch 1726: loss 0.090143\n",
      "batch 1727: loss 0.078850\n",
      "batch 1728: loss 0.142503\n",
      "batch 1729: loss 0.119079\n",
      "batch 1730: loss 0.116794\n",
      "batch 1731: loss 0.062663\n",
      "batch 1732: loss 0.099542\n",
      "batch 1733: loss 0.130488\n",
      "batch 1734: loss 0.048341\n",
      "batch 1735: loss 0.107689\n",
      "batch 1736: loss 0.161244\n",
      "batch 1737: loss 0.178909\n",
      "batch 1738: loss 0.190889\n",
      "batch 1739: loss 0.078625\n",
      "batch 1740: loss 0.118031\n",
      "batch 1741: loss 0.117682\n",
      "batch 1742: loss 0.074719\n",
      "batch 1743: loss 0.101574\n",
      "batch 1744: loss 0.105531\n",
      "batch 1745: loss 0.082940\n",
      "batch 1746: loss 0.097528\n",
      "batch 1747: loss 0.127166\n",
      "batch 1748: loss 0.372057\n",
      "batch 1749: loss 0.037591\n",
      "batch 1750: loss 0.135776\n",
      "batch 1751: loss 0.106666\n",
      "batch 1752: loss 0.062776\n",
      "batch 1753: loss 0.163271\n",
      "batch 1754: loss 0.054711\n",
      "batch 1755: loss 0.181468\n",
      "batch 1756: loss 0.118719\n",
      "batch 1757: loss 0.096474\n",
      "batch 1758: loss 0.177636\n",
      "batch 1759: loss 0.117505\n",
      "batch 1760: loss 0.070871\n",
      "batch 1761: loss 0.070299\n",
      "batch 1762: loss 0.093885\n",
      "batch 1763: loss 0.229198\n",
      "batch 1764: loss 0.164013\n",
      "batch 1765: loss 0.050751\n",
      "batch 1766: loss 0.070767\n",
      "batch 1767: loss 0.158210\n",
      "batch 1768: loss 0.053186\n",
      "batch 1769: loss 0.177763\n",
      "batch 1770: loss 0.091989\n",
      "batch 1771: loss 0.124035\n",
      "batch 1772: loss 0.156193\n",
      "batch 1773: loss 0.152763\n",
      "batch 1774: loss 0.058325\n",
      "batch 1775: loss 0.252223\n",
      "batch 1776: loss 0.165917\n",
      "batch 1777: loss 0.156356\n",
      "batch 1778: loss 0.067649\n",
      "batch 1779: loss 0.056683\n",
      "batch 1780: loss 0.113961\n",
      "batch 1781: loss 0.130950\n",
      "batch 1782: loss 0.074563\n",
      "batch 1783: loss 0.090217\n",
      "batch 1784: loss 0.347535\n",
      "batch 1785: loss 0.217289\n",
      "batch 1786: loss 0.052428\n",
      "batch 1787: loss 0.073071\n",
      "batch 1788: loss 0.045778\n",
      "batch 1789: loss 0.143138\n",
      "batch 1790: loss 0.283140\n",
      "batch 1791: loss 0.165144\n",
      "batch 1792: loss 0.160652\n",
      "batch 1793: loss 0.179779\n",
      "batch 1794: loss 0.209323\n",
      "batch 1795: loss 0.185784\n",
      "batch 1796: loss 0.046738\n",
      "batch 1797: loss 0.084297\n",
      "batch 1798: loss 0.073651\n",
      "batch 1799: loss 0.059147\n",
      "batch 1800: loss 0.108352\n",
      "batch 1801: loss 0.199218\n",
      "batch 1802: loss 0.164189\n",
      "batch 1803: loss 0.052120\n",
      "batch 1804: loss 0.041858\n",
      "batch 1805: loss 0.040791\n",
      "batch 1806: loss 0.264792\n",
      "batch 1807: loss 0.039177\n",
      "batch 1808: loss 0.012181\n",
      "batch 1809: loss 0.095402\n",
      "batch 1810: loss 0.081484\n",
      "batch 1811: loss 0.060052\n",
      "batch 1812: loss 0.042358\n",
      "batch 1813: loss 0.214642\n",
      "batch 1814: loss 0.069693\n",
      "batch 1815: loss 0.106516\n",
      "batch 1816: loss 0.118471\n",
      "batch 1817: loss 0.179463\n",
      "batch 1818: loss 0.122413\n",
      "batch 1819: loss 0.051865\n",
      "batch 1820: loss 0.080972\n",
      "batch 1821: loss 0.075685\n",
      "batch 1822: loss 0.056151\n",
      "batch 1823: loss 0.074795\n",
      "batch 1824: loss 0.229037\n",
      "batch 1825: loss 0.125459\n",
      "batch 1826: loss 0.108481\n",
      "batch 1827: loss 0.105910\n",
      "batch 1828: loss 0.069914\n",
      "batch 1829: loss 0.074983\n",
      "batch 1830: loss 0.116140\n",
      "batch 1831: loss 0.165648\n",
      "batch 1832: loss 0.038315\n",
      "batch 1833: loss 0.043347\n",
      "batch 1834: loss 0.064977\n",
      "batch 1835: loss 0.294955\n",
      "batch 1836: loss 0.110416\n",
      "batch 1837: loss 0.068603\n",
      "batch 1838: loss 0.160557\n",
      "batch 1839: loss 0.051925\n",
      "batch 1840: loss 0.130004\n",
      "batch 1841: loss 0.054379\n",
      "batch 1842: loss 0.077859\n",
      "batch 1843: loss 0.195668\n",
      "batch 1844: loss 0.069047\n",
      "batch 1845: loss 0.158818\n",
      "batch 1846: loss 0.180149\n",
      "batch 1847: loss 0.054077\n",
      "batch 1848: loss 0.085065\n",
      "batch 1849: loss 0.153359\n",
      "batch 1850: loss 0.030761\n",
      "batch 1851: loss 0.258434\n",
      "batch 1852: loss 0.072958\n",
      "batch 1853: loss 0.170352\n",
      "batch 1854: loss 0.087569\n",
      "batch 1855: loss 0.245388\n",
      "batch 1856: loss 0.200191\n",
      "batch 1857: loss 0.219491\n",
      "batch 1858: loss 0.176265\n",
      "batch 1859: loss 0.244516\n",
      "batch 1860: loss 0.075336\n",
      "batch 1861: loss 0.249817\n",
      "batch 1862: loss 0.033277\n",
      "batch 1863: loss 0.106167\n",
      "batch 1864: loss 0.125661\n",
      "batch 1865: loss 0.105984\n",
      "batch 1866: loss 0.116379\n",
      "batch 1867: loss 0.038542\n",
      "batch 1868: loss 0.041423\n",
      "batch 1869: loss 0.123254\n",
      "batch 1870: loss 0.219028\n",
      "batch 1871: loss 0.039071\n",
      "batch 1872: loss 0.116431\n",
      "batch 1873: loss 0.179716\n",
      "batch 1874: loss 0.091485\n",
      "batch 1875: loss 0.142536\n",
      "batch 1876: loss 0.053697\n",
      "batch 1877: loss 0.049582\n",
      "batch 1878: loss 0.039171\n",
      "batch 1879: loss 0.147749\n",
      "batch 1880: loss 0.148482\n",
      "batch 1881: loss 0.035305\n",
      "batch 1882: loss 0.149237\n",
      "batch 1883: loss 0.221674\n",
      "batch 1884: loss 0.124611\n",
      "batch 1885: loss 0.047674\n",
      "batch 1886: loss 0.114730\n",
      "batch 1887: loss 0.031070\n",
      "batch 1888: loss 0.249503\n",
      "batch 1889: loss 0.029535\n",
      "batch 1890: loss 0.089287\n",
      "batch 1891: loss 0.161713\n",
      "batch 1892: loss 0.176594\n",
      "batch 1893: loss 0.062994\n",
      "batch 1894: loss 0.045783\n",
      "batch 1895: loss 0.170782\n",
      "batch 1896: loss 0.152454\n",
      "batch 1897: loss 0.159894\n",
      "batch 1898: loss 0.064036\n",
      "batch 1899: loss 0.098752\n",
      "batch 1900: loss 0.079641\n",
      "batch 1901: loss 0.089821\n",
      "batch 1902: loss 0.098600\n",
      "batch 1903: loss 0.077301\n",
      "batch 1904: loss 0.045340\n",
      "batch 1905: loss 0.069823\n",
      "batch 1906: loss 0.117374\n",
      "batch 1907: loss 0.397197\n",
      "batch 1908: loss 0.184773\n",
      "batch 1909: loss 0.128028\n",
      "batch 1910: loss 0.044520\n",
      "batch 1911: loss 0.131747\n",
      "batch 1912: loss 0.055526\n",
      "batch 1913: loss 0.097785\n",
      "batch 1914: loss 0.141876\n",
      "batch 1915: loss 0.094185\n",
      "batch 1916: loss 0.188243\n",
      "batch 1917: loss 0.239114\n",
      "batch 1918: loss 0.087452\n",
      "batch 1919: loss 0.192090\n",
      "batch 1920: loss 0.055119\n",
      "batch 1921: loss 0.075957\n",
      "batch 1922: loss 0.070447\n",
      "batch 1923: loss 0.088847\n",
      "batch 1924: loss 0.232021\n",
      "batch 1925: loss 0.057556\n",
      "batch 1926: loss 0.038216\n",
      "batch 1927: loss 0.160622\n",
      "batch 1928: loss 0.060114\n",
      "batch 1929: loss 0.142777\n",
      "batch 1930: loss 0.103879\n",
      "batch 1931: loss 0.120142\n",
      "batch 1932: loss 0.056373\n",
      "batch 1933: loss 0.168933\n",
      "batch 1934: loss 0.082298\n",
      "batch 1935: loss 0.302873\n",
      "batch 1936: loss 0.050983\n",
      "batch 1937: loss 0.044958\n",
      "batch 1938: loss 0.105662\n",
      "batch 1939: loss 0.068246\n",
      "batch 1940: loss 0.183631\n",
      "batch 1941: loss 0.093929\n",
      "batch 1942: loss 0.078421\n",
      "batch 1943: loss 0.053653\n",
      "batch 1944: loss 0.034445\n",
      "batch 1945: loss 0.105185\n",
      "batch 1946: loss 0.088628\n",
      "batch 1947: loss 0.063155\n",
      "batch 1948: loss 0.055042\n",
      "batch 1949: loss 0.085763\n",
      "batch 1950: loss 0.088806\n",
      "batch 1951: loss 0.107227\n",
      "batch 1952: loss 0.213745\n",
      "batch 1953: loss 0.012995\n",
      "batch 1954: loss 0.250901\n",
      "batch 1955: loss 0.081365\n",
      "batch 1956: loss 0.055996\n",
      "batch 1957: loss 0.101625\n",
      "batch 1958: loss 0.099686\n",
      "batch 1959: loss 0.159460\n",
      "batch 1960: loss 0.068753\n",
      "batch 1961: loss 0.111464\n",
      "batch 1962: loss 0.182887\n",
      "batch 1963: loss 0.129073\n",
      "batch 1964: loss 0.095786\n",
      "batch 1965: loss 0.226592\n",
      "batch 1966: loss 0.107665\n",
      "batch 1967: loss 0.140821\n",
      "batch 1968: loss 0.135071\n",
      "batch 1969: loss 0.108046\n",
      "batch 1970: loss 0.072988\n",
      "batch 1971: loss 0.076133\n",
      "batch 1972: loss 0.409847\n",
      "batch 1973: loss 0.104600\n",
      "batch 1974: loss 0.172850\n",
      "batch 1975: loss 0.156614\n",
      "batch 1976: loss 0.120276\n",
      "batch 1977: loss 0.294092\n",
      "batch 1978: loss 0.040400\n",
      "batch 1979: loss 0.184762\n",
      "batch 1980: loss 0.159166\n",
      "batch 1981: loss 0.125464\n",
      "batch 1982: loss 0.110157\n",
      "batch 1983: loss 0.116699\n",
      "batch 1984: loss 0.179050\n",
      "batch 1985: loss 0.111528\n",
      "batch 1986: loss 0.242980\n",
      "batch 1987: loss 0.101456\n",
      "batch 1988: loss 0.124083\n",
      "batch 1989: loss 0.070688\n",
      "batch 1990: loss 0.068309\n",
      "batch 1991: loss 0.201139\n",
      "batch 1992: loss 0.172714\n",
      "batch 1993: loss 0.260794\n",
      "batch 1994: loss 0.213429\n",
      "batch 1995: loss 0.034231\n",
      "batch 1996: loss 0.103945\n",
      "batch 1997: loss 0.043852\n",
      "batch 1998: loss 0.162212\n",
      "batch 1999: loss 0.118345\n",
      "batch 2000: loss 0.099801\n",
      "batch 2001: loss 0.117550\n",
      "batch 2002: loss 0.121649\n",
      "batch 2003: loss 0.076137\n",
      "batch 2004: loss 0.053568\n",
      "batch 2005: loss 0.106507\n",
      "batch 2006: loss 0.136887\n",
      "batch 2007: loss 0.135367\n",
      "batch 2008: loss 0.080878\n",
      "batch 2009: loss 0.055990\n",
      "batch 2010: loss 0.045424\n",
      "batch 2011: loss 0.088845\n",
      "batch 2012: loss 0.043518\n",
      "batch 2013: loss 0.181097\n",
      "batch 2014: loss 0.112270\n",
      "batch 2015: loss 0.089554\n",
      "batch 2016: loss 0.126148\n",
      "batch 2017: loss 0.213931\n",
      "batch 2018: loss 0.131840\n",
      "batch 2019: loss 0.132186\n",
      "batch 2020: loss 0.127939\n",
      "batch 2021: loss 0.115083\n",
      "batch 2022: loss 0.077384\n",
      "batch 2023: loss 0.047261\n",
      "batch 2024: loss 0.117580\n",
      "batch 2025: loss 0.057511\n",
      "batch 2026: loss 0.100288\n",
      "batch 2027: loss 0.050494\n",
      "batch 2028: loss 0.140605\n",
      "batch 2029: loss 0.085217\n",
      "batch 2030: loss 0.143036\n",
      "batch 2031: loss 0.167178\n",
      "batch 2032: loss 0.055348\n",
      "batch 2033: loss 0.057698\n",
      "batch 2034: loss 0.086289\n",
      "batch 2035: loss 0.065926\n",
      "batch 2036: loss 0.087779\n",
      "batch 2037: loss 0.095253\n",
      "batch 2038: loss 0.046297\n",
      "batch 2039: loss 0.075541\n",
      "batch 2040: loss 0.136054\n",
      "batch 2041: loss 0.052063\n",
      "batch 2042: loss 0.104310\n",
      "batch 2043: loss 0.040114\n",
      "batch 2044: loss 0.105298\n",
      "batch 2045: loss 0.069492\n",
      "batch 2046: loss 0.091104\n",
      "batch 2047: loss 0.086986\n",
      "batch 2048: loss 0.139647\n",
      "batch 2049: loss 0.168638\n",
      "batch 2050: loss 0.029907\n",
      "batch 2051: loss 0.223844\n",
      "batch 2052: loss 0.054940\n",
      "batch 2053: loss 0.071488\n",
      "batch 2054: loss 0.019379\n",
      "batch 2055: loss 0.223432\n",
      "batch 2056: loss 0.188931\n",
      "batch 2057: loss 0.107153\n",
      "batch 2058: loss 0.237211\n",
      "batch 2059: loss 0.040990\n",
      "batch 2060: loss 0.037086\n",
      "batch 2061: loss 0.031749\n",
      "batch 2062: loss 0.189404\n",
      "batch 2063: loss 0.054488\n",
      "batch 2064: loss 0.231051\n",
      "batch 2065: loss 0.035488\n",
      "batch 2066: loss 0.106608\n",
      "batch 2067: loss 0.068480\n",
      "batch 2068: loss 0.098740\n",
      "batch 2069: loss 0.021819\n",
      "batch 2070: loss 0.062418\n",
      "batch 2071: loss 0.109029\n",
      "batch 2072: loss 0.039535\n",
      "batch 2073: loss 0.097327\n",
      "batch 2074: loss 0.085248\n",
      "batch 2075: loss 0.109630\n",
      "batch 2076: loss 0.266461\n",
      "batch 2077: loss 0.077677\n",
      "batch 2078: loss 0.167701\n",
      "batch 2079: loss 0.162781\n",
      "batch 2080: loss 0.054092\n",
      "batch 2081: loss 0.163317\n",
      "batch 2082: loss 0.215065\n",
      "batch 2083: loss 0.028323\n",
      "batch 2084: loss 0.108646\n",
      "batch 2085: loss 0.124446\n",
      "batch 2086: loss 0.102016\n",
      "batch 2087: loss 0.039120\n",
      "batch 2088: loss 0.037539\n",
      "batch 2089: loss 0.186389\n",
      "batch 2090: loss 0.083818\n",
      "batch 2091: loss 0.162352\n",
      "batch 2092: loss 0.171544\n",
      "batch 2093: loss 0.116858\n",
      "batch 2094: loss 0.063018\n",
      "batch 2095: loss 0.077614\n",
      "batch 2096: loss 0.197045\n",
      "batch 2097: loss 0.204948\n",
      "batch 2098: loss 0.190535\n",
      "batch 2099: loss 0.108149\n",
      "batch 2100: loss 0.040935\n",
      "batch 2101: loss 0.088851\n",
      "batch 2102: loss 0.066368\n",
      "batch 2103: loss 0.156774\n",
      "batch 2104: loss 0.160701\n",
      "batch 2105: loss 0.216518\n",
      "batch 2106: loss 0.044270\n",
      "batch 2107: loss 0.112050\n",
      "batch 2108: loss 0.067445\n",
      "batch 2109: loss 0.144916\n",
      "batch 2110: loss 0.323275\n",
      "batch 2111: loss 0.232285\n",
      "batch 2112: loss 0.120042\n",
      "batch 2113: loss 0.068352\n",
      "batch 2114: loss 0.022879\n",
      "batch 2115: loss 0.083588\n",
      "batch 2116: loss 0.049247\n",
      "batch 2117: loss 0.069721\n",
      "batch 2118: loss 0.278008\n",
      "batch 2119: loss 0.207941\n",
      "batch 2120: loss 0.113306\n",
      "batch 2121: loss 0.093082\n",
      "batch 2122: loss 0.052260\n",
      "batch 2123: loss 0.129949\n",
      "batch 2124: loss 0.094349\n",
      "batch 2125: loss 0.101061\n",
      "batch 2126: loss 0.022710\n",
      "batch 2127: loss 0.054315\n",
      "batch 2128: loss 0.099191\n",
      "batch 2129: loss 0.195863\n",
      "batch 2130: loss 0.106258\n",
      "batch 2131: loss 0.084452\n",
      "batch 2132: loss 0.214441\n",
      "batch 2133: loss 0.124368\n",
      "batch 2134: loss 0.076658\n",
      "batch 2135: loss 0.127517\n",
      "batch 2136: loss 0.123186\n",
      "batch 2137: loss 0.028855\n",
      "batch 2138: loss 0.094900\n",
      "batch 2139: loss 0.091339\n",
      "batch 2140: loss 0.117207\n",
      "batch 2141: loss 0.154731\n",
      "batch 2142: loss 0.316819\n",
      "batch 2143: loss 0.127391\n",
      "batch 2144: loss 0.040678\n",
      "batch 2145: loss 0.057417\n",
      "batch 2146: loss 0.028939\n",
      "batch 2147: loss 0.057256\n",
      "batch 2148: loss 0.082537\n",
      "batch 2149: loss 0.270890\n",
      "batch 2150: loss 0.171724\n",
      "batch 2151: loss 0.118603\n",
      "batch 2152: loss 0.046658\n",
      "batch 2153: loss 0.047429\n",
      "batch 2154: loss 0.128118\n",
      "batch 2155: loss 0.174142\n",
      "batch 2156: loss 0.169153\n",
      "batch 2157: loss 0.211276\n",
      "batch 2158: loss 0.054728\n",
      "batch 2159: loss 0.071654\n",
      "batch 2160: loss 0.195510\n",
      "batch 2161: loss 0.099759\n",
      "batch 2162: loss 0.107017\n",
      "batch 2163: loss 0.046577\n",
      "batch 2164: loss 0.048809\n",
      "batch 2165: loss 0.169562\n",
      "batch 2166: loss 0.140188\n",
      "batch 2167: loss 0.177018\n",
      "batch 2168: loss 0.094916\n",
      "batch 2169: loss 0.078423\n",
      "batch 2170: loss 0.046259\n",
      "batch 2171: loss 0.222049\n",
      "batch 2172: loss 0.075821\n",
      "batch 2173: loss 0.031597\n",
      "batch 2174: loss 0.045104\n",
      "batch 2175: loss 0.117715\n",
      "batch 2176: loss 0.097754\n",
      "batch 2177: loss 0.105593\n",
      "batch 2178: loss 0.170776\n",
      "batch 2179: loss 0.047802\n",
      "batch 2180: loss 0.086726\n",
      "batch 2181: loss 0.064146\n",
      "batch 2182: loss 0.053728\n",
      "batch 2183: loss 0.082792\n",
      "batch 2184: loss 0.060306\n",
      "batch 2185: loss 0.164374\n",
      "batch 2186: loss 0.084848\n",
      "batch 2187: loss 0.162745\n",
      "batch 2188: loss 0.047202\n",
      "batch 2189: loss 0.321620\n",
      "batch 2190: loss 0.044670\n",
      "batch 2191: loss 0.054446\n",
      "batch 2192: loss 0.074428\n",
      "batch 2193: loss 0.125714\n",
      "batch 2194: loss 0.105559\n",
      "batch 2195: loss 0.168688\n",
      "batch 2196: loss 0.096728\n",
      "batch 2197: loss 0.175856\n",
      "batch 2198: loss 0.077481\n",
      "batch 2199: loss 0.178769\n",
      "batch 2200: loss 0.050626\n",
      "batch 2201: loss 0.151853\n",
      "batch 2202: loss 0.112574\n",
      "batch 2203: loss 0.112074\n",
      "batch 2204: loss 0.067253\n",
      "batch 2205: loss 0.093848\n",
      "batch 2206: loss 0.190393\n",
      "batch 2207: loss 0.122270\n",
      "batch 2208: loss 0.133001\n",
      "batch 2209: loss 0.117507\n",
      "batch 2210: loss 0.098383\n",
      "batch 2211: loss 0.050633\n",
      "batch 2212: loss 0.094727\n",
      "batch 2213: loss 0.199272\n",
      "batch 2214: loss 0.371252\n",
      "batch 2215: loss 0.044117\n",
      "batch 2216: loss 0.148335\n",
      "batch 2217: loss 0.104065\n",
      "batch 2218: loss 0.025950\n",
      "batch 2219: loss 0.025230\n",
      "batch 2220: loss 0.082230\n",
      "batch 2221: loss 0.072990\n",
      "batch 2222: loss 0.133862\n",
      "batch 2223: loss 0.071249\n",
      "batch 2224: loss 0.095412\n",
      "batch 2225: loss 0.090388\n",
      "batch 2226: loss 0.052083\n",
      "batch 2227: loss 0.070574\n",
      "batch 2228: loss 0.119940\n",
      "batch 2229: loss 0.331446\n",
      "batch 2230: loss 0.048530\n",
      "batch 2231: loss 0.111818\n",
      "batch 2232: loss 0.120275\n",
      "batch 2233: loss 0.070555\n",
      "batch 2234: loss 0.075260\n",
      "batch 2235: loss 0.070783\n",
      "batch 2236: loss 0.135814\n",
      "batch 2237: loss 0.080797\n",
      "batch 2238: loss 0.230642\n",
      "batch 2239: loss 0.117067\n",
      "batch 2240: loss 0.033978\n",
      "batch 2241: loss 0.137043\n",
      "batch 2242: loss 0.160756\n",
      "batch 2243: loss 0.067254\n",
      "batch 2244: loss 0.137866\n",
      "batch 2245: loss 0.013117\n",
      "batch 2246: loss 0.091011\n",
      "batch 2247: loss 0.114157\n",
      "batch 2248: loss 0.145093\n",
      "batch 2249: loss 0.011853\n",
      "batch 2250: loss 0.044016\n",
      "batch 2251: loss 0.203984\n",
      "batch 2252: loss 0.040443\n",
      "batch 2253: loss 0.267859\n",
      "batch 2254: loss 0.045825\n",
      "batch 2255: loss 0.263607\n",
      "batch 2256: loss 0.032824\n",
      "batch 2257: loss 0.035476\n",
      "batch 2258: loss 0.111427\n",
      "batch 2259: loss 0.069930\n",
      "batch 2260: loss 0.078893\n",
      "batch 2261: loss 0.042369\n",
      "batch 2262: loss 0.171617\n",
      "batch 2263: loss 0.162972\n",
      "batch 2264: loss 0.096747\n",
      "batch 2265: loss 0.034975\n",
      "batch 2266: loss 0.115731\n",
      "batch 2267: loss 0.106630\n",
      "batch 2268: loss 0.181339\n",
      "batch 2269: loss 0.137724\n",
      "batch 2270: loss 0.236440\n",
      "batch 2271: loss 0.133825\n",
      "batch 2272: loss 0.048614\n",
      "batch 2273: loss 0.065759\n",
      "batch 2274: loss 0.220944\n",
      "batch 2275: loss 0.233031\n",
      "batch 2276: loss 0.134165\n",
      "batch 2277: loss 0.031560\n",
      "batch 2278: loss 0.087928\n",
      "batch 2279: loss 0.090313\n",
      "batch 2280: loss 0.045827\n",
      "batch 2281: loss 0.242329\n",
      "batch 2282: loss 0.120253\n",
      "batch 2283: loss 0.024921\n",
      "batch 2284: loss 0.019673\n",
      "batch 2285: loss 0.077881\n",
      "batch 2286: loss 0.049019\n",
      "batch 2287: loss 0.308374\n",
      "batch 2288: loss 0.067729\n",
      "batch 2289: loss 0.143257\n",
      "batch 2290: loss 0.208173\n",
      "batch 2291: loss 0.134978\n",
      "batch 2292: loss 0.073019\n",
      "batch 2293: loss 0.158777\n",
      "batch 2294: loss 0.128241\n",
      "batch 2295: loss 0.120979\n",
      "batch 2296: loss 0.192083\n",
      "batch 2297: loss 0.024797\n",
      "batch 2298: loss 0.206165\n",
      "batch 2299: loss 0.081230\n",
      "batch 2300: loss 0.035767\n",
      "batch 2301: loss 0.372301\n",
      "batch 2302: loss 0.083951\n",
      "batch 2303: loss 0.159182\n",
      "batch 2304: loss 0.102079\n",
      "batch 2305: loss 0.132990\n",
      "batch 2306: loss 0.259630\n",
      "batch 2307: loss 0.097127\n",
      "batch 2308: loss 0.061028\n",
      "batch 2309: loss 0.117226\n",
      "batch 2310: loss 0.081015\n",
      "batch 2311: loss 0.105767\n",
      "batch 2312: loss 0.122520\n",
      "batch 2313: loss 0.088505\n",
      "batch 2314: loss 0.262486\n",
      "batch 2315: loss 0.028969\n",
      "batch 2316: loss 0.068813\n",
      "batch 2317: loss 0.057839\n",
      "batch 2318: loss 0.056701\n",
      "batch 2319: loss 0.101041\n",
      "batch 2320: loss 0.134646\n",
      "batch 2321: loss 0.052265\n",
      "batch 2322: loss 0.082732\n",
      "batch 2323: loss 0.104522\n",
      "batch 2324: loss 0.045507\n",
      "batch 2325: loss 0.061100\n",
      "batch 2326: loss 0.164034\n",
      "batch 2327: loss 0.077477\n",
      "batch 2328: loss 0.165566\n",
      "batch 2329: loss 0.056151\n",
      "batch 2330: loss 0.036146\n",
      "batch 2331: loss 0.085672\n",
      "batch 2332: loss 0.049412\n",
      "batch 2333: loss 0.114119\n",
      "batch 2334: loss 0.166560\n",
      "batch 2335: loss 0.200484\n",
      "batch 2336: loss 0.065813\n",
      "batch 2337: loss 0.100295\n",
      "batch 2338: loss 0.045945\n",
      "batch 2339: loss 0.119898\n",
      "batch 2340: loss 0.087072\n",
      "batch 2341: loss 0.049834\n",
      "batch 2342: loss 0.133757\n",
      "batch 2343: loss 0.024311\n",
      "batch 2344: loss 0.138366\n",
      "batch 2345: loss 0.138137\n",
      "batch 2346: loss 0.085360\n",
      "batch 2347: loss 0.168303\n",
      "batch 2348: loss 0.319910\n",
      "batch 2349: loss 0.115932\n",
      "batch 2350: loss 0.285810\n",
      "batch 2351: loss 0.035245\n",
      "batch 2352: loss 0.140166\n",
      "batch 2353: loss 0.039795\n",
      "batch 2354: loss 0.133811\n",
      "batch 2355: loss 0.045648\n",
      "batch 2356: loss 0.118512\n",
      "batch 2357: loss 0.022973\n",
      "batch 2358: loss 0.147371\n",
      "batch 2359: loss 0.089748\n",
      "batch 2360: loss 0.187103\n",
      "batch 2361: loss 0.069024\n",
      "batch 2362: loss 0.265330\n",
      "batch 2363: loss 0.065203\n",
      "batch 2364: loss 0.072959\n",
      "batch 2365: loss 0.088629\n",
      "batch 2366: loss 0.065608\n",
      "batch 2367: loss 0.118344\n",
      "batch 2368: loss 0.132412\n",
      "batch 2369: loss 0.067511\n",
      "batch 2370: loss 0.021516\n",
      "batch 2371: loss 0.078161\n",
      "batch 2372: loss 0.206378\n",
      "batch 2373: loss 0.062835\n",
      "batch 2374: loss 0.057236\n",
      "batch 2375: loss 0.116917\n",
      "batch 2376: loss 0.031234\n",
      "batch 2377: loss 0.127626\n",
      "batch 2378: loss 0.267391\n",
      "batch 2379: loss 0.205021\n",
      "batch 2380: loss 0.078147\n",
      "batch 2381: loss 0.200300\n",
      "batch 2382: loss 0.049659\n",
      "batch 2383: loss 0.025734\n",
      "batch 2384: loss 0.210905\n",
      "batch 2385: loss 0.104394\n",
      "batch 2386: loss 0.396229\n",
      "batch 2387: loss 0.128366\n",
      "batch 2388: loss 0.087249\n",
      "batch 2389: loss 0.042653\n",
      "batch 2390: loss 0.169094\n",
      "batch 2391: loss 0.031525\n",
      "batch 2392: loss 0.108546\n",
      "batch 2393: loss 0.097850\n",
      "batch 2394: loss 0.147849\n",
      "batch 2395: loss 0.296469\n",
      "batch 2396: loss 0.243278\n",
      "batch 2397: loss 0.235298\n",
      "batch 2398: loss 0.073908\n",
      "batch 2399: loss 0.054330\n",
      "batch 2400: loss 0.035316\n",
      "batch 2401: loss 0.099515\n",
      "batch 2402: loss 0.121339\n",
      "batch 2403: loss 0.063011\n",
      "batch 2404: loss 0.144236\n",
      "batch 2405: loss 0.053653\n",
      "batch 2406: loss 0.180597\n",
      "batch 2407: loss 0.074333\n",
      "batch 2408: loss 0.188613\n",
      "batch 2409: loss 0.216947\n",
      "batch 2410: loss 0.037465\n",
      "batch 2411: loss 0.106635\n",
      "batch 2412: loss 0.114755\n",
      "batch 2413: loss 0.162277\n",
      "batch 2414: loss 0.175186\n",
      "batch 2415: loss 0.177908\n",
      "batch 2416: loss 0.110744\n",
      "batch 2417: loss 0.144465\n",
      "batch 2418: loss 0.091488\n",
      "batch 2419: loss 0.174325\n",
      "batch 2420: loss 0.102947\n",
      "batch 2421: loss 0.335942\n",
      "batch 2422: loss 0.060872\n",
      "batch 2423: loss 0.123211\n",
      "batch 2424: loss 0.033299\n",
      "batch 2425: loss 0.049931\n",
      "batch 2426: loss 0.039300\n",
      "batch 2427: loss 0.108649\n",
      "batch 2428: loss 0.130832\n",
      "batch 2429: loss 0.102620\n",
      "batch 2430: loss 0.096865\n",
      "batch 2431: loss 0.073403\n",
      "batch 2432: loss 0.048842\n",
      "batch 2433: loss 0.064237\n",
      "batch 2434: loss 0.120006\n",
      "batch 2435: loss 0.056485\n",
      "batch 2436: loss 0.046867\n",
      "batch 2437: loss 0.106654\n",
      "batch 2438: loss 0.156932\n",
      "batch 2439: loss 0.110637\n",
      "batch 2440: loss 0.067990\n",
      "batch 2441: loss 0.033373\n",
      "batch 2442: loss 0.070552\n",
      "batch 2443: loss 0.152081\n",
      "batch 2444: loss 0.169224\n",
      "batch 2445: loss 0.077853\n",
      "batch 2446: loss 0.102406\n",
      "batch 2447: loss 0.044763\n",
      "batch 2448: loss 0.081227\n",
      "batch 2449: loss 0.047784\n",
      "batch 2450: loss 0.058886\n",
      "batch 2451: loss 0.077766\n",
      "batch 2452: loss 0.058236\n",
      "batch 2453: loss 0.073230\n",
      "batch 2454: loss 0.150986\n",
      "batch 2455: loss 0.057122\n",
      "batch 2456: loss 0.117883\n",
      "batch 2457: loss 0.124631\n",
      "batch 2458: loss 0.304661\n",
      "batch 2459: loss 0.261390\n",
      "batch 2460: loss 0.101651\n",
      "batch 2461: loss 0.041638\n",
      "batch 2462: loss 0.132002\n",
      "batch 2463: loss 0.045885\n",
      "batch 2464: loss 0.065377\n",
      "batch 2465: loss 0.064607\n",
      "batch 2466: loss 0.127290\n",
      "batch 2467: loss 0.131247\n",
      "batch 2468: loss 0.146634\n",
      "batch 2469: loss 0.076913\n",
      "batch 2470: loss 0.148554\n",
      "batch 2471: loss 0.122767\n",
      "batch 2472: loss 0.054948\n",
      "batch 2473: loss 0.222312\n",
      "batch 2474: loss 0.067683\n",
      "batch 2475: loss 0.029403\n",
      "batch 2476: loss 0.161208\n",
      "batch 2477: loss 0.061154\n",
      "batch 2478: loss 0.097040\n",
      "batch 2479: loss 0.092694\n",
      "batch 2480: loss 0.064942\n",
      "batch 2481: loss 0.235496\n",
      "batch 2482: loss 0.060862\n",
      "batch 2483: loss 0.109259\n",
      "batch 2484: loss 0.117387\n",
      "batch 2485: loss 0.065532\n",
      "batch 2486: loss 0.069975\n",
      "batch 2487: loss 0.095729\n",
      "batch 2488: loss 0.077348\n",
      "batch 2489: loss 0.148780\n",
      "batch 2490: loss 0.188306\n",
      "batch 2491: loss 0.114841\n",
      "batch 2492: loss 0.073572\n",
      "batch 2493: loss 0.125296\n",
      "batch 2494: loss 0.030146\n",
      "batch 2495: loss 0.093276\n",
      "batch 2496: loss 0.112917\n",
      "batch 2497: loss 0.190006\n",
      "batch 2498: loss 0.045583\n",
      "batch 2499: loss 0.038891\n",
      "batch 2500: loss 0.096989\n",
      "batch 2501: loss 0.037331\n",
      "batch 2502: loss 0.201616\n",
      "batch 2503: loss 0.183452\n",
      "batch 2504: loss 0.146712\n",
      "batch 2505: loss 0.134766\n",
      "batch 2506: loss 0.060836\n",
      "batch 2507: loss 0.186835\n",
      "batch 2508: loss 0.029473\n",
      "batch 2509: loss 0.340676\n",
      "batch 2510: loss 0.159562\n",
      "batch 2511: loss 0.024262\n",
      "batch 2512: loss 0.059782\n",
      "batch 2513: loss 0.098132\n",
      "batch 2514: loss 0.047379\n",
      "batch 2515: loss 0.025717\n",
      "batch 2516: loss 0.066144\n",
      "batch 2517: loss 0.135343\n",
      "batch 2518: loss 0.057650\n",
      "batch 2519: loss 0.134322\n",
      "batch 2520: loss 0.063340\n",
      "batch 2521: loss 0.176935\n",
      "batch 2522: loss 0.200986\n",
      "batch 2523: loss 0.104974\n",
      "batch 2524: loss 0.104376\n",
      "batch 2525: loss 0.110122\n",
      "batch 2526: loss 0.053304\n",
      "batch 2527: loss 0.059460\n",
      "batch 2528: loss 0.063182\n",
      "batch 2529: loss 0.190996\n",
      "batch 2530: loss 0.052869\n",
      "batch 2531: loss 0.327181\n",
      "batch 2532: loss 0.090784\n",
      "batch 2533: loss 0.142102\n",
      "batch 2534: loss 0.074161\n",
      "batch 2535: loss 0.130836\n",
      "batch 2536: loss 0.145145\n",
      "batch 2537: loss 0.052228\n",
      "batch 2538: loss 0.070141\n",
      "batch 2539: loss 0.059600\n",
      "batch 2540: loss 0.410482\n",
      "batch 2541: loss 0.103141\n",
      "batch 2542: loss 0.107028\n",
      "batch 2543: loss 0.019363\n",
      "batch 2544: loss 0.073347\n",
      "batch 2545: loss 0.169215\n",
      "batch 2546: loss 0.100402\n",
      "batch 2547: loss 0.171854\n",
      "batch 2548: loss 0.047173\n",
      "batch 2549: loss 0.095795\n",
      "batch 2550: loss 0.109635\n",
      "batch 2551: loss 0.104924\n",
      "batch 2552: loss 0.073703\n",
      "batch 2553: loss 0.146292\n",
      "batch 2554: loss 0.028191\n",
      "batch 2555: loss 0.088509\n",
      "batch 2556: loss 0.051441\n",
      "batch 2557: loss 0.136806\n",
      "batch 2558: loss 0.051592\n",
      "batch 2559: loss 0.205888\n",
      "batch 2560: loss 0.031155\n",
      "batch 2561: loss 0.016299\n",
      "batch 2562: loss 0.101633\n",
      "batch 2563: loss 0.104342\n",
      "batch 2564: loss 0.124204\n",
      "batch 2565: loss 0.115037\n",
      "batch 2566: loss 0.121996\n",
      "batch 2567: loss 0.114064\n",
      "batch 2568: loss 0.094038\n",
      "batch 2569: loss 0.072685\n",
      "batch 2570: loss 0.041008\n",
      "batch 2571: loss 0.038755\n",
      "batch 2572: loss 0.027709\n",
      "batch 2573: loss 0.077376\n",
      "batch 2574: loss 0.038834\n",
      "batch 2575: loss 0.110488\n",
      "batch 2576: loss 0.085437\n",
      "batch 2577: loss 0.124497\n",
      "batch 2578: loss 0.086632\n",
      "batch 2579: loss 0.041960\n",
      "batch 2580: loss 0.034672\n",
      "batch 2581: loss 0.112180\n",
      "batch 2582: loss 0.035530\n",
      "batch 2583: loss 0.081249\n",
      "batch 2584: loss 0.030768\n",
      "batch 2585: loss 0.042566\n",
      "batch 2586: loss 0.034475\n",
      "batch 2587: loss 0.043240\n",
      "batch 2588: loss 0.094416\n",
      "batch 2589: loss 0.154302\n",
      "batch 2590: loss 0.136871\n",
      "batch 2591: loss 0.035198\n",
      "batch 2592: loss 0.065246\n",
      "batch 2593: loss 0.291198\n",
      "batch 2594: loss 0.204802\n",
      "batch 2595: loss 0.090625\n",
      "batch 2596: loss 0.092345\n",
      "batch 2597: loss 0.171040\n",
      "batch 2598: loss 0.083133\n",
      "batch 2599: loss 0.137311\n",
      "batch 2600: loss 0.128040\n",
      "batch 2601: loss 0.113079\n",
      "batch 2602: loss 0.186724\n",
      "batch 2603: loss 0.099878\n",
      "batch 2604: loss 0.088291\n",
      "batch 2605: loss 0.077896\n",
      "batch 2606: loss 0.022994\n",
      "batch 2607: loss 0.081213\n",
      "batch 2608: loss 0.010062\n",
      "batch 2609: loss 0.158614\n",
      "batch 2610: loss 0.041458\n",
      "batch 2611: loss 0.119908\n",
      "batch 2612: loss 0.052834\n",
      "batch 2613: loss 0.042188\n",
      "batch 2614: loss 0.095937\n",
      "batch 2615: loss 0.067414\n",
      "batch 2616: loss 0.067680\n",
      "batch 2617: loss 0.078403\n",
      "batch 2618: loss 0.265817\n",
      "batch 2619: loss 0.055515\n",
      "batch 2620: loss 0.114203\n",
      "batch 2621: loss 0.105551\n",
      "batch 2622: loss 0.112139\n",
      "batch 2623: loss 0.041461\n",
      "batch 2624: loss 0.067521\n",
      "batch 2625: loss 0.192606\n",
      "batch 2626: loss 0.238889\n",
      "batch 2627: loss 0.020628\n",
      "batch 2628: loss 0.020481\n",
      "batch 2629: loss 0.034400\n",
      "batch 2630: loss 0.053323\n",
      "batch 2631: loss 0.139760\n",
      "batch 2632: loss 0.051428\n",
      "batch 2633: loss 0.330742\n",
      "batch 2634: loss 0.221004\n",
      "batch 2635: loss 0.117882\n",
      "batch 2636: loss 0.100632\n",
      "batch 2637: loss 0.061541\n",
      "batch 2638: loss 0.097311\n",
      "batch 2639: loss 0.038172\n",
      "batch 2640: loss 0.118863\n",
      "batch 2641: loss 0.030213\n",
      "batch 2642: loss 0.203043\n",
      "batch 2643: loss 0.054331\n",
      "batch 2644: loss 0.053619\n",
      "batch 2645: loss 0.059641\n",
      "batch 2646: loss 0.058335\n",
      "batch 2647: loss 0.053327\n",
      "batch 2648: loss 0.058502\n",
      "batch 2649: loss 0.122648\n",
      "batch 2650: loss 0.035477\n",
      "batch 2651: loss 0.109605\n",
      "batch 2652: loss 0.142805\n",
      "batch 2653: loss 0.071935\n",
      "batch 2654: loss 0.149172\n",
      "batch 2655: loss 0.120208\n",
      "batch 2656: loss 0.062261\n",
      "batch 2657: loss 0.045480\n",
      "batch 2658: loss 0.161215\n",
      "batch 2659: loss 0.018196\n",
      "batch 2660: loss 0.224535\n",
      "batch 2661: loss 0.049440\n",
      "batch 2662: loss 0.136129\n",
      "batch 2663: loss 0.281404\n",
      "batch 2664: loss 0.055708\n",
      "batch 2665: loss 0.060052\n",
      "batch 2666: loss 0.015204\n",
      "batch 2667: loss 0.040329\n",
      "batch 2668: loss 0.088053\n",
      "batch 2669: loss 0.127262\n",
      "batch 2670: loss 0.153834\n",
      "batch 2671: loss 0.065424\n",
      "batch 2672: loss 0.056376\n",
      "batch 2673: loss 0.157774\n",
      "batch 2674: loss 0.160465\n",
      "batch 2675: loss 0.125867\n",
      "batch 2676: loss 0.127164\n",
      "batch 2677: loss 0.063175\n",
      "batch 2678: loss 0.060743\n",
      "batch 2679: loss 0.164843\n",
      "batch 2680: loss 0.057850\n",
      "batch 2681: loss 0.054966\n",
      "batch 2682: loss 0.032494\n",
      "batch 2683: loss 0.072478\n",
      "batch 2684: loss 0.130502\n",
      "batch 2685: loss 0.218493\n",
      "batch 2686: loss 0.014327\n",
      "batch 2687: loss 0.073516\n",
      "batch 2688: loss 0.097198\n",
      "batch 2689: loss 0.165445\n",
      "batch 2690: loss 0.061148\n",
      "batch 2691: loss 0.009922\n",
      "batch 2692: loss 0.063239\n",
      "batch 2693: loss 0.231569\n",
      "batch 2694: loss 0.196506\n",
      "batch 2695: loss 0.051624\n",
      "batch 2696: loss 0.109353\n",
      "batch 2697: loss 0.123137\n",
      "batch 2698: loss 0.141707\n",
      "batch 2699: loss 0.059271\n",
      "batch 2700: loss 0.106449\n",
      "batch 2701: loss 0.123462\n",
      "batch 2702: loss 0.190912\n",
      "batch 2703: loss 0.035056\n",
      "batch 2704: loss 0.091108\n",
      "batch 2705: loss 0.069200\n",
      "batch 2706: loss 0.066386\n",
      "batch 2707: loss 0.109529\n",
      "batch 2708: loss 0.040073\n",
      "batch 2709: loss 0.026390\n",
      "batch 2710: loss 0.261490\n",
      "batch 2711: loss 0.132179\n",
      "batch 2712: loss 0.017715\n",
      "batch 2713: loss 0.068546\n",
      "batch 2714: loss 0.022451\n",
      "batch 2715: loss 0.229155\n",
      "batch 2716: loss 0.166324\n",
      "batch 2717: loss 0.041806\n",
      "batch 2718: loss 0.017503\n",
      "batch 2719: loss 0.222007\n",
      "batch 2720: loss 0.087725\n",
      "batch 2721: loss 0.082828\n",
      "batch 2722: loss 0.074638\n",
      "batch 2723: loss 0.206848\n",
      "batch 2724: loss 0.162949\n",
      "batch 2725: loss 0.153386\n",
      "batch 2726: loss 0.117089\n",
      "batch 2727: loss 0.044066\n",
      "batch 2728: loss 0.048277\n",
      "batch 2729: loss 0.070288\n",
      "batch 2730: loss 0.069885\n",
      "batch 2731: loss 0.050774\n",
      "batch 2732: loss 0.151488\n",
      "batch 2733: loss 0.100890\n",
      "batch 2734: loss 0.314152\n",
      "batch 2735: loss 0.151567\n",
      "batch 2736: loss 0.058626\n",
      "batch 2737: loss 0.156589\n",
      "batch 2738: loss 0.056171\n",
      "batch 2739: loss 0.034370\n",
      "batch 2740: loss 0.025779\n",
      "batch 2741: loss 0.147952\n",
      "batch 2742: loss 0.189554\n",
      "batch 2743: loss 0.098857\n",
      "batch 2744: loss 0.106843\n",
      "batch 2745: loss 0.029075\n",
      "batch 2746: loss 0.255149\n",
      "batch 2747: loss 0.066728\n",
      "batch 2748: loss 0.114790\n",
      "batch 2749: loss 0.226938\n",
      "batch 2750: loss 0.034445\n",
      "batch 2751: loss 0.083574\n",
      "batch 2752: loss 0.124418\n",
      "batch 2753: loss 0.202262\n",
      "batch 2754: loss 0.054189\n",
      "batch 2755: loss 0.069401\n",
      "batch 2756: loss 0.045437\n",
      "batch 2757: loss 0.054367\n",
      "batch 2758: loss 0.069197\n",
      "batch 2759: loss 0.049403\n",
      "batch 2760: loss 0.091467\n",
      "batch 2761: loss 0.147495\n",
      "batch 2762: loss 0.053641\n",
      "batch 2763: loss 0.126574\n",
      "batch 2764: loss 0.093131\n",
      "batch 2765: loss 0.198343\n",
      "batch 2766: loss 0.140443\n",
      "batch 2767: loss 0.185746\n",
      "batch 2768: loss 0.043800\n",
      "batch 2769: loss 0.113297\n",
      "batch 2770: loss 0.045543\n",
      "batch 2771: loss 0.237832\n",
      "batch 2772: loss 0.051720\n",
      "batch 2773: loss 0.035765\n",
      "batch 2774: loss 0.040603\n",
      "batch 2775: loss 0.031047\n",
      "batch 2776: loss 0.091546\n",
      "batch 2777: loss 0.073693\n",
      "batch 2778: loss 0.147553\n",
      "batch 2779: loss 0.112706\n",
      "batch 2780: loss 0.110769\n",
      "batch 2781: loss 0.029223\n",
      "batch 2782: loss 0.059538\n",
      "batch 2783: loss 0.112961\n",
      "batch 2784: loss 0.065100\n",
      "batch 2785: loss 0.046241\n",
      "batch 2786: loss 0.130105\n",
      "batch 2787: loss 0.040576\n",
      "batch 2788: loss 0.086965\n",
      "batch 2789: loss 0.034207\n",
      "batch 2790: loss 0.035452\n",
      "batch 2791: loss 0.060949\n",
      "batch 2792: loss 0.114487\n",
      "batch 2793: loss 0.053699\n",
      "batch 2794: loss 0.183460\n",
      "batch 2795: loss 0.135753\n",
      "batch 2796: loss 0.103838\n",
      "batch 2797: loss 0.201988\n",
      "batch 2798: loss 0.105683\n",
      "batch 2799: loss 0.135567\n",
      "batch 2800: loss 0.094224\n",
      "batch 2801: loss 0.032137\n",
      "batch 2802: loss 0.140710\n",
      "batch 2803: loss 0.025757\n",
      "batch 2804: loss 0.048811\n",
      "batch 2805: loss 0.175533\n",
      "batch 2806: loss 0.041633\n",
      "batch 2807: loss 0.077199\n",
      "batch 2808: loss 0.138269\n",
      "batch 2809: loss 0.118726\n",
      "batch 2810: loss 0.093719\n",
      "batch 2811: loss 0.221910\n",
      "batch 2812: loss 0.033974\n",
      "batch 2813: loss 0.036453\n",
      "batch 2814: loss 0.048721\n",
      "batch 2815: loss 0.246333\n",
      "batch 2816: loss 0.046525\n",
      "batch 2817: loss 0.088407\n",
      "batch 2818: loss 0.148720\n",
      "batch 2819: loss 0.229667\n",
      "batch 2820: loss 0.094067\n",
      "batch 2821: loss 0.060017\n",
      "batch 2822: loss 0.023441\n",
      "batch 2823: loss 0.040260\n",
      "batch 2824: loss 0.120533\n",
      "batch 2825: loss 0.081407\n",
      "batch 2826: loss 0.042574\n",
      "batch 2827: loss 0.117059\n",
      "batch 2828: loss 0.031964\n",
      "batch 2829: loss 0.219405\n",
      "batch 2830: loss 0.061379\n",
      "batch 2831: loss 0.158788\n",
      "batch 2832: loss 0.199451\n",
      "batch 2833: loss 0.121607\n",
      "batch 2834: loss 0.030610\n",
      "batch 2835: loss 0.193763\n",
      "batch 2836: loss 0.053679\n",
      "batch 2837: loss 0.077362\n",
      "batch 2838: loss 0.023715\n",
      "batch 2839: loss 0.066217\n",
      "batch 2840: loss 0.077085\n",
      "batch 2841: loss 0.111193\n",
      "batch 2842: loss 0.034469\n",
      "batch 2843: loss 0.128675\n",
      "batch 2844: loss 0.014871\n",
      "batch 2845: loss 0.105816\n",
      "batch 2846: loss 0.072831\n",
      "batch 2847: loss 0.049402\n",
      "batch 2848: loss 0.067355\n",
      "batch 2849: loss 0.127958\n",
      "batch 2850: loss 0.022007\n",
      "batch 2851: loss 0.092668\n",
      "batch 2852: loss 0.063599\n",
      "batch 2853: loss 0.015110\n",
      "batch 2854: loss 0.036652\n",
      "batch 2855: loss 0.056961\n",
      "batch 2856: loss 0.101932\n",
      "batch 2857: loss 0.150158\n",
      "batch 2858: loss 0.066397\n",
      "batch 2859: loss 0.033692\n",
      "batch 2860: loss 0.044363\n",
      "batch 2861: loss 0.143562\n",
      "batch 2862: loss 0.164431\n",
      "batch 2863: loss 0.016209\n",
      "batch 2864: loss 0.076408\n",
      "batch 2865: loss 0.174671\n",
      "batch 2866: loss 0.147806\n",
      "batch 2867: loss 0.048588\n",
      "batch 2868: loss 0.140864\n",
      "batch 2869: loss 0.117751\n",
      "batch 2870: loss 0.082783\n",
      "batch 2871: loss 0.048790\n",
      "batch 2872: loss 0.016817\n",
      "batch 2873: loss 0.077975\n",
      "batch 2874: loss 0.127769\n",
      "batch 2875: loss 0.026229\n",
      "batch 2876: loss 0.029969\n",
      "batch 2877: loss 0.052575\n",
      "batch 2878: loss 0.018094\n",
      "batch 2879: loss 0.100180\n",
      "batch 2880: loss 0.104185\n",
      "batch 2881: loss 0.240619\n",
      "batch 2882: loss 0.080203\n",
      "batch 2883: loss 0.060011\n",
      "batch 2884: loss 0.160973\n",
      "batch 2885: loss 0.171373\n",
      "batch 2886: loss 0.047513\n",
      "batch 2887: loss 0.133097\n",
      "batch 2888: loss 0.067771\n",
      "batch 2889: loss 0.146652\n",
      "batch 2890: loss 0.160037\n",
      "batch 2891: loss 0.214736\n",
      "batch 2892: loss 0.223683\n",
      "batch 2893: loss 0.072658\n",
      "batch 2894: loss 0.114359\n",
      "batch 2895: loss 0.118364\n",
      "batch 2896: loss 0.126207\n",
      "batch 2897: loss 0.069194\n",
      "batch 2898: loss 0.076250\n",
      "batch 2899: loss 0.094734\n",
      "batch 2900: loss 0.225986\n",
      "batch 2901: loss 0.087582\n",
      "batch 2902: loss 0.029486\n",
      "batch 2903: loss 0.120747\n",
      "batch 2904: loss 0.171919\n",
      "batch 2905: loss 0.014408\n",
      "batch 2906: loss 0.036226\n",
      "batch 2907: loss 0.037396\n",
      "batch 2908: loss 0.069799\n",
      "batch 2909: loss 0.139819\n",
      "batch 2910: loss 0.146117\n",
      "batch 2911: loss 0.134537\n",
      "batch 2912: loss 0.073379\n",
      "batch 2913: loss 0.017941\n",
      "batch 2914: loss 0.108830\n",
      "batch 2915: loss 0.120168\n",
      "batch 2916: loss 0.057294\n",
      "batch 2917: loss 0.086308\n",
      "batch 2918: loss 0.104172\n",
      "batch 2919: loss 0.098884\n",
      "batch 2920: loss 0.131789\n",
      "batch 2921: loss 0.132534\n",
      "batch 2922: loss 0.127908\n",
      "batch 2923: loss 0.071703\n",
      "batch 2924: loss 0.071085\n",
      "batch 2925: loss 0.027933\n",
      "batch 2926: loss 0.071104\n",
      "batch 2927: loss 0.024645\n",
      "batch 2928: loss 0.035569\n",
      "batch 2929: loss 0.051919\n",
      "batch 2930: loss 0.025827\n",
      "batch 2931: loss 0.032096\n",
      "batch 2932: loss 0.078134\n",
      "batch 2933: loss 0.304205\n",
      "batch 2934: loss 0.131509\n",
      "batch 2935: loss 0.037503\n",
      "batch 2936: loss 0.027318\n",
      "batch 2937: loss 0.137880\n",
      "batch 2938: loss 0.028879\n",
      "batch 2939: loss 0.086373\n",
      "batch 2940: loss 0.024296\n",
      "batch 2941: loss 0.149536\n",
      "batch 2942: loss 0.069811\n",
      "batch 2943: loss 0.108039\n",
      "batch 2944: loss 0.101495\n",
      "batch 2945: loss 0.034692\n",
      "batch 2946: loss 0.057642\n",
      "batch 2947: loss 0.141645\n",
      "batch 2948: loss 0.227917\n",
      "batch 2949: loss 0.198968\n",
      "batch 2950: loss 0.045659\n",
      "batch 2951: loss 0.050291\n",
      "batch 2952: loss 0.287447\n",
      "batch 2953: loss 0.138536\n",
      "batch 2954: loss 0.100019\n",
      "batch 2955: loss 0.066797\n",
      "batch 2956: loss 0.040532\n",
      "batch 2957: loss 0.093007\n",
      "batch 2958: loss 0.127129\n",
      "batch 2959: loss 0.180827\n",
      "batch 2960: loss 0.096839\n",
      "batch 2961: loss 0.010205\n",
      "batch 2962: loss 0.028896\n",
      "batch 2963: loss 0.175320\n",
      "batch 2964: loss 0.082548\n",
      "batch 2965: loss 0.108984\n",
      "batch 2966: loss 0.072219\n",
      "batch 2967: loss 0.101981\n",
      "batch 2968: loss 0.018508\n",
      "batch 2969: loss 0.201158\n",
      "batch 2970: loss 0.109368\n",
      "batch 2971: loss 0.040149\n",
      "batch 2972: loss 0.058591\n",
      "batch 2973: loss 0.089099\n",
      "batch 2974: loss 0.080765\n",
      "batch 2975: loss 0.152291\n",
      "batch 2976: loss 0.061699\n",
      "batch 2977: loss 0.038602\n",
      "batch 2978: loss 0.067932\n",
      "batch 2979: loss 0.113907\n",
      "batch 2980: loss 0.040154\n",
      "batch 2981: loss 0.033548\n",
      "batch 2982: loss 0.066104\n",
      "batch 2983: loss 0.060751\n",
      "batch 2984: loss 0.049267\n",
      "batch 2985: loss 0.034609\n",
      "batch 2986: loss 0.021304\n",
      "batch 2987: loss 0.021631\n",
      "batch 2988: loss 0.018803\n",
      "batch 2989: loss 0.090298\n",
      "batch 2990: loss 0.123393\n",
      "batch 2991: loss 0.147768\n",
      "batch 2992: loss 0.122571\n",
      "batch 2993: loss 0.031240\n",
      "batch 2994: loss 0.071979\n",
      "batch 2995: loss 0.054207\n",
      "batch 2996: loss 0.032726\n",
      "batch 2997: loss 0.010670\n",
      "batch 2998: loss 0.024553\n",
      "batch 2999: loss 0.172647\n",
      "batch 3000: loss 0.016162\n",
      "batch 3001: loss 0.094054\n",
      "batch 3002: loss 0.050852\n",
      "batch 3003: loss 0.160226\n",
      "batch 3004: loss 0.126904\n",
      "batch 3005: loss 0.169238\n",
      "batch 3006: loss 0.060816\n",
      "batch 3007: loss 0.084097\n",
      "batch 3008: loss 0.197921\n",
      "batch 3009: loss 0.054555\n",
      "batch 3010: loss 0.072899\n",
      "batch 3011: loss 0.051477\n",
      "batch 3012: loss 0.142266\n",
      "batch 3013: loss 0.035635\n",
      "batch 3014: loss 0.140865\n",
      "batch 3015: loss 0.041906\n",
      "batch 3016: loss 0.035038\n",
      "batch 3017: loss 0.177504\n",
      "batch 3018: loss 0.202994\n",
      "batch 3019: loss 0.044963\n",
      "batch 3020: loss 0.048123\n",
      "batch 3021: loss 0.112737\n",
      "batch 3022: loss 0.020455\n",
      "batch 3023: loss 0.064041\n",
      "batch 3024: loss 0.125332\n",
      "batch 3025: loss 0.036608\n",
      "batch 3026: loss 0.039888\n",
      "batch 3027: loss 0.081957\n",
      "batch 3028: loss 0.019873\n",
      "batch 3029: loss 0.159622\n",
      "batch 3030: loss 0.106787\n",
      "batch 3031: loss 0.062571\n",
      "batch 3032: loss 0.053696\n",
      "batch 3033: loss 0.043005\n",
      "batch 3034: loss 0.077571\n",
      "batch 3035: loss 0.067641\n",
      "batch 3036: loss 0.030307\n",
      "batch 3037: loss 0.046041\n",
      "batch 3038: loss 0.132116\n",
      "batch 3039: loss 0.019853\n",
      "batch 3040: loss 0.041464\n",
      "batch 3041: loss 0.224154\n",
      "batch 3042: loss 0.058418\n",
      "batch 3043: loss 0.109427\n",
      "batch 3044: loss 0.059359\n",
      "batch 3045: loss 0.036182\n",
      "batch 3046: loss 0.077949\n",
      "batch 3047: loss 0.135785\n",
      "batch 3048: loss 0.023465\n",
      "batch 3049: loss 0.049200\n",
      "batch 3050: loss 0.089911\n",
      "batch 3051: loss 0.042653\n",
      "batch 3052: loss 0.073625\n",
      "batch 3053: loss 0.165107\n",
      "batch 3054: loss 0.045451\n",
      "batch 3055: loss 0.042677\n",
      "batch 3056: loss 0.047621\n",
      "batch 3057: loss 0.084458\n",
      "batch 3058: loss 0.008700\n",
      "batch 3059: loss 0.045664\n",
      "batch 3060: loss 0.035346\n",
      "batch 3061: loss 0.073541\n",
      "batch 3062: loss 0.016843\n",
      "batch 3063: loss 0.233342\n",
      "batch 3064: loss 0.068986\n",
      "batch 3065: loss 0.013362\n",
      "batch 3066: loss 0.175059\n",
      "batch 3067: loss 0.053394\n",
      "batch 3068: loss 0.064270\n",
      "batch 3069: loss 0.089015\n",
      "batch 3070: loss 0.014639\n",
      "batch 3071: loss 0.118316\n",
      "batch 3072: loss 0.123039\n",
      "batch 3073: loss 0.041319\n",
      "batch 3074: loss 0.042567\n",
      "batch 3075: loss 0.036776\n",
      "batch 3076: loss 0.088550\n",
      "batch 3077: loss 0.042273\n",
      "batch 3078: loss 0.076253\n",
      "batch 3079: loss 0.034210\n",
      "batch 3080: loss 0.145425\n",
      "batch 3081: loss 0.042392\n",
      "batch 3082: loss 0.167557\n",
      "batch 3083: loss 0.041957\n",
      "batch 3084: loss 0.076271\n",
      "batch 3085: loss 0.058199\n",
      "batch 3086: loss 0.026478\n",
      "batch 3087: loss 0.017120\n",
      "batch 3088: loss 0.049630\n",
      "batch 3089: loss 0.128512\n",
      "batch 3090: loss 0.093828\n",
      "batch 3091: loss 0.118385\n",
      "batch 3092: loss 0.060140\n",
      "batch 3093: loss 0.046071\n",
      "batch 3094: loss 0.054762\n",
      "batch 3095: loss 0.133036\n",
      "batch 3096: loss 0.049396\n",
      "batch 3097: loss 0.073196\n",
      "batch 3098: loss 0.062884\n",
      "batch 3099: loss 0.184181\n",
      "batch 3100: loss 0.085176\n",
      "batch 3101: loss 0.113781\n",
      "batch 3102: loss 0.059160\n",
      "batch 3103: loss 0.252820\n",
      "batch 3104: loss 0.052991\n",
      "batch 3105: loss 0.162628\n",
      "batch 3106: loss 0.030153\n",
      "batch 3107: loss 0.011267\n",
      "batch 3108: loss 0.064862\n",
      "batch 3109: loss 0.071609\n",
      "batch 3110: loss 0.013007\n",
      "batch 3111: loss 0.131425\n",
      "batch 3112: loss 0.042067\n",
      "batch 3113: loss 0.274472\n",
      "batch 3114: loss 0.026204\n",
      "batch 3115: loss 0.123130\n",
      "batch 3116: loss 0.088673\n",
      "batch 3117: loss 0.116034\n",
      "batch 3118: loss 0.047998\n",
      "batch 3119: loss 0.110048\n",
      "batch 3120: loss 0.111168\n",
      "batch 3121: loss 0.063610\n",
      "batch 3122: loss 0.033242\n",
      "batch 3123: loss 0.075100\n",
      "batch 3124: loss 0.089099\n",
      "batch 3125: loss 0.052805\n",
      "batch 3126: loss 0.068871\n",
      "batch 3127: loss 0.030379\n",
      "batch 3128: loss 0.052955\n",
      "batch 3129: loss 0.067916\n",
      "batch 3130: loss 0.034722\n",
      "batch 3131: loss 0.092810\n",
      "batch 3132: loss 0.105122\n",
      "batch 3133: loss 0.036819\n",
      "batch 3134: loss 0.105110\n",
      "batch 3135: loss 0.027324\n",
      "batch 3136: loss 0.092217\n",
      "batch 3137: loss 0.177884\n",
      "batch 3138: loss 0.027181\n",
      "batch 3139: loss 0.208275\n",
      "batch 3140: loss 0.063032\n",
      "batch 3141: loss 0.218680\n",
      "batch 3142: loss 0.199485\n",
      "batch 3143: loss 0.050511\n",
      "batch 3144: loss 0.117661\n",
      "batch 3145: loss 0.155156\n",
      "batch 3146: loss 0.042918\n",
      "batch 3147: loss 0.078106\n",
      "batch 3148: loss 0.018503\n",
      "batch 3149: loss 0.027181\n",
      "batch 3150: loss 0.060958\n",
      "batch 3151: loss 0.015746\n",
      "batch 3152: loss 0.079343\n",
      "batch 3153: loss 0.062721\n",
      "batch 3154: loss 0.022427\n",
      "batch 3155: loss 0.064720\n",
      "batch 3156: loss 0.066936\n",
      "batch 3157: loss 0.072067\n",
      "batch 3158: loss 0.089947\n",
      "batch 3159: loss 0.094338\n",
      "batch 3160: loss 0.219249\n",
      "batch 3161: loss 0.148604\n",
      "batch 3162: loss 0.036357\n",
      "batch 3163: loss 0.055262\n",
      "batch 3164: loss 0.139171\n",
      "batch 3165: loss 0.054798\n",
      "batch 3166: loss 0.022787\n",
      "batch 3167: loss 0.021684\n",
      "batch 3168: loss 0.061234\n",
      "batch 3169: loss 0.052468\n",
      "batch 3170: loss 0.027093\n",
      "batch 3171: loss 0.120282\n",
      "batch 3172: loss 0.060609\n",
      "batch 3173: loss 0.041195\n",
      "batch 3174: loss 0.132234\n",
      "batch 3175: loss 0.170634\n",
      "batch 3176: loss 0.020329\n",
      "batch 3177: loss 0.042300\n",
      "batch 3178: loss 0.084389\n",
      "batch 3179: loss 0.064275\n",
      "batch 3180: loss 0.081518\n",
      "batch 3181: loss 0.098802\n",
      "batch 3182: loss 0.255707\n",
      "batch 3183: loss 0.088179\n",
      "batch 3184: loss 0.051717\n",
      "batch 3185: loss 0.049906\n",
      "batch 3186: loss 0.063391\n",
      "batch 3187: loss 0.016028\n",
      "batch 3188: loss 0.047303\n",
      "batch 3189: loss 0.200987\n",
      "batch 3190: loss 0.272412\n",
      "batch 3191: loss 0.158576\n",
      "batch 3192: loss 0.118790\n",
      "batch 3193: loss 0.048423\n",
      "batch 3194: loss 0.024103\n",
      "batch 3195: loss 0.052175\n",
      "batch 3196: loss 0.100330\n",
      "batch 3197: loss 0.026925\n",
      "batch 3198: loss 0.133947\n",
      "batch 3199: loss 0.120849\n",
      "batch 3200: loss 0.042929\n",
      "batch 3201: loss 0.043758\n",
      "batch 3202: loss 0.031292\n",
      "batch 3203: loss 0.091013\n",
      "batch 3204: loss 0.186015\n",
      "batch 3205: loss 0.104934\n",
      "batch 3206: loss 0.058089\n",
      "batch 3207: loss 0.079310\n",
      "batch 3208: loss 0.096896\n",
      "batch 3209: loss 0.052359\n",
      "batch 3210: loss 0.056829\n",
      "batch 3211: loss 0.196980\n",
      "batch 3212: loss 0.021778\n",
      "batch 3213: loss 0.077032\n",
      "batch 3214: loss 0.014343\n",
      "batch 3215: loss 0.046921\n",
      "batch 3216: loss 0.023875\n",
      "batch 3217: loss 0.008695\n",
      "batch 3218: loss 0.025473\n",
      "batch 3219: loss 0.046102\n",
      "batch 3220: loss 0.020507\n",
      "batch 3221: loss 0.254781\n",
      "batch 3222: loss 0.089769\n",
      "batch 3223: loss 0.038528\n",
      "batch 3224: loss 0.201474\n",
      "batch 3225: loss 0.054082\n",
      "batch 3226: loss 0.157739\n",
      "batch 3227: loss 0.038076\n",
      "batch 3228: loss 0.148559\n",
      "batch 3229: loss 0.063494\n",
      "batch 3230: loss 0.084657\n",
      "batch 3231: loss 0.046188\n",
      "batch 3232: loss 0.049497\n",
      "batch 3233: loss 0.024607\n",
      "batch 3234: loss 0.026146\n",
      "batch 3235: loss 0.078845\n",
      "batch 3236: loss 0.065707\n",
      "batch 3237: loss 0.035892\n",
      "batch 3238: loss 0.156410\n",
      "batch 3239: loss 0.135309\n",
      "batch 3240: loss 0.058482\n",
      "batch 3241: loss 0.066217\n",
      "batch 3242: loss 0.084654\n",
      "batch 3243: loss 0.155717\n",
      "batch 3244: loss 0.075748\n",
      "batch 3245: loss 0.126834\n",
      "batch 3246: loss 0.056946\n",
      "batch 3247: loss 0.121869\n",
      "batch 3248: loss 0.106531\n",
      "batch 3249: loss 0.104069\n",
      "batch 3250: loss 0.023605\n",
      "batch 3251: loss 0.045167\n",
      "batch 3252: loss 0.173588\n",
      "batch 3253: loss 0.021286\n",
      "batch 3254: loss 0.038854\n",
      "batch 3255: loss 0.041912\n",
      "batch 3256: loss 0.069858\n",
      "batch 3257: loss 0.041463\n",
      "batch 3258: loss 0.046608\n",
      "batch 3259: loss 0.018010\n",
      "batch 3260: loss 0.071883\n",
      "batch 3261: loss 0.195806\n",
      "batch 3262: loss 0.062334\n",
      "batch 3263: loss 0.101246\n",
      "batch 3264: loss 0.132293\n",
      "batch 3265: loss 0.135344\n",
      "batch 3266: loss 0.111892\n",
      "batch 3267: loss 0.029102\n",
      "batch 3268: loss 0.019910\n",
      "batch 3269: loss 0.216288\n",
      "batch 3270: loss 0.020685\n",
      "batch 3271: loss 0.182845\n",
      "batch 3272: loss 0.069528\n",
      "batch 3273: loss 0.022999\n",
      "batch 3274: loss 0.023696\n",
      "batch 3275: loss 0.214639\n",
      "batch 3276: loss 0.116951\n",
      "batch 3277: loss 0.191142\n",
      "batch 3278: loss 0.191913\n",
      "batch 3279: loss 0.104663\n",
      "batch 3280: loss 0.059542\n",
      "batch 3281: loss 0.090233\n",
      "batch 3282: loss 0.124980\n",
      "batch 3283: loss 0.121909\n",
      "batch 3284: loss 0.194358\n",
      "batch 3285: loss 0.066071\n",
      "batch 3286: loss 0.135988\n",
      "batch 3287: loss 0.016971\n",
      "batch 3288: loss 0.010091\n",
      "batch 3289: loss 0.062276\n",
      "batch 3290: loss 0.028592\n",
      "batch 3291: loss 0.048167\n",
      "batch 3292: loss 0.065406\n",
      "batch 3293: loss 0.043364\n",
      "batch 3294: loss 0.048738\n",
      "batch 3295: loss 0.061108\n",
      "batch 3296: loss 0.172177\n",
      "batch 3297: loss 0.060781\n",
      "batch 3298: loss 0.257636\n",
      "batch 3299: loss 0.114497\n",
      "batch 3300: loss 0.132669\n",
      "batch 3301: loss 0.040140\n",
      "batch 3302: loss 0.042503\n",
      "batch 3303: loss 0.008979\n",
      "batch 3304: loss 0.032271\n",
      "batch 3305: loss 0.182318\n",
      "batch 3306: loss 0.090444\n",
      "batch 3307: loss 0.076494\n",
      "batch 3308: loss 0.155983\n",
      "batch 3309: loss 0.122372\n",
      "batch 3310: loss 0.158974\n",
      "batch 3311: loss 0.035308\n",
      "batch 3312: loss 0.047203\n",
      "batch 3313: loss 0.159616\n",
      "batch 3314: loss 0.090613\n",
      "batch 3315: loss 0.077015\n",
      "batch 3316: loss 0.034314\n",
      "batch 3317: loss 0.069029\n",
      "batch 3318: loss 0.028625\n",
      "batch 3319: loss 0.059710\n",
      "batch 3320: loss 0.029678\n",
      "batch 3321: loss 0.064543\n",
      "batch 3322: loss 0.059141\n",
      "batch 3323: loss 0.073866\n",
      "batch 3324: loss 0.080895\n",
      "batch 3325: loss 0.083603\n",
      "batch 3326: loss 0.073075\n",
      "batch 3327: loss 0.050972\n",
      "batch 3328: loss 0.259670\n",
      "batch 3329: loss 0.028056\n",
      "batch 3330: loss 0.029354\n",
      "batch 3331: loss 0.144302\n",
      "batch 3332: loss 0.045380\n",
      "batch 3333: loss 0.036232\n",
      "batch 3334: loss 0.097870\n",
      "batch 3335: loss 0.053138\n",
      "batch 3336: loss 0.108772\n",
      "batch 3337: loss 0.095967\n",
      "batch 3338: loss 0.195734\n",
      "batch 3339: loss 0.178373\n",
      "batch 3340: loss 0.052158\n",
      "batch 3341: loss 0.069854\n",
      "batch 3342: loss 0.049561\n",
      "batch 3343: loss 0.016180\n",
      "batch 3344: loss 0.049316\n",
      "batch 3345: loss 0.098863\n",
      "batch 3346: loss 0.072421\n",
      "batch 3347: loss 0.080588\n",
      "batch 3348: loss 0.019947\n",
      "batch 3349: loss 0.025300\n",
      "batch 3350: loss 0.041366\n",
      "batch 3351: loss 0.212370\n",
      "batch 3352: loss 0.179548\n",
      "batch 3353: loss 0.094389\n",
      "batch 3354: loss 0.192425\n",
      "batch 3355: loss 0.160173\n",
      "batch 3356: loss 0.034010\n",
      "batch 3357: loss 0.122845\n",
      "batch 3358: loss 0.049153\n",
      "batch 3359: loss 0.126327\n",
      "batch 3360: loss 0.009727\n",
      "batch 3361: loss 0.023561\n",
      "batch 3362: loss 0.076271\n",
      "batch 3363: loss 0.017475\n",
      "batch 3364: loss 0.135514\n",
      "batch 3365: loss 0.067674\n",
      "batch 3366: loss 0.022927\n",
      "batch 3367: loss 0.039637\n",
      "batch 3368: loss 0.103678\n",
      "batch 3369: loss 0.132143\n",
      "batch 3370: loss 0.065126\n",
      "batch 3371: loss 0.101989\n",
      "batch 3372: loss 0.034707\n",
      "batch 3373: loss 0.071045\n",
      "batch 3374: loss 0.078118\n",
      "batch 3375: loss 0.013556\n",
      "batch 3376: loss 0.095852\n",
      "batch 3377: loss 0.015387\n",
      "batch 3378: loss 0.134044\n",
      "batch 3379: loss 0.026116\n",
      "batch 3380: loss 0.024939\n",
      "batch 3381: loss 0.017225\n",
      "batch 3382: loss 0.064240\n",
      "batch 3383: loss 0.232438\n",
      "batch 3384: loss 0.039557\n",
      "batch 3385: loss 0.021858\n",
      "batch 3386: loss 0.074469\n",
      "batch 3387: loss 0.026312\n",
      "batch 3388: loss 0.119216\n",
      "batch 3389: loss 0.107057\n",
      "batch 3390: loss 0.014083\n",
      "batch 3391: loss 0.019024\n",
      "batch 3392: loss 0.251078\n",
      "batch 3393: loss 0.008355\n",
      "batch 3394: loss 0.184119\n",
      "batch 3395: loss 0.115170\n",
      "batch 3396: loss 0.082333\n",
      "batch 3397: loss 0.113000\n",
      "batch 3398: loss 0.139303\n",
      "batch 3399: loss 0.194184\n",
      "batch 3400: loss 0.084802\n",
      "batch 3401: loss 0.182492\n",
      "batch 3402: loss 0.153221\n",
      "batch 3403: loss 0.167210\n",
      "batch 3404: loss 0.126744\n",
      "batch 3405: loss 0.055653\n",
      "batch 3406: loss 0.036710\n",
      "batch 3407: loss 0.091294\n",
      "batch 3408: loss 0.081764\n",
      "batch 3409: loss 0.183760\n",
      "batch 3410: loss 0.019310\n",
      "batch 3411: loss 0.022952\n",
      "batch 3412: loss 0.022466\n",
      "batch 3413: loss 0.069284\n",
      "batch 3414: loss 0.063209\n",
      "batch 3415: loss 0.237051\n",
      "batch 3416: loss 0.047917\n",
      "batch 3417: loss 0.044946\n",
      "batch 3418: loss 0.056190\n",
      "batch 3419: loss 0.113780\n",
      "batch 3420: loss 0.097001\n",
      "batch 3421: loss 0.048318\n",
      "batch 3422: loss 0.071907\n",
      "batch 3423: loss 0.034713\n",
      "batch 3424: loss 0.088933\n",
      "batch 3425: loss 0.169611\n",
      "batch 3426: loss 0.035414\n",
      "batch 3427: loss 0.045204\n",
      "batch 3428: loss 0.019068\n",
      "batch 3429: loss 0.016449\n",
      "batch 3430: loss 0.120069\n",
      "batch 3431: loss 0.027161\n",
      "batch 3432: loss 0.109154\n",
      "batch 3433: loss 0.124476\n",
      "batch 3434: loss 0.281493\n",
      "batch 3435: loss 0.048781\n",
      "batch 3436: loss 0.103384\n",
      "batch 3437: loss 0.192719\n",
      "batch 3438: loss 0.075531\n",
      "batch 3439: loss 0.035738\n",
      "batch 3440: loss 0.146846\n",
      "batch 3441: loss 0.120652\n",
      "batch 3442: loss 0.195040\n",
      "batch 3443: loss 0.021982\n",
      "batch 3444: loss 0.098390\n",
      "batch 3445: loss 0.148201\n",
      "batch 3446: loss 0.121476\n",
      "batch 3447: loss 0.158515\n",
      "batch 3448: loss 0.091949\n",
      "batch 3449: loss 0.039842\n",
      "batch 3450: loss 0.200253\n",
      "batch 3451: loss 0.099511\n",
      "batch 3452: loss 0.029318\n",
      "batch 3453: loss 0.090771\n",
      "batch 3454: loss 0.237766\n",
      "batch 3455: loss 0.073147\n",
      "batch 3456: loss 0.033224\n",
      "batch 3457: loss 0.141807\n",
      "batch 3458: loss 0.055900\n",
      "batch 3459: loss 0.103876\n",
      "batch 3460: loss 0.142997\n",
      "batch 3461: loss 0.081141\n",
      "batch 3462: loss 0.201085\n",
      "batch 3463: loss 0.206525\n",
      "batch 3464: loss 0.056422\n",
      "batch 3465: loss 0.083155\n",
      "batch 3466: loss 0.164938\n",
      "batch 3467: loss 0.069068\n",
      "batch 3468: loss 0.047836\n",
      "batch 3469: loss 0.077531\n",
      "batch 3470: loss 0.054873\n",
      "batch 3471: loss 0.193195\n",
      "batch 3472: loss 0.017711\n",
      "batch 3473: loss 0.092858\n",
      "batch 3474: loss 0.084633\n",
      "batch 3475: loss 0.122767\n",
      "batch 3476: loss 0.200599\n",
      "batch 3477: loss 0.037120\n",
      "batch 3478: loss 0.031879\n",
      "batch 3479: loss 0.128076\n",
      "batch 3480: loss 0.032407\n",
      "batch 3481: loss 0.055305\n",
      "batch 3482: loss 0.079066\n",
      "batch 3483: loss 0.180599\n",
      "batch 3484: loss 0.080631\n",
      "batch 3485: loss 0.056342\n",
      "batch 3486: loss 0.144444\n",
      "batch 3487: loss 0.049738\n",
      "batch 3488: loss 0.086109\n",
      "batch 3489: loss 0.037311\n",
      "batch 3490: loss 0.119130\n",
      "batch 3491: loss 0.153305\n",
      "batch 3492: loss 0.145259\n",
      "batch 3493: loss 0.016717\n",
      "batch 3494: loss 0.082472\n",
      "batch 3495: loss 0.161581\n",
      "batch 3496: loss 0.044009\n",
      "batch 3497: loss 0.025144\n",
      "batch 3498: loss 0.048358\n",
      "batch 3499: loss 0.029275\n",
      "batch 3500: loss 0.048358\n",
      "batch 3501: loss 0.051142\n",
      "batch 3502: loss 0.071461\n",
      "batch 3503: loss 0.023508\n",
      "batch 3504: loss 0.189850\n",
      "batch 3505: loss 0.066643\n",
      "batch 3506: loss 0.103992\n",
      "batch 3507: loss 0.066446\n",
      "batch 3508: loss 0.283058\n",
      "batch 3509: loss 0.078081\n",
      "batch 3510: loss 0.034566\n",
      "batch 3511: loss 0.058186\n",
      "batch 3512: loss 0.183896\n",
      "batch 3513: loss 0.077557\n",
      "batch 3514: loss 0.109903\n",
      "batch 3515: loss 0.108135\n",
      "batch 3516: loss 0.015999\n",
      "batch 3517: loss 0.033098\n",
      "batch 3518: loss 0.036819\n",
      "batch 3519: loss 0.095139\n",
      "batch 3520: loss 0.131633\n",
      "batch 3521: loss 0.010553\n",
      "batch 3522: loss 0.131866\n",
      "batch 3523: loss 0.145421\n",
      "batch 3524: loss 0.055233\n",
      "batch 3525: loss 0.144425\n",
      "batch 3526: loss 0.113122\n",
      "batch 3527: loss 0.196668\n",
      "batch 3528: loss 0.085435\n",
      "batch 3529: loss 0.114491\n",
      "batch 3530: loss 0.031560\n",
      "batch 3531: loss 0.033445\n",
      "batch 3532: loss 0.067673\n",
      "batch 3533: loss 0.071394\n",
      "batch 3534: loss 0.034131\n",
      "batch 3535: loss 0.045909\n",
      "batch 3536: loss 0.168238\n",
      "batch 3537: loss 0.018725\n",
      "batch 3538: loss 0.186275\n",
      "batch 3539: loss 0.187012\n",
      "batch 3540: loss 0.026744\n",
      "batch 3541: loss 0.010031\n",
      "batch 3542: loss 0.180491\n",
      "batch 3543: loss 0.063098\n",
      "batch 3544: loss 0.251621\n",
      "batch 3545: loss 0.055422\n",
      "batch 3546: loss 0.097997\n",
      "batch 3547: loss 0.092187\n",
      "batch 3548: loss 0.032802\n",
      "batch 3549: loss 0.098702\n",
      "batch 3550: loss 0.047430\n",
      "batch 3551: loss 0.062799\n",
      "batch 3552: loss 0.057412\n",
      "batch 3553: loss 0.056566\n",
      "batch 3554: loss 0.043177\n",
      "batch 3555: loss 0.033105\n",
      "batch 3556: loss 0.200998\n",
      "batch 3557: loss 0.149770\n",
      "batch 3558: loss 0.060750\n",
      "batch 3559: loss 0.158443\n",
      "batch 3560: loss 0.016642\n",
      "batch 3561: loss 0.034679\n",
      "batch 3562: loss 0.224738\n",
      "batch 3563: loss 0.049488\n",
      "batch 3564: loss 0.043503\n",
      "batch 3565: loss 0.016763\n",
      "batch 3566: loss 0.043537\n",
      "batch 3567: loss 0.026693\n",
      "batch 3568: loss 0.085768\n",
      "batch 3569: loss 0.132269\n",
      "batch 3570: loss 0.214066\n",
      "batch 3571: loss 0.039194\n",
      "batch 3572: loss 0.078755\n",
      "batch 3573: loss 0.060788\n",
      "batch 3574: loss 0.052459\n",
      "batch 3575: loss 0.113728\n",
      "batch 3576: loss 0.131991\n",
      "batch 3577: loss 0.129502\n",
      "batch 3578: loss 0.063211\n",
      "batch 3579: loss 0.032442\n",
      "batch 3580: loss 0.014267\n",
      "batch 3581: loss 0.013332\n",
      "batch 3582: loss 0.069659\n",
      "batch 3583: loss 0.032774\n",
      "batch 3584: loss 0.061474\n",
      "batch 3585: loss 0.036999\n",
      "batch 3586: loss 0.043291\n",
      "batch 3587: loss 0.060758\n",
      "batch 3588: loss 0.107970\n",
      "batch 3589: loss 0.013378\n",
      "batch 3590: loss 0.035633\n",
      "batch 3591: loss 0.049024\n",
      "batch 3592: loss 0.250083\n",
      "batch 3593: loss 0.156941\n",
      "batch 3594: loss 0.247165\n",
      "batch 3595: loss 0.039757\n",
      "batch 3596: loss 0.299551\n",
      "batch 3597: loss 0.227633\n",
      "batch 3598: loss 0.102178\n",
      "batch 3599: loss 0.040544\n",
      "batch 3600: loss 0.033012\n",
      "batch 3601: loss 0.070142\n",
      "batch 3602: loss 0.053532\n",
      "batch 3603: loss 0.056480\n",
      "batch 3604: loss 0.032481\n",
      "batch 3605: loss 0.054660\n",
      "batch 3606: loss 0.076942\n",
      "batch 3607: loss 0.074108\n",
      "batch 3608: loss 0.065328\n",
      "batch 3609: loss 0.058044\n",
      "batch 3610: loss 0.083769\n",
      "batch 3611: loss 0.076121\n",
      "batch 3612: loss 0.188364\n",
      "batch 3613: loss 0.039273\n",
      "batch 3614: loss 0.028833\n",
      "batch 3615: loss 0.065790\n",
      "batch 3616: loss 0.134769\n",
      "batch 3617: loss 0.112542\n",
      "batch 3618: loss 0.066866\n",
      "batch 3619: loss 0.015732\n",
      "batch 3620: loss 0.092364\n",
      "batch 3621: loss 0.017026\n",
      "batch 3622: loss 0.018236\n",
      "batch 3623: loss 0.106736\n",
      "batch 3624: loss 0.139937\n",
      "batch 3625: loss 0.044240\n",
      "batch 3626: loss 0.026460\n",
      "batch 3627: loss 0.024805\n",
      "batch 3628: loss 0.107343\n",
      "batch 3629: loss 0.021346\n",
      "batch 3630: loss 0.039589\n",
      "batch 3631: loss 0.017557\n",
      "batch 3632: loss 0.052593\n",
      "batch 3633: loss 0.022290\n",
      "batch 3634: loss 0.087310\n",
      "batch 3635: loss 0.055296\n",
      "batch 3636: loss 0.038513\n",
      "batch 3637: loss 0.015594\n",
      "batch 3638: loss 0.117865\n",
      "batch 3639: loss 0.068039\n",
      "batch 3640: loss 0.035969\n",
      "batch 3641: loss 0.025177\n",
      "batch 3642: loss 0.043916\n",
      "batch 3643: loss 0.080175\n",
      "batch 3644: loss 0.118525\n",
      "batch 3645: loss 0.099121\n",
      "batch 3646: loss 0.041454\n",
      "batch 3647: loss 0.086432\n",
      "batch 3648: loss 0.104241\n",
      "batch 3649: loss 0.094710\n",
      "batch 3650: loss 0.100071\n",
      "batch 3651: loss 0.030274\n",
      "batch 3652: loss 0.058616\n",
      "batch 3653: loss 0.059503\n",
      "batch 3654: loss 0.153517\n",
      "batch 3655: loss 0.056617\n",
      "batch 3656: loss 0.062895\n",
      "batch 3657: loss 0.169437\n",
      "batch 3658: loss 0.145941\n",
      "batch 3659: loss 0.036861\n",
      "batch 3660: loss 0.168873\n",
      "batch 3661: loss 0.176380\n",
      "batch 3662: loss 0.071006\n",
      "batch 3663: loss 0.022692\n",
      "batch 3664: loss 0.086791\n",
      "batch 3665: loss 0.058497\n",
      "batch 3666: loss 0.016474\n",
      "batch 3667: loss 0.072316\n",
      "batch 3668: loss 0.037830\n",
      "batch 3669: loss 0.087887\n",
      "batch 3670: loss 0.057143\n",
      "batch 3671: loss 0.041221\n",
      "batch 3672: loss 0.158496\n",
      "batch 3673: loss 0.133228\n",
      "batch 3674: loss 0.017608\n",
      "batch 3675: loss 0.032679\n",
      "batch 3676: loss 0.039006\n",
      "batch 3677: loss 0.015280\n",
      "batch 3678: loss 0.041864\n",
      "batch 3679: loss 0.073312\n",
      "batch 3680: loss 0.109319\n",
      "batch 3681: loss 0.028197\n",
      "batch 3682: loss 0.099594\n",
      "batch 3683: loss 0.013919\n",
      "batch 3684: loss 0.073064\n",
      "batch 3685: loss 0.047669\n",
      "batch 3686: loss 0.037515\n",
      "batch 3687: loss 0.048307\n",
      "batch 3688: loss 0.028034\n",
      "batch 3689: loss 0.025031\n",
      "batch 3690: loss 0.019115\n",
      "batch 3691: loss 0.015701\n",
      "batch 3692: loss 0.031698\n",
      "batch 3693: loss 0.039488\n",
      "batch 3694: loss 0.036359\n",
      "batch 3695: loss 0.056773\n",
      "batch 3696: loss 0.079049\n",
      "batch 3697: loss 0.104650\n",
      "batch 3698: loss 0.014753\n",
      "batch 3699: loss 0.004488\n",
      "batch 3700: loss 0.060892\n",
      "batch 3701: loss 0.032059\n",
      "batch 3702: loss 0.044741\n",
      "batch 3703: loss 0.050605\n",
      "batch 3704: loss 0.042644\n",
      "batch 3705: loss 0.067575\n",
      "batch 3706: loss 0.133208\n",
      "batch 3707: loss 0.129810\n",
      "batch 3708: loss 0.055719\n",
      "batch 3709: loss 0.099972\n",
      "batch 3710: loss 0.020411\n",
      "batch 3711: loss 0.025230\n",
      "batch 3712: loss 0.032557\n",
      "batch 3713: loss 0.193336\n",
      "batch 3714: loss 0.034531\n",
      "batch 3715: loss 0.022045\n",
      "batch 3716: loss 0.063424\n",
      "batch 3717: loss 0.088888\n",
      "batch 3718: loss 0.239848\n",
      "batch 3719: loss 0.072175\n",
      "batch 3720: loss 0.102680\n",
      "batch 3721: loss 0.037626\n",
      "batch 3722: loss 0.083646\n",
      "batch 3723: loss 0.022967\n",
      "batch 3724: loss 0.044112\n",
      "batch 3725: loss 0.442587\n",
      "batch 3726: loss 0.164225\n",
      "batch 3727: loss 0.115515\n",
      "batch 3728: loss 0.050101\n",
      "batch 3729: loss 0.112223\n",
      "batch 3730: loss 0.073576\n",
      "batch 3731: loss 0.097908\n",
      "batch 3732: loss 0.115102\n",
      "batch 3733: loss 0.028155\n",
      "batch 3734: loss 0.035561\n",
      "batch 3735: loss 0.094800\n",
      "batch 3736: loss 0.029041\n",
      "batch 3737: loss 0.200682\n",
      "batch 3738: loss 0.085091\n",
      "batch 3739: loss 0.100567\n",
      "batch 3740: loss 0.059829\n",
      "batch 3741: loss 0.132616\n",
      "batch 3742: loss 0.133785\n",
      "batch 3743: loss 0.007812\n",
      "batch 3744: loss 0.073601\n",
      "batch 3745: loss 0.111710\n",
      "batch 3746: loss 0.066905\n",
      "batch 3747: loss 0.034427\n",
      "batch 3748: loss 0.022554\n",
      "batch 3749: loss 0.063855\n",
      "batch 3750: loss 0.050146\n",
      "batch 3751: loss 0.099086\n",
      "batch 3752: loss 0.033884\n",
      "batch 3753: loss 0.039453\n",
      "batch 3754: loss 0.061725\n",
      "batch 3755: loss 0.068948\n",
      "batch 3756: loss 0.016616\n",
      "batch 3757: loss 0.062654\n",
      "batch 3758: loss 0.018078\n",
      "batch 3759: loss 0.061073\n",
      "batch 3760: loss 0.055996\n",
      "batch 3761: loss 0.023092\n",
      "batch 3762: loss 0.035831\n",
      "batch 3763: loss 0.033686\n",
      "batch 3764: loss 0.120032\n",
      "batch 3765: loss 0.125890\n",
      "batch 3766: loss 0.036956\n",
      "batch 3767: loss 0.063958\n",
      "batch 3768: loss 0.177221\n",
      "batch 3769: loss 0.052395\n",
      "batch 3770: loss 0.028789\n",
      "batch 3771: loss 0.036930\n",
      "batch 3772: loss 0.099067\n",
      "batch 3773: loss 0.203606\n",
      "batch 3774: loss 0.096664\n",
      "batch 3775: loss 0.038905\n",
      "batch 3776: loss 0.095390\n",
      "batch 3777: loss 0.045465\n",
      "batch 3778: loss 0.031935\n",
      "batch 3779: loss 0.056117\n",
      "batch 3780: loss 0.097239\n",
      "batch 3781: loss 0.050190\n",
      "batch 3782: loss 0.139106\n",
      "batch 3783: loss 0.087736\n",
      "batch 3784: loss 0.058375\n",
      "batch 3785: loss 0.043586\n",
      "batch 3786: loss 0.065183\n",
      "batch 3787: loss 0.084331\n",
      "batch 3788: loss 0.045191\n",
      "batch 3789: loss 0.039591\n",
      "batch 3790: loss 0.130626\n",
      "batch 3791: loss 0.073615\n",
      "batch 3792: loss 0.232690\n",
      "batch 3793: loss 0.082146\n",
      "batch 3794: loss 0.060869\n",
      "batch 3795: loss 0.089446\n",
      "batch 3796: loss 0.038654\n",
      "batch 3797: loss 0.263912\n",
      "batch 3798: loss 0.126201\n",
      "batch 3799: loss 0.048698\n",
      "batch 3800: loss 0.023861\n",
      "batch 3801: loss 0.104328\n",
      "batch 3802: loss 0.048551\n",
      "batch 3803: loss 0.096467\n",
      "batch 3804: loss 0.028295\n",
      "batch 3805: loss 0.118229\n",
      "batch 3806: loss 0.034454\n",
      "batch 3807: loss 0.045606\n",
      "batch 3808: loss 0.090843\n",
      "batch 3809: loss 0.022815\n",
      "batch 3810: loss 0.098546\n",
      "batch 3811: loss 0.223701\n",
      "batch 3812: loss 0.041131\n",
      "batch 3813: loss 0.066936\n",
      "batch 3814: loss 0.030754\n",
      "batch 3815: loss 0.117744\n",
      "batch 3816: loss 0.026638\n",
      "batch 3817: loss 0.035825\n",
      "batch 3818: loss 0.061398\n",
      "batch 3819: loss 0.084128\n",
      "batch 3820: loss 0.060328\n",
      "batch 3821: loss 0.015553\n",
      "batch 3822: loss 0.031687\n",
      "batch 3823: loss 0.117905\n",
      "batch 3824: loss 0.032522\n",
      "batch 3825: loss 0.025695\n",
      "batch 3826: loss 0.054360\n",
      "batch 3827: loss 0.054804\n",
      "batch 3828: loss 0.108450\n",
      "batch 3829: loss 0.133967\n",
      "batch 3830: loss 0.031336\n",
      "batch 3831: loss 0.016750\n",
      "batch 3832: loss 0.046737\n",
      "batch 3833: loss 0.047111\n",
      "batch 3834: loss 0.059076\n",
      "batch 3835: loss 0.018647\n",
      "batch 3836: loss 0.163024\n",
      "batch 3837: loss 0.082595\n",
      "batch 3838: loss 0.125525\n",
      "batch 3839: loss 0.057641\n",
      "batch 3840: loss 0.154439\n",
      "batch 3841: loss 0.012756\n",
      "batch 3842: loss 0.064767\n",
      "batch 3843: loss 0.013256\n",
      "batch 3844: loss 0.048813\n",
      "batch 3845: loss 0.075208\n",
      "batch 3846: loss 0.062405\n",
      "batch 3847: loss 0.043332\n",
      "batch 3848: loss 0.038185\n",
      "batch 3849: loss 0.083498\n",
      "batch 3850: loss 0.250468\n",
      "batch 3851: loss 0.111343\n",
      "batch 3852: loss 0.131680\n",
      "batch 3853: loss 0.015853\n",
      "batch 3854: loss 0.034401\n",
      "batch 3855: loss 0.079763\n",
      "batch 3856: loss 0.062515\n",
      "batch 3857: loss 0.016449\n",
      "batch 3858: loss 0.052742\n",
      "batch 3859: loss 0.108266\n",
      "batch 3860: loss 0.102539\n",
      "batch 3861: loss 0.078697\n",
      "batch 3862: loss 0.131316\n",
      "batch 3863: loss 0.112478\n",
      "batch 3864: loss 0.079659\n",
      "batch 3865: loss 0.080872\n",
      "batch 3866: loss 0.010819\n",
      "batch 3867: loss 0.028492\n",
      "batch 3868: loss 0.032985\n",
      "batch 3869: loss 0.043389\n",
      "batch 3870: loss 0.077653\n",
      "batch 3871: loss 0.074920\n",
      "batch 3872: loss 0.063141\n",
      "batch 3873: loss 0.130628\n",
      "batch 3874: loss 0.129113\n",
      "batch 3875: loss 0.013510\n",
      "batch 3876: loss 0.028198\n",
      "batch 3877: loss 0.028375\n",
      "batch 3878: loss 0.193375\n",
      "batch 3879: loss 0.288241\n",
      "batch 3880: loss 0.112753\n",
      "batch 3881: loss 0.025391\n",
      "batch 3882: loss 0.033296\n",
      "batch 3883: loss 0.083863\n",
      "batch 3884: loss 0.054361\n",
      "batch 3885: loss 0.026203\n",
      "batch 3886: loss 0.024399\n",
      "batch 3887: loss 0.039314\n",
      "batch 3888: loss 0.119826\n",
      "batch 3889: loss 0.033480\n",
      "batch 3890: loss 0.057795\n",
      "batch 3891: loss 0.037860\n",
      "batch 3892: loss 0.050205\n",
      "batch 3893: loss 0.036694\n",
      "batch 3894: loss 0.076026\n",
      "batch 3895: loss 0.033926\n",
      "batch 3896: loss 0.094258\n",
      "batch 3897: loss 0.351842\n",
      "batch 3898: loss 0.018569\n",
      "batch 3899: loss 0.090539\n",
      "batch 3900: loss 0.059572\n",
      "batch 3901: loss 0.031402\n",
      "batch 3902: loss 0.091676\n",
      "batch 3903: loss 0.080421\n",
      "batch 3904: loss 0.060037\n",
      "batch 3905: loss 0.042643\n",
      "batch 3906: loss 0.071234\n",
      "batch 3907: loss 0.026966\n",
      "batch 3908: loss 0.100806\n",
      "batch 3909: loss 0.028551\n",
      "batch 3910: loss 0.016212\n",
      "batch 3911: loss 0.149068\n",
      "batch 3912: loss 0.287697\n",
      "batch 3913: loss 0.021705\n",
      "batch 3914: loss 0.068270\n",
      "batch 3915: loss 0.121027\n",
      "batch 3916: loss 0.026349\n",
      "batch 3917: loss 0.213738\n",
      "batch 3918: loss 0.092184\n",
      "batch 3919: loss 0.025430\n",
      "batch 3920: loss 0.057901\n",
      "batch 3921: loss 0.030061\n",
      "batch 3922: loss 0.052916\n",
      "batch 3923: loss 0.020877\n",
      "batch 3924: loss 0.063215\n",
      "batch 3925: loss 0.055653\n",
      "batch 3926: loss 0.042590\n",
      "batch 3927: loss 0.044100\n",
      "batch 3928: loss 0.160007\n",
      "batch 3929: loss 0.088986\n",
      "batch 3930: loss 0.011925\n",
      "batch 3931: loss 0.046432\n",
      "batch 3932: loss 0.111305\n",
      "batch 3933: loss 0.035642\n",
      "batch 3934: loss 0.071927\n",
      "batch 3935: loss 0.077100\n",
      "batch 3936: loss 0.065505\n",
      "batch 3937: loss 0.019960\n",
      "batch 3938: loss 0.083013\n",
      "batch 3939: loss 0.151002\n",
      "batch 3940: loss 0.081325\n",
      "batch 3941: loss 0.067025\n",
      "batch 3942: loss 0.010614\n",
      "batch 3943: loss 0.107649\n",
      "batch 3944: loss 0.049255\n",
      "batch 3945: loss 0.016715\n",
      "batch 3946: loss 0.031382\n",
      "batch 3947: loss 0.019847\n",
      "batch 3948: loss 0.149461\n",
      "batch 3949: loss 0.092014\n",
      "batch 3950: loss 0.018382\n",
      "batch 3951: loss 0.051366\n",
      "batch 3952: loss 0.073470\n",
      "batch 3953: loss 0.178826\n",
      "batch 3954: loss 0.123364\n",
      "batch 3955: loss 0.061792\n",
      "batch 3956: loss 0.034720\n",
      "batch 3957: loss 0.025862\n",
      "batch 3958: loss 0.015723\n",
      "batch 3959: loss 0.026100\n",
      "batch 3960: loss 0.063927\n",
      "batch 3961: loss 0.022783\n",
      "batch 3962: loss 0.017627\n",
      "batch 3963: loss 0.017300\n",
      "batch 3964: loss 0.034102\n",
      "batch 3965: loss 0.098722\n",
      "batch 3966: loss 0.028329\n",
      "batch 3967: loss 0.017111\n",
      "batch 3968: loss 0.164212\n",
      "batch 3969: loss 0.108116\n",
      "batch 3970: loss 0.010743\n",
      "batch 3971: loss 0.042277\n",
      "batch 3972: loss 0.009545\n",
      "batch 3973: loss 0.060492\n",
      "batch 3974: loss 0.017138\n",
      "batch 3975: loss 0.044878\n",
      "batch 3976: loss 0.198532\n",
      "batch 3977: loss 0.045665\n",
      "batch 3978: loss 0.089341\n",
      "batch 3979: loss 0.165601\n",
      "batch 3980: loss 0.084999\n",
      "batch 3981: loss 0.028329\n",
      "batch 3982: loss 0.079247\n",
      "batch 3983: loss 0.047072\n",
      "batch 3984: loss 0.021180\n",
      "batch 3985: loss 0.092807\n",
      "batch 3986: loss 0.039425\n",
      "batch 3987: loss 0.032426\n",
      "batch 3988: loss 0.039770\n",
      "batch 3989: loss 0.049432\n",
      "batch 3990: loss 0.045745\n",
      "batch 3991: loss 0.105015\n",
      "batch 3992: loss 0.036190\n",
      "batch 3993: loss 0.051569\n",
      "batch 3994: loss 0.030486\n",
      "batch 3995: loss 0.031147\n",
      "batch 3996: loss 0.051694\n",
      "batch 3997: loss 0.078052\n",
      "batch 3998: loss 0.018037\n",
      "batch 3999: loss 0.063878\n",
      "batch 4000: loss 0.107369\n",
      "batch 4001: loss 0.017058\n",
      "batch 4002: loss 0.065315\n",
      "batch 4003: loss 0.133365\n",
      "batch 4004: loss 0.076809\n",
      "batch 4005: loss 0.075350\n",
      "batch 4006: loss 0.021314\n",
      "batch 4007: loss 0.120227\n",
      "batch 4008: loss 0.089818\n",
      "batch 4009: loss 0.027170\n",
      "batch 4010: loss 0.110535\n",
      "batch 4011: loss 0.104919\n",
      "batch 4012: loss 0.086921\n",
      "batch 4013: loss 0.063221\n",
      "batch 4014: loss 0.240878\n",
      "batch 4015: loss 0.034082\n",
      "batch 4016: loss 0.068278\n",
      "batch 4017: loss 0.019798\n",
      "batch 4018: loss 0.061941\n",
      "batch 4019: loss 0.107186\n",
      "batch 4020: loss 0.067445\n",
      "batch 4021: loss 0.024847\n",
      "batch 4022: loss 0.062375\n",
      "batch 4023: loss 0.040711\n",
      "batch 4024: loss 0.088344\n",
      "batch 4025: loss 0.043186\n",
      "batch 4026: loss 0.136265\n",
      "batch 4027: loss 0.009737\n",
      "batch 4028: loss 0.046232\n",
      "batch 4029: loss 0.068902\n",
      "batch 4030: loss 0.240814\n",
      "batch 4031: loss 0.094619\n",
      "batch 4032: loss 0.021039\n",
      "batch 4033: loss 0.029039\n",
      "batch 4034: loss 0.160625\n",
      "batch 4035: loss 0.083235\n",
      "batch 4036: loss 0.144590\n",
      "batch 4037: loss 0.024796\n",
      "batch 4038: loss 0.043132\n",
      "batch 4039: loss 0.039560\n",
      "batch 4040: loss 0.024882\n",
      "batch 4041: loss 0.047459\n",
      "batch 4042: loss 0.165861\n",
      "batch 4043: loss 0.018224\n",
      "batch 4044: loss 0.045064\n",
      "batch 4045: loss 0.282988\n",
      "batch 4046: loss 0.029581\n",
      "batch 4047: loss 0.033211\n",
      "batch 4048: loss 0.085410\n",
      "batch 4049: loss 0.018318\n",
      "batch 4050: loss 0.009715\n",
      "batch 4051: loss 0.015749\n",
      "batch 4052: loss 0.074448\n",
      "batch 4053: loss 0.027714\n",
      "batch 4054: loss 0.151940\n",
      "batch 4055: loss 0.078842\n",
      "batch 4056: loss 0.048110\n",
      "batch 4057: loss 0.013550\n",
      "batch 4058: loss 0.071166\n",
      "batch 4059: loss 0.025840\n",
      "batch 4060: loss 0.010592\n",
      "batch 4061: loss 0.062287\n",
      "batch 4062: loss 0.031426\n",
      "batch 4063: loss 0.095684\n",
      "batch 4064: loss 0.148020\n",
      "batch 4065: loss 0.055006\n",
      "batch 4066: loss 0.096351\n",
      "batch 4067: loss 0.104462\n",
      "batch 4068: loss 0.033827\n",
      "batch 4069: loss 0.025762\n",
      "batch 4070: loss 0.030143\n",
      "batch 4071: loss 0.050860\n",
      "batch 4072: loss 0.035617\n",
      "batch 4073: loss 0.023989\n",
      "batch 4074: loss 0.146956\n",
      "batch 4075: loss 0.068437\n",
      "batch 4076: loss 0.124822\n",
      "batch 4077: loss 0.069257\n",
      "batch 4078: loss 0.083250\n",
      "batch 4079: loss 0.014233\n",
      "batch 4080: loss 0.152549\n",
      "batch 4081: loss 0.077747\n",
      "batch 4082: loss 0.064525\n",
      "batch 4083: loss 0.055905\n",
      "batch 4084: loss 0.116295\n",
      "batch 4085: loss 0.023283\n",
      "batch 4086: loss 0.013147\n",
      "batch 4087: loss 0.016212\n",
      "batch 4088: loss 0.040418\n",
      "batch 4089: loss 0.040283\n",
      "batch 4090: loss 0.115233\n",
      "batch 4091: loss 0.023286\n",
      "batch 4092: loss 0.034804\n",
      "batch 4093: loss 0.011996\n",
      "batch 4094: loss 0.021648\n",
      "batch 4095: loss 0.040073\n",
      "batch 4096: loss 0.040808\n",
      "batch 4097: loss 0.043609\n",
      "batch 4098: loss 0.025492\n",
      "batch 4099: loss 0.029313\n",
      "batch 4100: loss 0.012574\n",
      "batch 4101: loss 0.038563\n",
      "batch 4102: loss 0.036337\n",
      "batch 4103: loss 0.062084\n",
      "batch 4104: loss 0.103595\n",
      "batch 4105: loss 0.011554\n",
      "batch 4106: loss 0.110331\n",
      "batch 4107: loss 0.202486\n",
      "batch 4108: loss 0.156625\n",
      "batch 4109: loss 0.080408\n",
      "batch 4110: loss 0.080215\n",
      "batch 4111: loss 0.035383\n",
      "batch 4112: loss 0.018022\n",
      "batch 4113: loss 0.023502\n",
      "batch 4114: loss 0.243215\n",
      "batch 4115: loss 0.051569\n",
      "batch 4116: loss 0.005764\n",
      "batch 4117: loss 0.037011\n",
      "batch 4118: loss 0.016080\n",
      "batch 4119: loss 0.044110\n",
      "batch 4120: loss 0.037052\n",
      "batch 4121: loss 0.027043\n",
      "batch 4122: loss 0.051199\n",
      "batch 4123: loss 0.056908\n",
      "batch 4124: loss 0.058967\n",
      "batch 4125: loss 0.168250\n",
      "batch 4126: loss 0.043312\n",
      "batch 4127: loss 0.096739\n",
      "batch 4128: loss 0.081905\n",
      "batch 4129: loss 0.069751\n",
      "batch 4130: loss 0.019592\n",
      "batch 4131: loss 0.011159\n",
      "batch 4132: loss 0.056865\n",
      "batch 4133: loss 0.067476\n",
      "batch 4134: loss 0.016793\n",
      "batch 4135: loss 0.073278\n",
      "batch 4136: loss 0.260357\n",
      "batch 4137: loss 0.036116\n",
      "batch 4138: loss 0.040832\n",
      "batch 4139: loss 0.069383\n",
      "batch 4140: loss 0.039017\n",
      "batch 4141: loss 0.134644\n",
      "batch 4142: loss 0.218052\n",
      "batch 4143: loss 0.052090\n",
      "batch 4144: loss 0.033593\n",
      "batch 4145: loss 0.031694\n",
      "batch 4146: loss 0.012201\n",
      "batch 4147: loss 0.142814\n",
      "batch 4148: loss 0.038096\n",
      "batch 4149: loss 0.169943\n",
      "batch 4150: loss 0.202975\n",
      "batch 4151: loss 0.103145\n",
      "batch 4152: loss 0.033626\n",
      "batch 4153: loss 0.022346\n",
      "batch 4154: loss 0.062512\n",
      "batch 4155: loss 0.020932\n",
      "batch 4156: loss 0.057397\n",
      "batch 4157: loss 0.028983\n",
      "batch 4158: loss 0.078143\n",
      "batch 4159: loss 0.009809\n",
      "batch 4160: loss 0.059932\n",
      "batch 4161: loss 0.018184\n",
      "batch 4162: loss 0.027542\n",
      "batch 4163: loss 0.024069\n",
      "batch 4164: loss 0.032677\n",
      "batch 4165: loss 0.031462\n",
      "batch 4166: loss 0.030570\n",
      "batch 4167: loss 0.044136\n",
      "batch 4168: loss 0.009922\n",
      "batch 4169: loss 0.100120\n",
      "batch 4170: loss 0.024348\n",
      "batch 4171: loss 0.049505\n",
      "batch 4172: loss 0.116061\n",
      "batch 4173: loss 0.070022\n",
      "batch 4174: loss 0.073901\n",
      "batch 4175: loss 0.094977\n",
      "batch 4176: loss 0.043858\n",
      "batch 4177: loss 0.027354\n",
      "batch 4178: loss 0.093270\n",
      "batch 4179: loss 0.027614\n",
      "batch 4180: loss 0.110144\n",
      "batch 4181: loss 0.078291\n",
      "batch 4182: loss 0.116596\n",
      "batch 4183: loss 0.094379\n",
      "batch 4184: loss 0.079861\n",
      "batch 4185: loss 0.061025\n",
      "batch 4186: loss 0.052278\n",
      "batch 4187: loss 0.068470\n",
      "batch 4188: loss 0.036438\n",
      "batch 4189: loss 0.121193\n",
      "batch 4190: loss 0.066411\n",
      "batch 4191: loss 0.037054\n",
      "batch 4192: loss 0.033539\n",
      "batch 4193: loss 0.041911\n",
      "batch 4194: loss 0.012619\n",
      "batch 4195: loss 0.121263\n",
      "batch 4196: loss 0.028694\n",
      "batch 4197: loss 0.034576\n",
      "batch 4198: loss 0.031181\n",
      "batch 4199: loss 0.032672\n",
      "batch 4200: loss 0.063967\n",
      "batch 4201: loss 0.055629\n",
      "batch 4202: loss 0.054001\n",
      "batch 4203: loss 0.019090\n",
      "batch 4204: loss 0.016794\n",
      "batch 4205: loss 0.101938\n",
      "batch 4206: loss 0.020136\n",
      "batch 4207: loss 0.010868\n",
      "batch 4208: loss 0.072612\n",
      "batch 4209: loss 0.021893\n",
      "batch 4210: loss 0.024759\n",
      "batch 4211: loss 0.104780\n",
      "batch 4212: loss 0.027515\n",
      "batch 4213: loss 0.038699\n",
      "batch 4214: loss 0.127623\n",
      "batch 4215: loss 0.022926\n",
      "batch 4216: loss 0.027775\n",
      "batch 4217: loss 0.009050\n",
      "batch 4218: loss 0.165356\n",
      "batch 4219: loss 0.056571\n",
      "batch 4220: loss 0.049263\n",
      "batch 4221: loss 0.020511\n",
      "batch 4222: loss 0.057492\n",
      "batch 4223: loss 0.069880\n",
      "batch 4224: loss 0.084668\n",
      "batch 4225: loss 0.114218\n",
      "batch 4226: loss 0.026923\n",
      "batch 4227: loss 0.025806\n",
      "batch 4228: loss 0.056442\n",
      "batch 4229: loss 0.054397\n",
      "batch 4230: loss 0.198230\n",
      "batch 4231: loss 0.030126\n",
      "batch 4232: loss 0.049388\n",
      "batch 4233: loss 0.036379\n",
      "batch 4234: loss 0.070147\n",
      "batch 4235: loss 0.034129\n",
      "batch 4236: loss 0.041817\n",
      "batch 4237: loss 0.054895\n",
      "batch 4238: loss 0.029602\n",
      "batch 4239: loss 0.088970\n",
      "batch 4240: loss 0.035132\n",
      "batch 4241: loss 0.035825\n",
      "batch 4242: loss 0.111460\n",
      "batch 4243: loss 0.039041\n",
      "batch 4244: loss 0.170241\n",
      "batch 4245: loss 0.098304\n",
      "batch 4246: loss 0.038031\n",
      "batch 4247: loss 0.093403\n",
      "batch 4248: loss 0.067439\n",
      "batch 4249: loss 0.024526\n",
      "batch 4250: loss 0.014258\n",
      "batch 4251: loss 0.013984\n",
      "batch 4252: loss 0.097118\n",
      "batch 4253: loss 0.125053\n",
      "batch 4254: loss 0.052694\n",
      "batch 4255: loss 0.082522\n",
      "batch 4256: loss 0.025319\n",
      "batch 4257: loss 0.017925\n",
      "batch 4258: loss 0.033297\n",
      "batch 4259: loss 0.020978\n",
      "batch 4260: loss 0.210877\n",
      "batch 4261: loss 0.051886\n",
      "batch 4262: loss 0.101297\n",
      "batch 4263: loss 0.024880\n",
      "batch 4264: loss 0.045190\n",
      "batch 4265: loss 0.066787\n",
      "batch 4266: loss 0.030417\n",
      "batch 4267: loss 0.145596\n",
      "batch 4268: loss 0.082445\n",
      "batch 4269: loss 0.090376\n",
      "batch 4270: loss 0.056749\n",
      "batch 4271: loss 0.038192\n",
      "batch 4272: loss 0.078953\n",
      "batch 4273: loss 0.027205\n",
      "batch 4274: loss 0.028332\n",
      "batch 4275: loss 0.049005\n",
      "batch 4276: loss 0.081437\n",
      "batch 4277: loss 0.038279\n",
      "batch 4278: loss 0.114312\n",
      "batch 4279: loss 0.045355\n",
      "batch 4280: loss 0.280410\n",
      "batch 4281: loss 0.029365\n",
      "batch 4282: loss 0.171193\n",
      "batch 4283: loss 0.012605\n",
      "batch 4284: loss 0.093855\n",
      "batch 4285: loss 0.023516\n",
      "batch 4286: loss 0.264199\n",
      "batch 4287: loss 0.201072\n",
      "batch 4288: loss 0.109581\n",
      "batch 4289: loss 0.012515\n",
      "batch 4290: loss 0.058061\n",
      "batch 4291: loss 0.106864\n",
      "batch 4292: loss 0.113133\n",
      "batch 4293: loss 0.045321\n",
      "batch 4294: loss 0.121048\n",
      "batch 4295: loss 0.012077\n",
      "batch 4296: loss 0.050099\n",
      "batch 4297: loss 0.074575\n",
      "batch 4298: loss 0.033153\n",
      "batch 4299: loss 0.088799\n",
      "batch 4300: loss 0.098647\n",
      "batch 4301: loss 0.191936\n",
      "batch 4302: loss 0.039692\n",
      "batch 4303: loss 0.077334\n",
      "batch 4304: loss 0.105449\n",
      "batch 4305: loss 0.136374\n",
      "batch 4306: loss 0.186118\n",
      "batch 4307: loss 0.098241\n",
      "batch 4308: loss 0.026751\n",
      "batch 4309: loss 0.022714\n",
      "batch 4310: loss 0.208058\n",
      "batch 4311: loss 0.045072\n",
      "batch 4312: loss 0.042191\n",
      "batch 4313: loss 0.120545\n",
      "batch 4314: loss 0.061863\n",
      "batch 4315: loss 0.080573\n",
      "batch 4316: loss 0.203217\n",
      "batch 4317: loss 0.152934\n",
      "batch 4318: loss 0.032757\n",
      "batch 4319: loss 0.028440\n",
      "batch 4320: loss 0.010329\n",
      "batch 4321: loss 0.022681\n",
      "batch 4322: loss 0.024831\n",
      "batch 4323: loss 0.187937\n",
      "batch 4324: loss 0.071306\n",
      "batch 4325: loss 0.058630\n",
      "batch 4326: loss 0.018656\n",
      "batch 4327: loss 0.064613\n",
      "batch 4328: loss 0.021099\n",
      "batch 4329: loss 0.015910\n",
      "batch 4330: loss 0.196749\n",
      "batch 4331: loss 0.050550\n",
      "batch 4332: loss 0.011712\n",
      "batch 4333: loss 0.029287\n",
      "batch 4334: loss 0.112335\n",
      "batch 4335: loss 0.111313\n",
      "batch 4336: loss 0.063762\n",
      "batch 4337: loss 0.107429\n",
      "batch 4338: loss 0.089416\n",
      "batch 4339: loss 0.016413\n",
      "batch 4340: loss 0.104138\n",
      "batch 4341: loss 0.152222\n",
      "batch 4342: loss 0.026453\n",
      "batch 4343: loss 0.047773\n",
      "batch 4344: loss 0.133173\n",
      "batch 4345: loss 0.035334\n",
      "batch 4346: loss 0.094140\n",
      "batch 4347: loss 0.085653\n",
      "batch 4348: loss 0.064478\n",
      "batch 4349: loss 0.019753\n",
      "batch 4350: loss 0.055455\n",
      "batch 4351: loss 0.093907\n",
      "batch 4352: loss 0.105303\n",
      "batch 4353: loss 0.029370\n",
      "batch 4354: loss 0.025895\n",
      "batch 4355: loss 0.031982\n",
      "batch 4356: loss 0.043547\n",
      "batch 4357: loss 0.020289\n",
      "batch 4358: loss 0.059443\n",
      "batch 4359: loss 0.119490\n",
      "batch 4360: loss 0.121171\n",
      "batch 4361: loss 0.115523\n",
      "batch 4362: loss 0.090860\n",
      "batch 4363: loss 0.089882\n",
      "batch 4364: loss 0.007122\n",
      "batch 4365: loss 0.099395\n",
      "batch 4366: loss 0.018151\n",
      "batch 4367: loss 0.019194\n",
      "batch 4368: loss 0.093040\n",
      "batch 4369: loss 0.086788\n",
      "batch 4370: loss 0.016913\n",
      "batch 4371: loss 0.104821\n",
      "batch 4372: loss 0.032723\n",
      "batch 4373: loss 0.011644\n",
      "batch 4374: loss 0.063435\n",
      "batch 4375: loss 0.178748\n",
      "batch 4376: loss 0.095031\n",
      "batch 4377: loss 0.094182\n",
      "batch 4378: loss 0.060030\n",
      "batch 4379: loss 0.084501\n",
      "batch 4380: loss 0.101152\n",
      "batch 4381: loss 0.064565\n",
      "batch 4382: loss 0.021469\n",
      "batch 4383: loss 0.138676\n",
      "batch 4384: loss 0.028108\n",
      "batch 4385: loss 0.239589\n",
      "batch 4386: loss 0.038974\n",
      "batch 4387: loss 0.026198\n",
      "batch 4388: loss 0.044969\n",
      "batch 4389: loss 0.089225\n",
      "batch 4390: loss 0.042497\n",
      "batch 4391: loss 0.234375\n",
      "batch 4392: loss 0.094983\n",
      "batch 4393: loss 0.071042\n",
      "batch 4394: loss 0.144799\n",
      "batch 4395: loss 0.041227\n",
      "batch 4396: loss 0.122418\n",
      "batch 4397: loss 0.196605\n",
      "batch 4398: loss 0.071087\n",
      "batch 4399: loss 0.042146\n",
      "batch 4400: loss 0.097154\n",
      "batch 4401: loss 0.049896\n",
      "batch 4402: loss 0.079467\n",
      "batch 4403: loss 0.200671\n",
      "batch 4404: loss 0.055155\n",
      "batch 4405: loss 0.084627\n",
      "batch 4406: loss 0.037813\n",
      "batch 4407: loss 0.037378\n",
      "batch 4408: loss 0.104879\n",
      "batch 4409: loss 0.359503\n",
      "batch 4410: loss 0.042335\n",
      "batch 4411: loss 0.050792\n",
      "batch 4412: loss 0.054467\n",
      "batch 4413: loss 0.108014\n",
      "batch 4414: loss 0.025853\n",
      "batch 4415: loss 0.186901\n",
      "batch 4416: loss 0.062161\n",
      "batch 4417: loss 0.085667\n",
      "batch 4418: loss 0.073591\n",
      "batch 4419: loss 0.026807\n",
      "batch 4420: loss 0.029952\n",
      "batch 4421: loss 0.044306\n",
      "batch 4422: loss 0.155360\n",
      "batch 4423: loss 0.026815\n",
      "batch 4424: loss 0.091095\n",
      "batch 4425: loss 0.032507\n",
      "batch 4426: loss 0.016069\n",
      "batch 4427: loss 0.071888\n",
      "batch 4428: loss 0.011043\n",
      "batch 4429: loss 0.028137\n",
      "batch 4430: loss 0.124240\n",
      "batch 4431: loss 0.055434\n",
      "batch 4432: loss 0.034492\n",
      "batch 4433: loss 0.092140\n",
      "batch 4434: loss 0.074054\n",
      "batch 4435: loss 0.100669\n",
      "batch 4436: loss 0.014944\n",
      "batch 4437: loss 0.046123\n",
      "batch 4438: loss 0.084201\n",
      "batch 4439: loss 0.071019\n",
      "batch 4440: loss 0.066251\n",
      "batch 4441: loss 0.040368\n",
      "batch 4442: loss 0.021354\n",
      "batch 4443: loss 0.137964\n",
      "batch 4444: loss 0.273096\n",
      "batch 4445: loss 0.058630\n",
      "batch 4446: loss 0.166808\n",
      "batch 4447: loss 0.049412\n",
      "batch 4448: loss 0.008893\n",
      "batch 4449: loss 0.078823\n",
      "batch 4450: loss 0.160548\n",
      "batch 4451: loss 0.013031\n",
      "batch 4452: loss 0.037854\n",
      "batch 4453: loss 0.044730\n",
      "batch 4454: loss 0.083948\n",
      "batch 4455: loss 0.011996\n",
      "batch 4456: loss 0.015293\n",
      "batch 4457: loss 0.081876\n",
      "batch 4458: loss 0.044806\n",
      "batch 4459: loss 0.045197\n",
      "batch 4460: loss 0.162683\n",
      "batch 4461: loss 0.100964\n",
      "batch 4462: loss 0.079187\n",
      "batch 4463: loss 0.060997\n",
      "batch 4464: loss 0.006516\n",
      "batch 4465: loss 0.041508\n",
      "batch 4466: loss 0.020316\n",
      "batch 4467: loss 0.052016\n",
      "batch 4468: loss 0.014887\n",
      "batch 4469: loss 0.026400\n",
      "batch 4470: loss 0.080016\n",
      "batch 4471: loss 0.032920\n",
      "batch 4472: loss 0.060706\n",
      "batch 4473: loss 0.034913\n",
      "batch 4474: loss 0.007165\n",
      "batch 4475: loss 0.019091\n",
      "batch 4476: loss 0.065910\n",
      "batch 4477: loss 0.021663\n",
      "batch 4478: loss 0.055570\n",
      "batch 4479: loss 0.049860\n",
      "batch 4480: loss 0.086456\n",
      "batch 4481: loss 0.010507\n",
      "batch 4482: loss 0.042307\n",
      "batch 4483: loss 0.066337\n",
      "batch 4484: loss 0.010053\n",
      "batch 4485: loss 0.075453\n",
      "batch 4486: loss 0.053280\n",
      "batch 4487: loss 0.029741\n",
      "batch 4488: loss 0.098131\n",
      "batch 4489: loss 0.095543\n",
      "batch 4490: loss 0.104449\n",
      "batch 4491: loss 0.030720\n",
      "batch 4492: loss 0.077790\n",
      "batch 4493: loss 0.151310\n",
      "batch 4494: loss 0.042771\n",
      "batch 4495: loss 0.163987\n",
      "batch 4496: loss 0.099394\n",
      "batch 4497: loss 0.018110\n",
      "batch 4498: loss 0.046340\n",
      "batch 4499: loss 0.027575\n",
      "batch 4500: loss 0.032341\n",
      "batch 4501: loss 0.010788\n",
      "batch 4502: loss 0.172819\n",
      "batch 4503: loss 0.036104\n",
      "batch 4504: loss 0.065781\n",
      "batch 4505: loss 0.047860\n",
      "batch 4506: loss 0.013137\n",
      "batch 4507: loss 0.108438\n",
      "batch 4508: loss 0.020371\n",
      "batch 4509: loss 0.031772\n",
      "batch 4510: loss 0.025071\n",
      "batch 4511: loss 0.036624\n",
      "batch 4512: loss 0.024859\n",
      "batch 4513: loss 0.065112\n",
      "batch 4514: loss 0.053658\n",
      "batch 4515: loss 0.049479\n",
      "batch 4516: loss 0.111419\n",
      "batch 4517: loss 0.029739\n",
      "batch 4518: loss 0.155259\n",
      "batch 4519: loss 0.064110\n",
      "batch 4520: loss 0.023245\n",
      "batch 4521: loss 0.051879\n",
      "batch 4522: loss 0.015465\n",
      "batch 4523: loss 0.032972\n",
      "batch 4524: loss 0.091544\n",
      "batch 4525: loss 0.096006\n",
      "batch 4526: loss 0.049457\n",
      "batch 4527: loss 0.054215\n",
      "batch 4528: loss 0.070639\n",
      "batch 4529: loss 0.023142\n",
      "batch 4530: loss 0.076602\n",
      "batch 4531: loss 0.085155\n",
      "batch 4532: loss 0.028787\n",
      "batch 4533: loss 0.036044\n",
      "batch 4534: loss 0.055263\n",
      "batch 4535: loss 0.032175\n",
      "batch 4536: loss 0.023407\n",
      "batch 4537: loss 0.008450\n",
      "batch 4538: loss 0.015778\n",
      "batch 4539: loss 0.032573\n",
      "batch 4540: loss 0.010861\n",
      "batch 4541: loss 0.130010\n",
      "batch 4542: loss 0.012192\n",
      "batch 4543: loss 0.019954\n",
      "batch 4544: loss 0.013477\n",
      "batch 4545: loss 0.088395\n",
      "batch 4546: loss 0.038227\n",
      "batch 4547: loss 0.031660\n",
      "batch 4548: loss 0.168496\n",
      "batch 4549: loss 0.036639\n",
      "batch 4550: loss 0.102891\n",
      "batch 4551: loss 0.099097\n",
      "batch 4552: loss 0.094111\n",
      "batch 4553: loss 0.040132\n",
      "batch 4554: loss 0.028471\n",
      "batch 4555: loss 0.028467\n",
      "batch 4556: loss 0.069227\n",
      "batch 4557: loss 0.067762\n",
      "batch 4558: loss 0.008052\n",
      "batch 4559: loss 0.026709\n",
      "batch 4560: loss 0.081124\n",
      "batch 4561: loss 0.047191\n",
      "batch 4562: loss 0.012784\n",
      "batch 4563: loss 0.106652\n",
      "batch 4564: loss 0.023883\n",
      "batch 4565: loss 0.050714\n",
      "batch 4566: loss 0.108784\n",
      "batch 4567: loss 0.066303\n",
      "batch 4568: loss 0.090321\n",
      "batch 4569: loss 0.069097\n",
      "batch 4570: loss 0.060434\n",
      "batch 4571: loss 0.045543\n",
      "batch 4572: loss 0.039802\n",
      "batch 4573: loss 0.223406\n",
      "batch 4574: loss 0.067940\n",
      "batch 4575: loss 0.096096\n",
      "batch 4576: loss 0.030764\n",
      "batch 4577: loss 0.024669\n",
      "batch 4578: loss 0.101815\n",
      "batch 4579: loss 0.140765\n",
      "batch 4580: loss 0.014577\n",
      "batch 4581: loss 0.114143\n",
      "batch 4582: loss 0.055311\n",
      "batch 4583: loss 0.032176\n",
      "batch 4584: loss 0.030481\n",
      "batch 4585: loss 0.072150\n",
      "batch 4586: loss 0.052974\n",
      "batch 4587: loss 0.090104\n",
      "batch 4588: loss 0.013065\n",
      "batch 4589: loss 0.026878\n",
      "batch 4590: loss 0.052569\n",
      "batch 4591: loss 0.024143\n",
      "batch 4592: loss 0.126002\n",
      "batch 4593: loss 0.030466\n",
      "batch 4594: loss 0.016073\n",
      "batch 4595: loss 0.054686\n",
      "batch 4596: loss 0.066967\n",
      "batch 4597: loss 0.056272\n",
      "batch 4598: loss 0.066965\n",
      "batch 4599: loss 0.037827\n",
      "batch 4600: loss 0.046917\n",
      "batch 4601: loss 0.007089\n",
      "batch 4602: loss 0.021880\n",
      "batch 4603: loss 0.057453\n",
      "batch 4604: loss 0.099508\n",
      "batch 4605: loss 0.013380\n",
      "batch 4606: loss 0.016564\n",
      "batch 4607: loss 0.025500\n",
      "batch 4608: loss 0.034941\n",
      "batch 4609: loss 0.110723\n",
      "batch 4610: loss 0.023440\n",
      "batch 4611: loss 0.031124\n",
      "batch 4612: loss 0.044305\n",
      "batch 4613: loss 0.168771\n",
      "batch 4614: loss 0.070487\n",
      "batch 4615: loss 0.012196\n",
      "batch 4616: loss 0.018992\n",
      "batch 4617: loss 0.155992\n",
      "batch 4618: loss 0.039360\n",
      "batch 4619: loss 0.018045\n",
      "batch 4620: loss 0.057273\n",
      "batch 4621: loss 0.055915\n",
      "batch 4622: loss 0.137737\n",
      "batch 4623: loss 0.083681\n",
      "batch 4624: loss 0.094664\n",
      "batch 4625: loss 0.059923\n",
      "batch 4626: loss 0.051896\n",
      "batch 4627: loss 0.052322\n",
      "batch 4628: loss 0.063411\n",
      "batch 4629: loss 0.169422\n",
      "batch 4630: loss 0.051723\n",
      "batch 4631: loss 0.036875\n",
      "batch 4632: loss 0.022083\n",
      "batch 4633: loss 0.121328\n",
      "batch 4634: loss 0.039044\n",
      "batch 4635: loss 0.011390\n",
      "batch 4636: loss 0.104353\n",
      "batch 4637: loss 0.011759\n",
      "batch 4638: loss 0.085270\n",
      "batch 4639: loss 0.056657\n",
      "batch 4640: loss 0.015071\n",
      "batch 4641: loss 0.158927\n",
      "batch 4642: loss 0.052256\n",
      "batch 4643: loss 0.070012\n",
      "batch 4644: loss 0.044866\n",
      "batch 4645: loss 0.050564\n",
      "batch 4646: loss 0.062543\n",
      "batch 4647: loss 0.049503\n",
      "batch 4648: loss 0.112320\n",
      "batch 4649: loss 0.072179\n",
      "batch 4650: loss 0.080378\n",
      "batch 4651: loss 0.088997\n",
      "batch 4652: loss 0.030903\n",
      "batch 4653: loss 0.116215\n",
      "batch 4654: loss 0.023699\n",
      "batch 4655: loss 0.014023\n",
      "batch 4656: loss 0.015343\n",
      "batch 4657: loss 0.123055\n",
      "batch 4658: loss 0.230287\n",
      "batch 4659: loss 0.079738\n",
      "batch 4660: loss 0.034877\n",
      "batch 4661: loss 0.029492\n",
      "batch 4662: loss 0.038927\n",
      "batch 4663: loss 0.056998\n",
      "batch 4664: loss 0.032622\n",
      "batch 4665: loss 0.046884\n",
      "batch 4666: loss 0.047500\n",
      "batch 4667: loss 0.031908\n",
      "batch 4668: loss 0.012713\n",
      "batch 4669: loss 0.069062\n",
      "batch 4670: loss 0.201234\n",
      "batch 4671: loss 0.079138\n",
      "batch 4672: loss 0.106432\n",
      "batch 4673: loss 0.053451\n",
      "batch 4674: loss 0.156960\n",
      "batch 4675: loss 0.118392\n",
      "batch 4676: loss 0.089006\n",
      "batch 4677: loss 0.074952\n",
      "batch 4678: loss 0.080031\n",
      "batch 4679: loss 0.036832\n",
      "batch 4680: loss 0.088770\n",
      "batch 4681: loss 0.088663\n",
      "batch 4682: loss 0.186573\n",
      "batch 4683: loss 0.010726\n",
      "batch 4684: loss 0.012908\n",
      "batch 4685: loss 0.021980\n",
      "batch 4686: loss 0.085684\n",
      "batch 4687: loss 0.019400\n",
      "batch 4688: loss 0.020273\n",
      "batch 4689: loss 0.019536\n",
      "batch 4690: loss 0.046320\n",
      "batch 4691: loss 0.037101\n",
      "batch 4692: loss 0.036982\n",
      "batch 4693: loss 0.062887\n",
      "batch 4694: loss 0.179082\n",
      "batch 4695: loss 0.016728\n",
      "batch 4696: loss 0.036290\n",
      "batch 4697: loss 0.079870\n",
      "batch 4698: loss 0.033611\n",
      "batch 4699: loss 0.040801\n",
      "batch 4700: loss 0.056086\n",
      "batch 4701: loss 0.009776\n",
      "batch 4702: loss 0.050277\n",
      "batch 4703: loss 0.042263\n",
      "batch 4704: loss 0.103989\n",
      "batch 4705: loss 0.047666\n",
      "batch 4706: loss 0.056409\n",
      "batch 4707: loss 0.078563\n",
      "batch 4708: loss 0.092661\n",
      "batch 4709: loss 0.029944\n",
      "batch 4710: loss 0.019457\n",
      "batch 4711: loss 0.146076\n",
      "batch 4712: loss 0.026677\n",
      "batch 4713: loss 0.093151\n",
      "batch 4714: loss 0.019231\n",
      "batch 4715: loss 0.041439\n",
      "batch 4716: loss 0.080136\n",
      "batch 4717: loss 0.010337\n",
      "batch 4718: loss 0.094987\n",
      "batch 4719: loss 0.106420\n",
      "batch 4720: loss 0.034649\n",
      "batch 4721: loss 0.052458\n",
      "batch 4722: loss 0.015950\n",
      "batch 4723: loss 0.020024\n",
      "batch 4724: loss 0.063007\n",
      "batch 4725: loss 0.035840\n",
      "batch 4726: loss 0.025345\n",
      "batch 4727: loss 0.079833\n",
      "batch 4728: loss 0.036193\n",
      "batch 4729: loss 0.085705\n",
      "batch 4730: loss 0.098688\n",
      "batch 4731: loss 0.009309\n",
      "batch 4732: loss 0.052039\n",
      "batch 4733: loss 0.101911\n",
      "batch 4734: loss 0.012058\n",
      "batch 4735: loss 0.010120\n",
      "batch 4736: loss 0.021645\n",
      "batch 4737: loss 0.091934\n",
      "batch 4738: loss 0.038469\n",
      "batch 4739: loss 0.104023\n",
      "batch 4740: loss 0.095530\n",
      "batch 4741: loss 0.125661\n",
      "batch 4742: loss 0.039686\n",
      "batch 4743: loss 0.059877\n",
      "batch 4744: loss 0.046033\n",
      "batch 4745: loss 0.041591\n",
      "batch 4746: loss 0.064125\n",
      "batch 4747: loss 0.019644\n",
      "batch 4748: loss 0.036442\n",
      "batch 4749: loss 0.149722\n",
      "batch 4750: loss 0.055788\n",
      "batch 4751: loss 0.168237\n",
      "batch 4752: loss 0.006602\n",
      "batch 4753: loss 0.008671\n",
      "batch 4754: loss 0.158841\n",
      "batch 4755: loss 0.119690\n",
      "batch 4756: loss 0.261532\n",
      "batch 4757: loss 0.189246\n",
      "batch 4758: loss 0.036806\n",
      "batch 4759: loss 0.044932\n",
      "batch 4760: loss 0.122907\n",
      "batch 4761: loss 0.056965\n",
      "batch 4762: loss 0.015173\n",
      "batch 4763: loss 0.035458\n",
      "batch 4764: loss 0.079013\n",
      "batch 4765: loss 0.097796\n",
      "batch 4766: loss 0.255749\n",
      "batch 4767: loss 0.097251\n",
      "batch 4768: loss 0.137249\n",
      "batch 4769: loss 0.035827\n",
      "batch 4770: loss 0.008004\n",
      "batch 4771: loss 0.096414\n",
      "batch 4772: loss 0.029982\n",
      "batch 4773: loss 0.013900\n",
      "batch 4774: loss 0.052228\n",
      "batch 4775: loss 0.036472\n",
      "batch 4776: loss 0.033692\n",
      "batch 4777: loss 0.053079\n",
      "batch 4778: loss 0.007781\n",
      "batch 4779: loss 0.022241\n",
      "batch 4780: loss 0.035858\n",
      "batch 4781: loss 0.162971\n",
      "batch 4782: loss 0.087733\n",
      "batch 4783: loss 0.112193\n",
      "batch 4784: loss 0.038159\n",
      "batch 4785: loss 0.015901\n",
      "batch 4786: loss 0.026310\n",
      "batch 4787: loss 0.074286\n",
      "batch 4788: loss 0.036621\n",
      "batch 4789: loss 0.119199\n",
      "batch 4790: loss 0.117911\n",
      "batch 4791: loss 0.171902\n",
      "batch 4792: loss 0.014947\n",
      "batch 4793: loss 0.060078\n",
      "batch 4794: loss 0.020346\n",
      "batch 4795: loss 0.036720\n",
      "batch 4796: loss 0.052850\n",
      "batch 4797: loss 0.041447\n",
      "batch 4798: loss 0.032260\n",
      "batch 4799: loss 0.093821\n",
      "batch 4800: loss 0.128712\n",
      "batch 4801: loss 0.013567\n",
      "batch 4802: loss 0.049046\n",
      "batch 4803: loss 0.070926\n",
      "batch 4804: loss 0.016453\n",
      "batch 4805: loss 0.083013\n",
      "batch 4806: loss 0.075990\n",
      "batch 4807: loss 0.016627\n",
      "batch 4808: loss 0.043088\n",
      "batch 4809: loss 0.014281\n",
      "batch 4810: loss 0.105461\n",
      "batch 4811: loss 0.031006\n",
      "batch 4812: loss 0.056301\n",
      "batch 4813: loss 0.044069\n",
      "batch 4814: loss 0.062976\n",
      "batch 4815: loss 0.053726\n",
      "batch 4816: loss 0.187430\n",
      "batch 4817: loss 0.205005\n",
      "batch 4818: loss 0.017967\n",
      "batch 4819: loss 0.037856\n",
      "batch 4820: loss 0.028505\n",
      "batch 4821: loss 0.038099\n",
      "batch 4822: loss 0.084085\n",
      "batch 4823: loss 0.118319\n",
      "batch 4824: loss 0.046616\n",
      "batch 4825: loss 0.049863\n",
      "batch 4826: loss 0.009117\n",
      "batch 4827: loss 0.022149\n",
      "batch 4828: loss 0.016912\n",
      "batch 4829: loss 0.064445\n",
      "batch 4830: loss 0.068601\n",
      "batch 4831: loss 0.064295\n",
      "batch 4832: loss 0.065443\n",
      "batch 4833: loss 0.053534\n",
      "batch 4834: loss 0.066952\n",
      "batch 4835: loss 0.140454\n",
      "batch 4836: loss 0.129848\n",
      "batch 4837: loss 0.028837\n",
      "batch 4838: loss 0.028006\n",
      "batch 4839: loss 0.112528\n",
      "batch 4840: loss 0.144156\n",
      "batch 4841: loss 0.050641\n",
      "batch 4842: loss 0.008825\n",
      "batch 4843: loss 0.041035\n",
      "batch 4844: loss 0.109681\n",
      "batch 4845: loss 0.067921\n",
      "batch 4846: loss 0.040927\n",
      "batch 4847: loss 0.071044\n",
      "batch 4848: loss 0.031649\n",
      "batch 4849: loss 0.064040\n",
      "batch 4850: loss 0.061621\n",
      "batch 4851: loss 0.074186\n",
      "batch 4852: loss 0.019951\n",
      "batch 4853: loss 0.076593\n",
      "batch 4854: loss 0.026399\n",
      "batch 4855: loss 0.009817\n",
      "batch 4856: loss 0.081607\n",
      "batch 4857: loss 0.015654\n",
      "batch 4858: loss 0.065499\n",
      "batch 4859: loss 0.026631\n",
      "batch 4860: loss 0.092057\n",
      "batch 4861: loss 0.050768\n",
      "batch 4862: loss 0.017087\n",
      "batch 4863: loss 0.017769\n",
      "batch 4864: loss 0.084876\n",
      "batch 4865: loss 0.131372\n",
      "batch 4866: loss 0.084049\n",
      "batch 4867: loss 0.036028\n",
      "batch 4868: loss 0.025037\n",
      "batch 4869: loss 0.091521\n",
      "batch 4870: loss 0.019386\n",
      "batch 4871: loss 0.162100\n",
      "batch 4872: loss 0.114902\n",
      "batch 4873: loss 0.051623\n",
      "batch 4874: loss 0.050571\n",
      "batch 4875: loss 0.023215\n",
      "batch 4876: loss 0.021685\n",
      "batch 4877: loss 0.034365\n",
      "batch 4878: loss 0.091946\n",
      "batch 4879: loss 0.021178\n",
      "batch 4880: loss 0.076962\n",
      "batch 4881: loss 0.007043\n",
      "batch 4882: loss 0.067199\n",
      "batch 4883: loss 0.085488\n",
      "batch 4884: loss 0.082923\n",
      "batch 4885: loss 0.021203\n",
      "batch 4886: loss 0.068113\n",
      "batch 4887: loss 0.040221\n",
      "batch 4888: loss 0.020480\n",
      "batch 4889: loss 0.087354\n",
      "batch 4890: loss 0.094778\n",
      "batch 4891: loss 0.034214\n",
      "batch 4892: loss 0.019393\n",
      "batch 4893: loss 0.026096\n",
      "batch 4894: loss 0.118116\n",
      "batch 4895: loss 0.035144\n",
      "batch 4896: loss 0.046021\n",
      "batch 4897: loss 0.047447\n",
      "batch 4898: loss 0.034535\n",
      "batch 4899: loss 0.072640\n",
      "batch 4900: loss 0.099463\n",
      "batch 4901: loss 0.129775\n",
      "batch 4902: loss 0.085363\n",
      "batch 4903: loss 0.021579\n",
      "batch 4904: loss 0.069015\n",
      "batch 4905: loss 0.025396\n",
      "batch 4906: loss 0.115769\n",
      "batch 4907: loss 0.009730\n",
      "batch 4908: loss 0.030019\n",
      "batch 4909: loss 0.115774\n",
      "batch 4910: loss 0.014535\n",
      "batch 4911: loss 0.048896\n",
      "batch 4912: loss 0.018935\n",
      "batch 4913: loss 0.111427\n",
      "batch 4914: loss 0.056371\n",
      "batch 4915: loss 0.132346\n",
      "batch 4916: loss 0.039594\n",
      "batch 4917: loss 0.051369\n",
      "batch 4918: loss 0.086309\n",
      "batch 4919: loss 0.057338\n",
      "batch 4920: loss 0.031405\n",
      "batch 4921: loss 0.248657\n",
      "batch 4922: loss 0.183186\n",
      "batch 4923: loss 0.041257\n",
      "batch 4924: loss 0.009377\n",
      "batch 4925: loss 0.173270\n",
      "batch 4926: loss 0.076990\n",
      "batch 4927: loss 0.112737\n",
      "batch 4928: loss 0.059203\n",
      "batch 4929: loss 0.025857\n",
      "batch 4930: loss 0.049073\n",
      "batch 4931: loss 0.019522\n",
      "batch 4932: loss 0.026895\n",
      "batch 4933: loss 0.022746\n",
      "batch 4934: loss 0.033874\n",
      "batch 4935: loss 0.111467\n",
      "batch 4936: loss 0.064248\n",
      "batch 4937: loss 0.004498\n",
      "batch 4938: loss 0.074024\n",
      "batch 4939: loss 0.020515\n",
      "batch 4940: loss 0.036666\n",
      "batch 4941: loss 0.036736\n",
      "batch 4942: loss 0.129989\n",
      "batch 4943: loss 0.211215\n",
      "batch 4944: loss 0.066839\n",
      "batch 4945: loss 0.070109\n",
      "batch 4946: loss 0.015832\n",
      "batch 4947: loss 0.104254\n",
      "batch 4948: loss 0.017904\n",
      "batch 4949: loss 0.022330\n",
      "batch 4950: loss 0.031925\n",
      "batch 4951: loss 0.037710\n",
      "batch 4952: loss 0.029300\n",
      "batch 4953: loss 0.030525\n",
      "batch 4954: loss 0.047843\n",
      "batch 4955: loss 0.018322\n",
      "batch 4956: loss 0.009292\n",
      "batch 4957: loss 0.019295\n",
      "batch 4958: loss 0.178928\n",
      "batch 4959: loss 0.135022\n",
      "batch 4960: loss 0.122249\n",
      "batch 4961: loss 0.037201\n",
      "batch 4962: loss 0.089647\n",
      "batch 4963: loss 0.022553\n",
      "batch 4964: loss 0.095265\n",
      "batch 4965: loss 0.199133\n",
      "batch 4966: loss 0.134087\n",
      "batch 4967: loss 0.122174\n",
      "batch 4968: loss 0.097500\n",
      "batch 4969: loss 0.099123\n",
      "batch 4970: loss 0.104263\n",
      "batch 4971: loss 0.008501\n",
      "batch 4972: loss 0.009429\n",
      "batch 4973: loss 0.052673\n",
      "batch 4974: loss 0.025128\n",
      "batch 4975: loss 0.073957\n",
      "batch 4976: loss 0.071531\n",
      "batch 4977: loss 0.073035\n",
      "batch 4978: loss 0.112723\n",
      "batch 4979: loss 0.025720\n",
      "batch 4980: loss 0.131755\n",
      "batch 4981: loss 0.020989\n",
      "batch 4982: loss 0.024024\n",
      "batch 4983: loss 0.073854\n",
      "batch 4984: loss 0.175505\n",
      "batch 4985: loss 0.038962\n",
      "batch 4986: loss 0.030334\n",
      "batch 4987: loss 0.073001\n",
      "batch 4988: loss 0.105511\n",
      "batch 4989: loss 0.102569\n",
      "batch 4990: loss 0.068215\n",
      "batch 4991: loss 0.008326\n",
      "batch 4992: loss 0.023286\n",
      "batch 4993: loss 0.135186\n",
      "batch 4994: loss 0.056828\n",
      "batch 4995: loss 0.042246\n",
      "batch 4996: loss 0.055637\n",
      "batch 4997: loss 0.178904\n",
      "batch 4998: loss 0.066551\n",
      "batch 4999: loss 0.053441\n",
      "batch 5000: loss 0.028850\n",
      "batch 5001: loss 0.088131\n",
      "batch 5002: loss 0.040721\n",
      "batch 5003: loss 0.085497\n",
      "batch 5004: loss 0.009506\n",
      "batch 5005: loss 0.009876\n",
      "batch 5006: loss 0.011460\n",
      "batch 5007: loss 0.031110\n",
      "batch 5008: loss 0.058142\n",
      "batch 5009: loss 0.026400\n",
      "batch 5010: loss 0.010011\n",
      "batch 5011: loss 0.092928\n",
      "batch 5012: loss 0.138878\n",
      "batch 5013: loss 0.138896\n",
      "batch 5014: loss 0.086096\n",
      "batch 5015: loss 0.028122\n",
      "batch 5016: loss 0.034773\n",
      "batch 5017: loss 0.036653\n",
      "batch 5018: loss 0.033446\n",
      "batch 5019: loss 0.027146\n",
      "batch 5020: loss 0.126757\n",
      "batch 5021: loss 0.012749\n",
      "batch 5022: loss 0.054300\n",
      "batch 5023: loss 0.036602\n",
      "batch 5024: loss 0.013189\n",
      "batch 5025: loss 0.017937\n",
      "batch 5026: loss 0.044180\n",
      "batch 5027: loss 0.071706\n",
      "batch 5028: loss 0.032391\n",
      "batch 5029: loss 0.081595\n",
      "batch 5030: loss 0.028434\n",
      "batch 5031: loss 0.014479\n",
      "batch 5032: loss 0.006957\n",
      "batch 5033: loss 0.017652\n",
      "batch 5034: loss 0.007032\n",
      "batch 5035: loss 0.166440\n",
      "batch 5036: loss 0.097836\n",
      "batch 5037: loss 0.024540\n",
      "batch 5038: loss 0.188763\n",
      "batch 5039: loss 0.032752\n",
      "batch 5040: loss 0.019572\n",
      "batch 5041: loss 0.052951\n",
      "batch 5042: loss 0.052240\n",
      "batch 5043: loss 0.018665\n",
      "batch 5044: loss 0.032368\n",
      "batch 5045: loss 0.077310\n",
      "batch 5046: loss 0.028545\n",
      "batch 5047: loss 0.089569\n",
      "batch 5048: loss 0.085755\n",
      "batch 5049: loss 0.010440\n",
      "batch 5050: loss 0.004824\n",
      "batch 5051: loss 0.251458\n",
      "batch 5052: loss 0.173320\n",
      "batch 5053: loss 0.121966\n",
      "batch 5054: loss 0.081305\n",
      "batch 5055: loss 0.073943\n",
      "batch 5056: loss 0.025946\n",
      "batch 5057: loss 0.042060\n",
      "batch 5058: loss 0.041102\n",
      "batch 5059: loss 0.063516\n",
      "batch 5060: loss 0.016129\n",
      "batch 5061: loss 0.296195\n",
      "batch 5062: loss 0.013997\n",
      "batch 5063: loss 0.011040\n",
      "batch 5064: loss 0.118559\n",
      "batch 5065: loss 0.030121\n",
      "batch 5066: loss 0.019794\n",
      "batch 5067: loss 0.086454\n",
      "batch 5068: loss 0.017165\n",
      "batch 5069: loss 0.066462\n",
      "batch 5070: loss 0.049082\n",
      "batch 5071: loss 0.011881\n",
      "batch 5072: loss 0.180335\n",
      "batch 5073: loss 0.029341\n",
      "batch 5074: loss 0.216979\n",
      "batch 5075: loss 0.045997\n",
      "batch 5076: loss 0.026935\n",
      "batch 5077: loss 0.073494\n",
      "batch 5078: loss 0.118646\n",
      "batch 5079: loss 0.025956\n",
      "batch 5080: loss 0.057727\n",
      "batch 5081: loss 0.070503\n",
      "batch 5082: loss 0.093224\n",
      "batch 5083: loss 0.070749\n",
      "batch 5084: loss 0.019833\n",
      "batch 5085: loss 0.058947\n",
      "batch 5086: loss 0.040708\n",
      "batch 5087: loss 0.020880\n",
      "batch 5088: loss 0.063114\n",
      "batch 5089: loss 0.020471\n",
      "batch 5090: loss 0.026924\n",
      "batch 5091: loss 0.080842\n",
      "batch 5092: loss 0.022111\n",
      "batch 5093: loss 0.034976\n",
      "batch 5094: loss 0.172243\n",
      "batch 5095: loss 0.023813\n",
      "batch 5096: loss 0.075317\n",
      "batch 5097: loss 0.011822\n",
      "batch 5098: loss 0.045877\n",
      "batch 5099: loss 0.069413\n",
      "batch 5100: loss 0.025283\n",
      "batch 5101: loss 0.098571\n",
      "batch 5102: loss 0.066243\n",
      "batch 5103: loss 0.039222\n",
      "batch 5104: loss 0.117883\n",
      "batch 5105: loss 0.055316\n",
      "batch 5106: loss 0.084937\n",
      "batch 5107: loss 0.009594\n",
      "batch 5108: loss 0.142995\n",
      "batch 5109: loss 0.041185\n",
      "batch 5110: loss 0.005035\n",
      "batch 5111: loss 0.011483\n",
      "batch 5112: loss 0.068976\n",
      "batch 5113: loss 0.066691\n",
      "batch 5114: loss 0.039711\n",
      "batch 5115: loss 0.014225\n",
      "batch 5116: loss 0.133180\n",
      "batch 5117: loss 0.021184\n",
      "batch 5118: loss 0.045953\n",
      "batch 5119: loss 0.004237\n",
      "batch 5120: loss 0.103790\n",
      "batch 5121: loss 0.044221\n",
      "batch 5122: loss 0.010225\n",
      "batch 5123: loss 0.153761\n",
      "batch 5124: loss 0.076567\n",
      "batch 5125: loss 0.102062\n",
      "batch 5126: loss 0.138778\n",
      "batch 5127: loss 0.041004\n",
      "batch 5128: loss 0.041107\n",
      "batch 5129: loss 0.045074\n",
      "batch 5130: loss 0.035944\n",
      "batch 5131: loss 0.238629\n",
      "batch 5132: loss 0.016975\n",
      "batch 5133: loss 0.049462\n",
      "batch 5134: loss 0.014096\n",
      "batch 5135: loss 0.156871\n",
      "batch 5136: loss 0.072294\n",
      "batch 5137: loss 0.103469\n",
      "batch 5138: loss 0.074299\n",
      "batch 5139: loss 0.029697\n",
      "batch 5140: loss 0.031770\n",
      "batch 5141: loss 0.068154\n",
      "batch 5142: loss 0.163474\n",
      "batch 5143: loss 0.037851\n",
      "batch 5144: loss 0.094527\n",
      "batch 5145: loss 0.111045\n",
      "batch 5146: loss 0.039679\n",
      "batch 5147: loss 0.029374\n",
      "batch 5148: loss 0.025441\n",
      "batch 5149: loss 0.049318\n",
      "batch 5150: loss 0.084789\n",
      "batch 5151: loss 0.041355\n",
      "batch 5152: loss 0.034036\n",
      "batch 5153: loss 0.038907\n",
      "batch 5154: loss 0.040578\n",
      "batch 5155: loss 0.069858\n",
      "batch 5156: loss 0.068751\n",
      "batch 5157: loss 0.148221\n",
      "batch 5158: loss 0.065327\n",
      "batch 5159: loss 0.133723\n",
      "batch 5160: loss 0.013196\n",
      "batch 5161: loss 0.101538\n",
      "batch 5162: loss 0.058671\n",
      "batch 5163: loss 0.038952\n",
      "batch 5164: loss 0.028130\n",
      "batch 5165: loss 0.058064\n",
      "batch 5166: loss 0.010085\n",
      "batch 5167: loss 0.021379\n",
      "batch 5168: loss 0.016377\n",
      "batch 5169: loss 0.008404\n",
      "batch 5170: loss 0.084116\n",
      "batch 5171: loss 0.025994\n",
      "batch 5172: loss 0.017264\n",
      "batch 5173: loss 0.014514\n",
      "batch 5174: loss 0.041260\n",
      "batch 5175: loss 0.047394\n",
      "batch 5176: loss 0.047622\n",
      "batch 5177: loss 0.041940\n",
      "batch 5178: loss 0.015520\n",
      "batch 5179: loss 0.023892\n",
      "batch 5180: loss 0.018186\n",
      "batch 5181: loss 0.134075\n",
      "batch 5182: loss 0.048091\n",
      "batch 5183: loss 0.047962\n",
      "batch 5184: loss 0.020889\n",
      "batch 5185: loss 0.048969\n",
      "batch 5186: loss 0.062193\n",
      "batch 5187: loss 0.019590\n",
      "batch 5188: loss 0.042603\n",
      "batch 5189: loss 0.030934\n",
      "batch 5190: loss 0.020449\n",
      "batch 5191: loss 0.066746\n",
      "batch 5192: loss 0.084068\n",
      "batch 5193: loss 0.043223\n",
      "batch 5194: loss 0.121985\n",
      "batch 5195: loss 0.016259\n",
      "batch 5196: loss 0.027487\n",
      "batch 5197: loss 0.053082\n",
      "batch 5198: loss 0.011938\n",
      "batch 5199: loss 0.028845\n",
      "batch 5200: loss 0.023638\n",
      "batch 5201: loss 0.125653\n",
      "batch 5202: loss 0.155187\n",
      "batch 5203: loss 0.040461\n",
      "batch 5204: loss 0.009429\n",
      "batch 5205: loss 0.056667\n",
      "batch 5206: loss 0.014658\n",
      "batch 5207: loss 0.009943\n",
      "batch 5208: loss 0.005042\n",
      "batch 5209: loss 0.051747\n",
      "batch 5210: loss 0.044722\n",
      "batch 5211: loss 0.071055\n",
      "batch 5212: loss 0.074056\n",
      "batch 5213: loss 0.109041\n",
      "batch 5214: loss 0.044122\n",
      "batch 5215: loss 0.014322\n",
      "batch 5216: loss 0.029651\n",
      "batch 5217: loss 0.027404\n",
      "batch 5218: loss 0.079532\n",
      "batch 5219: loss 0.007698\n",
      "batch 5220: loss 0.187837\n",
      "batch 5221: loss 0.034397\n",
      "batch 5222: loss 0.100966\n",
      "batch 5223: loss 0.043697\n",
      "batch 5224: loss 0.015990\n",
      "batch 5225: loss 0.066768\n",
      "batch 5226: loss 0.067146\n",
      "batch 5227: loss 0.035725\n",
      "batch 5228: loss 0.016225\n",
      "batch 5229: loss 0.013803\n",
      "batch 5230: loss 0.111041\n",
      "batch 5231: loss 0.006096\n",
      "batch 5232: loss 0.058905\n",
      "batch 5233: loss 0.060596\n",
      "batch 5234: loss 0.023276\n",
      "batch 5235: loss 0.085979\n",
      "batch 5236: loss 0.027131\n",
      "batch 5237: loss 0.080005\n",
      "batch 5238: loss 0.221334\n",
      "batch 5239: loss 0.104414\n",
      "batch 5240: loss 0.012608\n",
      "batch 5241: loss 0.052190\n",
      "batch 5242: loss 0.021938\n",
      "batch 5243: loss 0.050845\n",
      "batch 5244: loss 0.117278\n",
      "batch 5245: loss 0.038269\n",
      "batch 5246: loss 0.125928\n",
      "batch 5247: loss 0.048462\n",
      "batch 5248: loss 0.042149\n",
      "batch 5249: loss 0.021579\n",
      "batch 5250: loss 0.021766\n",
      "batch 5251: loss 0.075002\n",
      "batch 5252: loss 0.022815\n",
      "batch 5253: loss 0.015873\n",
      "batch 5254: loss 0.031299\n",
      "batch 5255: loss 0.060922\n",
      "batch 5256: loss 0.012103\n",
      "batch 5257: loss 0.079146\n",
      "batch 5258: loss 0.067185\n",
      "batch 5259: loss 0.045768\n",
      "batch 5260: loss 0.029637\n",
      "batch 5261: loss 0.185773\n",
      "batch 5262: loss 0.113803\n",
      "batch 5263: loss 0.043896\n",
      "batch 5264: loss 0.017143\n",
      "batch 5265: loss 0.087825\n",
      "batch 5266: loss 0.025921\n",
      "batch 5267: loss 0.014981\n",
      "batch 5268: loss 0.044332\n",
      "batch 5269: loss 0.043275\n",
      "batch 5270: loss 0.196432\n",
      "batch 5271: loss 0.136639\n",
      "batch 5272: loss 0.031565\n",
      "batch 5273: loss 0.028806\n",
      "batch 5274: loss 0.019694\n",
      "batch 5275: loss 0.063021\n",
      "batch 5276: loss 0.199911\n",
      "batch 5277: loss 0.047468\n",
      "batch 5278: loss 0.037735\n",
      "batch 5279: loss 0.030374\n",
      "batch 5280: loss 0.044902\n",
      "batch 5281: loss 0.115441\n",
      "batch 5282: loss 0.263368\n",
      "batch 5283: loss 0.014849\n",
      "batch 5284: loss 0.027878\n",
      "batch 5285: loss 0.033405\n",
      "batch 5286: loss 0.031633\n",
      "batch 5287: loss 0.038310\n",
      "batch 5288: loss 0.131500\n",
      "batch 5289: loss 0.096931\n",
      "batch 5290: loss 0.047118\n",
      "batch 5291: loss 0.028651\n",
      "batch 5292: loss 0.014588\n",
      "batch 5293: loss 0.189578\n",
      "batch 5294: loss 0.029751\n",
      "batch 5295: loss 0.041506\n",
      "batch 5296: loss 0.123325\n",
      "batch 5297: loss 0.017476\n",
      "batch 5298: loss 0.009465\n",
      "batch 5299: loss 0.056575\n",
      "batch 5300: loss 0.028832\n",
      "batch 5301: loss 0.031757\n",
      "batch 5302: loss 0.113808\n",
      "batch 5303: loss 0.021797\n",
      "batch 5304: loss 0.007932\n",
      "batch 5305: loss 0.012684\n",
      "batch 5306: loss 0.018981\n",
      "batch 5307: loss 0.037556\n",
      "batch 5308: loss 0.039677\n",
      "batch 5309: loss 0.050398\n",
      "batch 5310: loss 0.098582\n",
      "batch 5311: loss 0.031698\n",
      "batch 5312: loss 0.011967\n",
      "batch 5313: loss 0.034085\n",
      "batch 5314: loss 0.034769\n",
      "batch 5315: loss 0.094262\n",
      "batch 5316: loss 0.017703\n",
      "batch 5317: loss 0.010949\n",
      "batch 5318: loss 0.011917\n",
      "batch 5319: loss 0.044551\n",
      "batch 5320: loss 0.043121\n",
      "batch 5321: loss 0.010501\n",
      "batch 5322: loss 0.044159\n",
      "batch 5323: loss 0.033110\n",
      "batch 5324: loss 0.008135\n",
      "batch 5325: loss 0.226942\n",
      "batch 5326: loss 0.012742\n",
      "batch 5327: loss 0.011417\n",
      "batch 5328: loss 0.094163\n",
      "batch 5329: loss 0.035434\n",
      "batch 5330: loss 0.099491\n",
      "batch 5331: loss 0.019964\n",
      "batch 5332: loss 0.071496\n",
      "batch 5333: loss 0.016375\n",
      "batch 5334: loss 0.091471\n",
      "batch 5335: loss 0.012270\n",
      "batch 5336: loss 0.028635\n",
      "batch 5337: loss 0.042597\n",
      "batch 5338: loss 0.015870\n",
      "batch 5339: loss 0.050971\n",
      "batch 5340: loss 0.114931\n",
      "batch 5341: loss 0.049966\n",
      "batch 5342: loss 0.026458\n",
      "batch 5343: loss 0.049191\n",
      "batch 5344: loss 0.018867\n",
      "batch 5345: loss 0.012995\n",
      "batch 5346: loss 0.055489\n",
      "batch 5347: loss 0.013709\n",
      "batch 5348: loss 0.025409\n",
      "batch 5349: loss 0.017114\n",
      "batch 5350: loss 0.024518\n",
      "batch 5351: loss 0.016778\n",
      "batch 5352: loss 0.016821\n",
      "batch 5353: loss 0.104263\n",
      "batch 5354: loss 0.149062\n",
      "batch 5355: loss 0.054057\n",
      "batch 5356: loss 0.047562\n",
      "batch 5357: loss 0.134043\n",
      "batch 5358: loss 0.014384\n",
      "batch 5359: loss 0.069940\n",
      "batch 5360: loss 0.030339\n",
      "batch 5361: loss 0.036374\n",
      "batch 5362: loss 0.029280\n",
      "batch 5363: loss 0.005946\n",
      "batch 5364: loss 0.060558\n",
      "batch 5365: loss 0.090080\n",
      "batch 5366: loss 0.006535\n",
      "batch 5367: loss 0.063761\n",
      "batch 5368: loss 0.047283\n",
      "batch 5369: loss 0.065209\n",
      "batch 5370: loss 0.046113\n",
      "batch 5371: loss 0.022774\n",
      "batch 5372: loss 0.018150\n",
      "batch 5373: loss 0.021401\n",
      "batch 5374: loss 0.041338\n",
      "batch 5375: loss 0.032243\n",
      "batch 5376: loss 0.105306\n",
      "batch 5377: loss 0.035627\n",
      "batch 5378: loss 0.047912\n",
      "batch 5379: loss 0.024647\n",
      "batch 5380: loss 0.023630\n",
      "batch 5381: loss 0.050649\n",
      "batch 5382: loss 0.118397\n",
      "batch 5383: loss 0.060716\n",
      "batch 5384: loss 0.011577\n",
      "batch 5385: loss 0.058204\n",
      "batch 5386: loss 0.047690\n",
      "batch 5387: loss 0.041513\n",
      "batch 5388: loss 0.031384\n",
      "batch 5389: loss 0.010281\n",
      "batch 5390: loss 0.040012\n",
      "batch 5391: loss 0.011467\n",
      "batch 5392: loss 0.057782\n",
      "batch 5393: loss 0.113466\n",
      "batch 5394: loss 0.010212\n",
      "batch 5395: loss 0.035058\n",
      "batch 5396: loss 0.098784\n",
      "batch 5397: loss 0.047868\n",
      "batch 5398: loss 0.045673\n",
      "batch 5399: loss 0.049021\n",
      "batch 5400: loss 0.059740\n",
      "batch 5401: loss 0.039984\n",
      "batch 5402: loss 0.036000\n",
      "batch 5403: loss 0.046787\n",
      "batch 5404: loss 0.022980\n",
      "batch 5405: loss 0.047528\n",
      "batch 5406: loss 0.034952\n",
      "batch 5407: loss 0.046270\n",
      "batch 5408: loss 0.022087\n",
      "batch 5409: loss 0.020762\n",
      "batch 5410: loss 0.031906\n",
      "batch 5411: loss 0.005755\n",
      "batch 5412: loss 0.021576\n",
      "batch 5413: loss 0.058837\n",
      "batch 5414: loss 0.027836\n",
      "batch 5415: loss 0.033715\n",
      "batch 5416: loss 0.013729\n",
      "batch 5417: loss 0.159253\n",
      "batch 5418: loss 0.029742\n",
      "batch 5419: loss 0.013221\n",
      "batch 5420: loss 0.016345\n",
      "batch 5421: loss 0.009831\n",
      "batch 5422: loss 0.036451\n",
      "batch 5423: loss 0.056323\n",
      "batch 5424: loss 0.048562\n",
      "batch 5425: loss 0.089491\n",
      "batch 5426: loss 0.124031\n",
      "batch 5427: loss 0.008275\n",
      "batch 5428: loss 0.071261\n",
      "batch 5429: loss 0.062116\n",
      "batch 5430: loss 0.020111\n",
      "batch 5431: loss 0.042261\n",
      "batch 5432: loss 0.060780\n",
      "batch 5433: loss 0.025681\n",
      "batch 5434: loss 0.105348\n",
      "batch 5435: loss 0.058634\n",
      "batch 5436: loss 0.011927\n",
      "batch 5437: loss 0.030048\n",
      "batch 5438: loss 0.061002\n",
      "batch 5439: loss 0.023110\n",
      "batch 5440: loss 0.018622\n",
      "batch 5441: loss 0.028063\n",
      "batch 5442: loss 0.030642\n",
      "batch 5443: loss 0.059055\n",
      "batch 5444: loss 0.028386\n",
      "batch 5445: loss 0.081186\n",
      "batch 5446: loss 0.090848\n",
      "batch 5447: loss 0.085245\n",
      "batch 5448: loss 0.036731\n",
      "batch 5449: loss 0.068969\n",
      "batch 5450: loss 0.016909\n",
      "batch 5451: loss 0.130783\n",
      "batch 5452: loss 0.053821\n",
      "batch 5453: loss 0.012836\n",
      "batch 5454: loss 0.048596\n",
      "batch 5455: loss 0.016801\n",
      "batch 5456: loss 0.020469\n",
      "batch 5457: loss 0.006711\n",
      "batch 5458: loss 0.010587\n",
      "batch 5459: loss 0.019333\n",
      "batch 5460: loss 0.178319\n",
      "batch 5461: loss 0.078078\n",
      "batch 5462: loss 0.041693\n",
      "batch 5463: loss 0.158783\n",
      "batch 5464: loss 0.085376\n",
      "batch 5465: loss 0.008839\n",
      "batch 5466: loss 0.021944\n",
      "batch 5467: loss 0.050234\n",
      "batch 5468: loss 0.067978\n",
      "batch 5469: loss 0.142236\n",
      "batch 5470: loss 0.011384\n",
      "batch 5471: loss 0.045686\n",
      "batch 5472: loss 0.015635\n",
      "batch 5473: loss 0.116318\n",
      "batch 5474: loss 0.054032\n",
      "batch 5475: loss 0.080744\n",
      "batch 5476: loss 0.036811\n",
      "batch 5477: loss 0.030946\n",
      "batch 5478: loss 0.072183\n",
      "batch 5479: loss 0.032425\n",
      "batch 5480: loss 0.021616\n",
      "batch 5481: loss 0.039092\n",
      "batch 5482: loss 0.091669\n",
      "batch 5483: loss 0.018965\n",
      "batch 5484: loss 0.133598\n",
      "batch 5485: loss 0.134469\n",
      "batch 5486: loss 0.084380\n",
      "batch 5487: loss 0.007067\n",
      "batch 5488: loss 0.021859\n",
      "batch 5489: loss 0.021816\n",
      "batch 5490: loss 0.018905\n",
      "batch 5491: loss 0.043204\n",
      "batch 5492: loss 0.047717\n",
      "batch 5493: loss 0.048740\n",
      "batch 5494: loss 0.069465\n",
      "batch 5495: loss 0.009737\n",
      "batch 5496: loss 0.073883\n",
      "batch 5497: loss 0.063999\n",
      "batch 5498: loss 0.007109\n",
      "batch 5499: loss 0.092888\n",
      "batch 5500: loss 0.008262\n",
      "batch 5501: loss 0.003872\n",
      "batch 5502: loss 0.018548\n",
      "batch 5503: loss 0.076378\n",
      "batch 5504: loss 0.073810\n",
      "batch 5505: loss 0.038688\n",
      "batch 5506: loss 0.033700\n",
      "batch 5507: loss 0.125476\n",
      "batch 5508: loss 0.050596\n",
      "batch 5509: loss 0.095771\n",
      "batch 5510: loss 0.128830\n",
      "batch 5511: loss 0.058562\n",
      "batch 5512: loss 0.021338\n",
      "batch 5513: loss 0.049048\n",
      "batch 5514: loss 0.022056\n",
      "batch 5515: loss 0.017519\n",
      "batch 5516: loss 0.062283\n",
      "batch 5517: loss 0.009962\n",
      "batch 5518: loss 0.033396\n",
      "batch 5519: loss 0.050326\n",
      "batch 5520: loss 0.099038\n",
      "batch 5521: loss 0.036746\n",
      "batch 5522: loss 0.030480\n",
      "batch 5523: loss 0.068563\n",
      "batch 5524: loss 0.028735\n",
      "batch 5525: loss 0.149290\n",
      "batch 5526: loss 0.041628\n",
      "batch 5527: loss 0.114755\n",
      "batch 5528: loss 0.047158\n",
      "batch 5529: loss 0.068015\n",
      "batch 5530: loss 0.023177\n",
      "batch 5531: loss 0.050686\n",
      "batch 5532: loss 0.042581\n",
      "batch 5533: loss 0.132746\n",
      "batch 5534: loss 0.016320\n",
      "batch 5535: loss 0.021432\n",
      "batch 5536: loss 0.012736\n",
      "batch 5537: loss 0.097171\n",
      "batch 5538: loss 0.090396\n",
      "batch 5539: loss 0.131856\n",
      "batch 5540: loss 0.065298\n",
      "batch 5541: loss 0.025324\n",
      "batch 5542: loss 0.021691\n",
      "batch 5543: loss 0.017477\n",
      "batch 5544: loss 0.036063\n",
      "batch 5545: loss 0.078253\n",
      "batch 5546: loss 0.016440\n",
      "batch 5547: loss 0.073619\n",
      "batch 5548: loss 0.017778\n",
      "batch 5549: loss 0.018028\n",
      "batch 5550: loss 0.010777\n",
      "batch 5551: loss 0.061480\n",
      "batch 5552: loss 0.042252\n",
      "batch 5553: loss 0.014163\n",
      "batch 5554: loss 0.289101\n",
      "batch 5555: loss 0.042543\n",
      "batch 5556: loss 0.032538\n",
      "batch 5557: loss 0.042285\n",
      "batch 5558: loss 0.033102\n",
      "batch 5559: loss 0.112102\n",
      "batch 5560: loss 0.009775\n",
      "batch 5561: loss 0.024630\n",
      "batch 5562: loss 0.006485\n",
      "batch 5563: loss 0.145416\n",
      "batch 5564: loss 0.088937\n",
      "batch 5565: loss 0.068903\n",
      "batch 5566: loss 0.035230\n",
      "batch 5567: loss 0.222641\n",
      "batch 5568: loss 0.025545\n",
      "batch 5569: loss 0.013517\n",
      "batch 5570: loss 0.026259\n",
      "batch 5571: loss 0.044684\n",
      "batch 5572: loss 0.127517\n",
      "batch 5573: loss 0.055221\n",
      "batch 5574: loss 0.070744\n",
      "batch 5575: loss 0.121658\n",
      "batch 5576: loss 0.135889\n",
      "batch 5577: loss 0.016416\n",
      "batch 5578: loss 0.031202\n",
      "batch 5579: loss 0.016097\n",
      "batch 5580: loss 0.166100\n",
      "batch 5581: loss 0.015914\n",
      "batch 5582: loss 0.072538\n",
      "batch 5583: loss 0.085634\n",
      "batch 5584: loss 0.055336\n",
      "batch 5585: loss 0.080997\n",
      "batch 5586: loss 0.064136\n",
      "batch 5587: loss 0.031893\n",
      "batch 5588: loss 0.038358\n",
      "batch 5589: loss 0.010157\n",
      "batch 5590: loss 0.061361\n",
      "batch 5591: loss 0.025177\n",
      "batch 5592: loss 0.021897\n",
      "batch 5593: loss 0.032213\n",
      "batch 5594: loss 0.081480\n",
      "batch 5595: loss 0.191158\n",
      "batch 5596: loss 0.095689\n",
      "batch 5597: loss 0.012946\n",
      "batch 5598: loss 0.060195\n",
      "batch 5599: loss 0.082038\n",
      "batch 5600: loss 0.017194\n",
      "batch 5601: loss 0.022762\n",
      "batch 5602: loss 0.008987\n",
      "batch 5603: loss 0.006971\n",
      "batch 5604: loss 0.035762\n",
      "batch 5605: loss 0.117454\n",
      "batch 5606: loss 0.024319\n",
      "batch 5607: loss 0.103382\n",
      "batch 5608: loss 0.009653\n",
      "batch 5609: loss 0.047799\n",
      "batch 5610: loss 0.024652\n",
      "batch 5611: loss 0.058850\n",
      "batch 5612: loss 0.068445\n",
      "batch 5613: loss 0.050544\n",
      "batch 5614: loss 0.042579\n",
      "batch 5615: loss 0.128287\n",
      "batch 5616: loss 0.044630\n",
      "batch 5617: loss 0.047136\n",
      "batch 5618: loss 0.127633\n",
      "batch 5619: loss 0.032039\n",
      "batch 5620: loss 0.228841\n",
      "batch 5621: loss 0.040782\n",
      "batch 5622: loss 0.072660\n",
      "batch 5623: loss 0.050331\n",
      "batch 5624: loss 0.102315\n",
      "batch 5625: loss 0.011928\n",
      "batch 5626: loss 0.038430\n",
      "batch 5627: loss 0.035746\n",
      "batch 5628: loss 0.064970\n",
      "batch 5629: loss 0.040175\n",
      "batch 5630: loss 0.155042\n",
      "batch 5631: loss 0.062531\n",
      "batch 5632: loss 0.017721\n",
      "batch 5633: loss 0.041254\n",
      "batch 5634: loss 0.058866\n",
      "batch 5635: loss 0.015560\n",
      "batch 5636: loss 0.038743\n",
      "batch 5637: loss 0.027683\n",
      "batch 5638: loss 0.013523\n",
      "batch 5639: loss 0.026396\n",
      "batch 5640: loss 0.007339\n",
      "batch 5641: loss 0.011638\n",
      "batch 5642: loss 0.097889\n",
      "batch 5643: loss 0.155634\n",
      "batch 5644: loss 0.040471\n",
      "batch 5645: loss 0.035392\n",
      "batch 5646: loss 0.130170\n",
      "batch 5647: loss 0.041929\n",
      "batch 5648: loss 0.009079\n",
      "batch 5649: loss 0.048280\n",
      "batch 5650: loss 0.024288\n",
      "batch 5651: loss 0.015509\n",
      "batch 5652: loss 0.029018\n",
      "batch 5653: loss 0.018779\n",
      "batch 5654: loss 0.045191\n",
      "batch 5655: loss 0.055012\n",
      "batch 5656: loss 0.065206\n",
      "batch 5657: loss 0.032879\n",
      "batch 5658: loss 0.020553\n",
      "batch 5659: loss 0.006807\n",
      "batch 5660: loss 0.025637\n",
      "batch 5661: loss 0.007869\n",
      "batch 5662: loss 0.057162\n",
      "batch 5663: loss 0.105517\n",
      "batch 5664: loss 0.013553\n",
      "batch 5665: loss 0.036666\n",
      "batch 5666: loss 0.024671\n",
      "batch 5667: loss 0.151983\n",
      "batch 5668: loss 0.061997\n",
      "batch 5669: loss 0.021984\n",
      "batch 5670: loss 0.082796\n",
      "batch 5671: loss 0.068134\n",
      "batch 5672: loss 0.007532\n",
      "batch 5673: loss 0.014194\n",
      "batch 5674: loss 0.047751\n",
      "batch 5675: loss 0.015430\n",
      "batch 5676: loss 0.050169\n",
      "batch 5677: loss 0.015618\n",
      "batch 5678: loss 0.027916\n",
      "batch 5679: loss 0.061821\n",
      "batch 5680: loss 0.366698\n",
      "batch 5681: loss 0.025614\n",
      "batch 5682: loss 0.012070\n",
      "batch 5683: loss 0.042222\n",
      "batch 5684: loss 0.035186\n",
      "batch 5685: loss 0.020575\n",
      "batch 5686: loss 0.011986\n",
      "batch 5687: loss 0.023524\n",
      "batch 5688: loss 0.024434\n",
      "batch 5689: loss 0.050086\n",
      "batch 5690: loss 0.033140\n",
      "batch 5691: loss 0.136872\n",
      "batch 5692: loss 0.058871\n",
      "batch 5693: loss 0.043681\n",
      "batch 5694: loss 0.024123\n",
      "batch 5695: loss 0.065432\n",
      "batch 5696: loss 0.047144\n",
      "batch 5697: loss 0.132143\n",
      "batch 5698: loss 0.034263\n",
      "batch 5699: loss 0.070547\n",
      "batch 5700: loss 0.022289\n",
      "batch 5701: loss 0.027041\n",
      "batch 5702: loss 0.049774\n",
      "batch 5703: loss 0.015165\n",
      "batch 5704: loss 0.041095\n",
      "batch 5705: loss 0.042420\n",
      "batch 5706: loss 0.025288\n",
      "batch 5707: loss 0.083823\n",
      "batch 5708: loss 0.149506\n",
      "batch 5709: loss 0.022332\n",
      "batch 5710: loss 0.078117\n",
      "batch 5711: loss 0.028635\n",
      "batch 5712: loss 0.016131\n",
      "batch 5713: loss 0.016988\n",
      "batch 5714: loss 0.058594\n",
      "batch 5715: loss 0.049941\n",
      "batch 5716: loss 0.058673\n",
      "batch 5717: loss 0.006045\n",
      "batch 5718: loss 0.006084\n",
      "batch 5719: loss 0.069791\n",
      "batch 5720: loss 0.014360\n",
      "batch 5721: loss 0.008886\n",
      "batch 5722: loss 0.008067\n",
      "batch 5723: loss 0.154745\n",
      "batch 5724: loss 0.077300\n",
      "batch 5725: loss 0.042662\n",
      "batch 5726: loss 0.023662\n",
      "batch 5727: loss 0.003589\n",
      "batch 5728: loss 0.079309\n",
      "batch 5729: loss 0.003501\n",
      "batch 5730: loss 0.015382\n",
      "batch 5731: loss 0.064861\n",
      "batch 5732: loss 0.041572\n",
      "batch 5733: loss 0.103591\n",
      "batch 5734: loss 0.015152\n",
      "batch 5735: loss 0.060318\n",
      "batch 5736: loss 0.120438\n",
      "batch 5737: loss 0.026421\n",
      "batch 5738: loss 0.151007\n",
      "batch 5739: loss 0.091101\n",
      "batch 5740: loss 0.063436\n",
      "batch 5741: loss 0.026835\n",
      "batch 5742: loss 0.006698\n",
      "batch 5743: loss 0.057030\n",
      "batch 5744: loss 0.141537\n",
      "batch 5745: loss 0.022894\n",
      "batch 5746: loss 0.072800\n",
      "batch 5747: loss 0.023535\n",
      "batch 5748: loss 0.043831\n",
      "batch 5749: loss 0.051107\n",
      "batch 5750: loss 0.062881\n",
      "batch 5751: loss 0.040806\n",
      "batch 5752: loss 0.122049\n",
      "batch 5753: loss 0.026684\n",
      "batch 5754: loss 0.071633\n",
      "batch 5755: loss 0.093752\n",
      "batch 5756: loss 0.034386\n",
      "batch 5757: loss 0.065737\n",
      "batch 5758: loss 0.010755\n",
      "batch 5759: loss 0.067810\n",
      "batch 5760: loss 0.056465\n",
      "batch 5761: loss 0.009939\n",
      "batch 5762: loss 0.096591\n",
      "batch 5763: loss 0.036973\n",
      "batch 5764: loss 0.025380\n",
      "batch 5765: loss 0.007160\n",
      "batch 5766: loss 0.036381\n",
      "batch 5767: loss 0.023027\n",
      "batch 5768: loss 0.052809\n",
      "batch 5769: loss 0.054649\n",
      "batch 5770: loss 0.021423\n",
      "batch 5771: loss 0.044901\n",
      "batch 5772: loss 0.034439\n",
      "batch 5773: loss 0.011092\n",
      "batch 5774: loss 0.039149\n",
      "batch 5775: loss 0.028322\n",
      "batch 5776: loss 0.021590\n",
      "batch 5777: loss 0.084340\n",
      "batch 5778: loss 0.019431\n",
      "batch 5779: loss 0.088469\n",
      "batch 5780: loss 0.087616\n",
      "batch 5781: loss 0.125727\n",
      "batch 5782: loss 0.172571\n",
      "batch 5783: loss 0.016598\n",
      "batch 5784: loss 0.052399\n",
      "batch 5785: loss 0.043908\n",
      "batch 5786: loss 0.033501\n",
      "batch 5787: loss 0.088589\n",
      "batch 5788: loss 0.012024\n",
      "batch 5789: loss 0.025669\n",
      "batch 5790: loss 0.008051\n",
      "batch 5791: loss 0.044581\n",
      "batch 5792: loss 0.010305\n",
      "batch 5793: loss 0.070647\n",
      "batch 5794: loss 0.012524\n",
      "batch 5795: loss 0.045576\n",
      "batch 5796: loss 0.014061\n",
      "batch 5797: loss 0.024105\n",
      "batch 5798: loss 0.055043\n",
      "batch 5799: loss 0.047484\n",
      "batch 5800: loss 0.020454\n",
      "batch 5801: loss 0.025495\n",
      "batch 5802: loss 0.058372\n",
      "batch 5803: loss 0.040768\n",
      "batch 5804: loss 0.105227\n",
      "batch 5805: loss 0.050387\n",
      "batch 5806: loss 0.069810\n",
      "batch 5807: loss 0.020016\n",
      "batch 5808: loss 0.214380\n",
      "batch 5809: loss 0.022578\n",
      "batch 5810: loss 0.006505\n",
      "batch 5811: loss 0.184085\n",
      "batch 5812: loss 0.159036\n",
      "batch 5813: loss 0.014327\n",
      "batch 5814: loss 0.043697\n",
      "batch 5815: loss 0.081793\n",
      "batch 5816: loss 0.007090\n",
      "batch 5817: loss 0.027643\n",
      "batch 5818: loss 0.110865\n",
      "batch 5819: loss 0.015673\n",
      "batch 5820: loss 0.116397\n",
      "batch 5821: loss 0.005229\n",
      "batch 5822: loss 0.113874\n",
      "batch 5823: loss 0.084433\n",
      "batch 5824: loss 0.121834\n",
      "batch 5825: loss 0.015066\n",
      "batch 5826: loss 0.009601\n",
      "batch 5827: loss 0.030337\n",
      "batch 5828: loss 0.051750\n",
      "batch 5829: loss 0.097990\n",
      "batch 5830: loss 0.009115\n",
      "batch 5831: loss 0.022647\n",
      "batch 5832: loss 0.117070\n",
      "batch 5833: loss 0.039509\n",
      "batch 5834: loss 0.056335\n",
      "batch 5835: loss 0.036227\n",
      "batch 5836: loss 0.086372\n",
      "batch 5837: loss 0.071478\n",
      "batch 5838: loss 0.022099\n",
      "batch 5839: loss 0.006681\n",
      "batch 5840: loss 0.020492\n",
      "batch 5841: loss 0.102006\n",
      "batch 5842: loss 0.046540\n",
      "batch 5843: loss 0.170319\n",
      "batch 5844: loss 0.044385\n",
      "batch 5845: loss 0.029887\n",
      "batch 5846: loss 0.021446\n",
      "batch 5847: loss 0.063949\n",
      "batch 5848: loss 0.119589\n",
      "batch 5849: loss 0.052909\n",
      "batch 5850: loss 0.011821\n",
      "batch 5851: loss 0.049450\n",
      "batch 5852: loss 0.046914\n",
      "batch 5853: loss 0.018364\n",
      "batch 5854: loss 0.045158\n",
      "batch 5855: loss 0.026421\n",
      "batch 5856: loss 0.097313\n",
      "batch 5857: loss 0.103442\n",
      "batch 5858: loss 0.045115\n",
      "batch 5859: loss 0.140003\n",
      "batch 5860: loss 0.006781\n",
      "batch 5861: loss 0.106588\n",
      "batch 5862: loss 0.031728\n",
      "batch 5863: loss 0.026505\n",
      "batch 5864: loss 0.046442\n",
      "batch 5865: loss 0.419527\n",
      "batch 5866: loss 0.044328\n",
      "batch 5867: loss 0.007951\n",
      "batch 5868: loss 0.008843\n",
      "batch 5869: loss 0.083347\n",
      "batch 5870: loss 0.027698\n",
      "batch 5871: loss 0.082519\n",
      "batch 5872: loss 0.059761\n",
      "batch 5873: loss 0.073613\n",
      "batch 5874: loss 0.095204\n",
      "batch 5875: loss 0.032202\n",
      "batch 5876: loss 0.065316\n",
      "batch 5877: loss 0.077422\n",
      "batch 5878: loss 0.012743\n",
      "batch 5879: loss 0.015157\n",
      "batch 5880: loss 0.006283\n",
      "batch 5881: loss 0.017501\n",
      "batch 5882: loss 0.021098\n",
      "batch 5883: loss 0.053772\n",
      "batch 5884: loss 0.103134\n",
      "batch 5885: loss 0.095139\n",
      "batch 5886: loss 0.114110\n",
      "batch 5887: loss 0.023619\n",
      "batch 5888: loss 0.007666\n",
      "batch 5889: loss 0.035593\n",
      "batch 5890: loss 0.017376\n",
      "batch 5891: loss 0.018199\n",
      "batch 5892: loss 0.004334\n",
      "batch 5893: loss 0.010680\n",
      "batch 5894: loss 0.087260\n",
      "batch 5895: loss 0.032905\n",
      "batch 5896: loss 0.025602\n",
      "batch 5897: loss 0.044130\n",
      "batch 5898: loss 0.019488\n",
      "batch 5899: loss 0.019539\n",
      "batch 5900: loss 0.012399\n",
      "batch 5901: loss 0.066325\n",
      "batch 5902: loss 0.004783\n",
      "batch 5903: loss 0.014306\n",
      "batch 5904: loss 0.055025\n",
      "batch 5905: loss 0.033073\n",
      "batch 5906: loss 0.093589\n",
      "batch 5907: loss 0.030501\n",
      "batch 5908: loss 0.011838\n",
      "batch 5909: loss 0.023106\n",
      "batch 5910: loss 0.004261\n",
      "batch 5911: loss 0.032819\n",
      "batch 5912: loss 0.054443\n",
      "batch 5913: loss 0.028543\n",
      "batch 5914: loss 0.045290\n",
      "batch 5915: loss 0.041801\n",
      "batch 5916: loss 0.013849\n",
      "batch 5917: loss 0.024994\n",
      "batch 5918: loss 0.035086\n",
      "batch 5919: loss 0.019547\n",
      "batch 5920: loss 0.049572\n",
      "batch 5921: loss 0.071710\n",
      "batch 5922: loss 0.047604\n",
      "batch 5923: loss 0.016937\n",
      "batch 5924: loss 0.023682\n",
      "batch 5925: loss 0.033678\n",
      "batch 5926: loss 0.008400\n",
      "batch 5927: loss 0.041706\n",
      "batch 5928: loss 0.008495\n",
      "batch 5929: loss 0.015540\n",
      "batch 5930: loss 0.040528\n",
      "batch 5931: loss 0.079341\n",
      "batch 5932: loss 0.020230\n",
      "batch 5933: loss 0.096160\n",
      "batch 5934: loss 0.030741\n",
      "batch 5935: loss 0.007231\n",
      "batch 5936: loss 0.014083\n",
      "batch 5937: loss 0.016426\n",
      "batch 5938: loss 0.059377\n",
      "batch 5939: loss 0.020526\n",
      "batch 5940: loss 0.037242\n",
      "batch 5941: loss 0.062530\n",
      "batch 5942: loss 0.133277\n",
      "batch 5943: loss 0.015095\n",
      "batch 5944: loss 0.012379\n",
      "batch 5945: loss 0.035021\n",
      "batch 5946: loss 0.038277\n",
      "batch 5947: loss 0.012293\n",
      "batch 5948: loss 0.032851\n",
      "batch 5949: loss 0.046117\n",
      "batch 5950: loss 0.005167\n",
      "batch 5951: loss 0.139379\n",
      "batch 5952: loss 0.047683\n",
      "batch 5953: loss 0.027055\n",
      "batch 5954: loss 0.033997\n",
      "batch 5955: loss 0.006297\n",
      "batch 5956: loss 0.033070\n",
      "batch 5957: loss 0.023040\n",
      "batch 5958: loss 0.140323\n",
      "batch 5959: loss 0.032970\n",
      "batch 5960: loss 0.026770\n",
      "batch 5961: loss 0.008854\n",
      "batch 5962: loss 0.095583\n",
      "batch 5963: loss 0.074820\n",
      "batch 5964: loss 0.121828\n",
      "batch 5965: loss 0.151749\n",
      "batch 5966: loss 0.033811\n",
      "batch 5967: loss 0.118380\n",
      "batch 5968: loss 0.070386\n",
      "batch 5969: loss 0.095430\n",
      "batch 5970: loss 0.022959\n",
      "batch 5971: loss 0.013712\n",
      "batch 5972: loss 0.056306\n",
      "batch 5973: loss 0.009865\n",
      "batch 5974: loss 0.013615\n",
      "batch 5975: loss 0.119400\n",
      "batch 5976: loss 0.031232\n",
      "batch 5977: loss 0.150520\n",
      "batch 5978: loss 0.006416\n",
      "batch 5979: loss 0.081510\n",
      "batch 5980: loss 0.170064\n",
      "batch 5981: loss 0.098980\n",
      "batch 5982: loss 0.041630\n",
      "batch 5983: loss 0.003886\n",
      "batch 5984: loss 0.025790\n",
      "batch 5985: loss 0.049279\n",
      "batch 5986: loss 0.077624\n",
      "batch 5987: loss 0.011060\n",
      "batch 5988: loss 0.096650\n",
      "batch 5989: loss 0.108936\n",
      "batch 5990: loss 0.013117\n",
      "batch 5991: loss 0.050317\n",
      "batch 5992: loss 0.085866\n",
      "batch 5993: loss 0.017701\n",
      "batch 5994: loss 0.010873\n",
      "batch 5995: loss 0.062688\n",
      "batch 5996: loss 0.046317\n",
      "batch 5997: loss 0.059086\n",
      "batch 5998: loss 0.017112\n",
      "batch 5999: loss 0.144052\n"
     ]
    }
   ],
   "source": [
    "num_batches = int(data_loader.num_train_data // batch_size * num_epochs)\n",
    "for batch_index in range(num_batches):\n",
    "  X, y = data_loader.get_batch(batch_size)\n",
    "  with tf.GradientTape() as tape:\n",
    "    y_pred = model(X)\n",
    "    loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_pred)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    print(\"batch %d: loss %f\" % (batch_index, loss.numpy()))\n",
    "  grads = tape.gradient(loss, model.variables)\n",
    "  optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9dCft6A86dch"
   },
   "source": [
    "# 模型的评估： tf.keras.metrics\n",
    "最后，我们使用测试集评估模型的性能。这里，我们使用 tf.keras.metrics 中的 SparseCategoricalAccuracy 评估器来评估模型在测试集上的性能，该评估器能够对模型预测的结果与真实结果进行比较，并输出预测正确的样本数占总样本数的比例。我们迭代测试数据集，每次通过 update_state() 方法向评估器输入两个参数： y_pred 和 y_true ，即模型预测出的结果和真实结果。评估器具有内部变量来保存当前评估指标相关的参数数值（例如当前已传入的累计样本数和当前预测正确的样本数）。迭代结束后，我们使用 result() 方法输出最终的评估指标值（预测正确的样本数占总样本数的比例）。\n",
    "\n",
    "在以下代码中，我们实例化了一个 tf.keras.metrics.SparseCategoricalAccuracy 评估器，并使用 For 循环迭代分批次传入了测试集数据的预测结果与真实结果，并输出训练后的模型在测试数据集上的准确率。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MRgrQ46u4IZq",
    "outputId": "33a83d07-c5be-4894-ce3e-192e74375981"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.973400\n"
     ]
    }
   ],
   "source": [
    "sparse_categorical_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "num_batches = int(data_loader.num_test_data // batch_size)\n",
    "for batch_index in range(num_batches):\n",
    "  start_index, end_index = batch_index * batch_size, (batch_index + 1) * batch_size\n",
    "  y_pred = model.predict(data_loader.test_data[start_index: end_index])\n",
    "  sparse_categorical_accuracy.update_state(y_true=data_loader.test_label[start_index:end_index], y_pred=y_pred)\n",
    "print(\"test accuracy: %f\" % sparse_categorical_accuracy.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nfP1_xu05aUL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "多层感知机（MLP）",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
